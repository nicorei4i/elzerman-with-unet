GPU available:  True
cuda
(100, 8192)
(100, 8192)
20086
noise sigs:  [0.01   0.5075 1.005  1.5025 2.    ]
Noise Sigma:  0.01
Creating datasets...
Start training...
Epoch [1/250], Train Loss: 0.6907, Validation Loss: 0.6893
Epoch [2/250], Train Loss: 0.6883, Validation Loss: 0.6872
Epoch [3/250], Train Loss: 0.6861, Validation Loss: 0.6848
Epoch [4/250], Train Loss: 0.6836, Validation Loss: 0.6819
Epoch [5/250], Train Loss: 0.6806, Validation Loss: 0.6785
Epoch [6/250], Train Loss: 0.6772, Validation Loss: 0.6743
Epoch [7/250], Train Loss: 0.6728, Validation Loss: 0.6691
Epoch [8/250], Train Loss: 0.6673, Validation Loss: 0.6629
Epoch [9/250], Train Loss: 0.6609, Validation Loss: 0.6555
Epoch [10/250], Train Loss: 0.6531, Validation Loss: 0.6463
Epoch [11/250], Train Loss: 0.6437, Validation Loss: 0.6369
Epoch [12/250], Train Loss: 0.6345, Validation Loss: 0.6277
Epoch [13/250], Train Loss: 0.6260, Validation Loss: 0.6207
Epoch [14/250], Train Loss: 0.6192, Validation Loss: 0.6138
Epoch [15/250], Train Loss: 0.6123, Validation Loss: 0.6066
Epoch [16/250], Train Loss: 0.6053, Validation Loss: 0.6001
Epoch [17/250], Train Loss: 0.5990, Validation Loss: 0.5940
Epoch [18/250], Train Loss: 0.5929, Validation Loss: 0.5878
Epoch [19/250], Train Loss: 0.5867, Validation Loss: 0.5812
Epoch [20/250], Train Loss: 0.5800, Validation Loss: 0.5744
Epoch [21/250], Train Loss: 0.5730, Validation Loss: 0.5672
Epoch [22/250], Train Loss: 0.5657, Validation Loss: 0.5594
Epoch [23/250], Train Loss: 0.5577, Validation Loss: 0.5506
Epoch [24/250], Train Loss: 0.5484, Validation Loss: 0.5392
Epoch [25/250], Train Loss: 0.5355, Validation Loss: 0.5188
Epoch [26/250], Train Loss: 0.5100, Validation Loss: 0.4711
Epoch [27/250], Train Loss: 0.4520, Validation Loss: 0.3888
Epoch [28/250], Train Loss: 0.3883, Validation Loss: 0.3558
Epoch [29/250], Train Loss: 0.3466, Validation Loss: 0.3153
Epoch [30/250], Train Loss: 0.3100, Validation Loss: 0.2748
Epoch [31/250], Train Loss: 0.2702, Validation Loss: 0.2466
Epoch [32/250], Train Loss: 0.2433, Validation Loss: 0.2250
Epoch [33/250], Train Loss: 0.2256, Validation Loss: 0.2123
Epoch [34/250], Train Loss: 0.2130, Validation Loss: 0.2000
Epoch [35/250], Train Loss: 0.2010, Validation Loss: 0.1904
Epoch [36/250], Train Loss: 0.1914, Validation Loss: 0.1805
Epoch [37/250], Train Loss: 0.1812, Validation Loss: 0.1702
Epoch [38/250], Train Loss: 0.1709, Validation Loss: 0.1604
Epoch [39/250], Train Loss: 0.1609, Validation Loss: 0.1505
Epoch [40/250], Train Loss: 0.1507, Validation Loss: 0.1404
Epoch [41/250], Train Loss: 0.1406, Validation Loss: 0.1306
Epoch [42/250], Train Loss: 0.1305, Validation Loss: 0.1210
Epoch [43/250], Train Loss: 0.1209, Validation Loss: 0.1116
Epoch [44/250], Train Loss: 0.1114, Validation Loss: 0.1028
Epoch [45/250], Train Loss: 0.1025, Validation Loss: 0.0944
Epoch [46/250], Train Loss: 0.0940, Validation Loss: 0.0861
Epoch [47/250], Train Loss: 0.0853, Validation Loss: 0.0774
Epoch [48/250], Train Loss: 0.0767, Validation Loss: 0.0696
Epoch [49/250], Train Loss: 0.0689, Validation Loss: 0.0623
Epoch [50/250], Train Loss: 0.0615, Validation Loss: 0.0558
Epoch [51/250], Train Loss: 0.0551, Validation Loss: 0.0498
Epoch [52/250], Train Loss: 0.0491, Validation Loss: 0.0442
Epoch [53/250], Train Loss: 0.0436, Validation Loss: 0.0392
Epoch [54/250], Train Loss: 0.0386, Validation Loss: 0.0348
Epoch [55/250], Train Loss: 0.0344, Validation Loss: 0.0310
Epoch [56/250], Train Loss: 0.0304, Validation Loss: 0.0274
Epoch [57/250], Train Loss: 0.0270, Validation Loss: 0.0244
Epoch [58/250], Train Loss: 0.0240, Validation Loss: 0.0217
Epoch [59/250], Train Loss: 0.0215, Validation Loss: 0.0194
Epoch [60/250], Train Loss: 0.0191, Validation Loss: 0.0172
Epoch [61/250], Train Loss: 0.0169, Validation Loss: 0.0153
Epoch [62/250], Train Loss: 0.0151, Validation Loss: 0.0136
Epoch [63/250], Train Loss: 0.0133, Validation Loss: 0.0120
Epoch [64/250], Train Loss: 0.0119, Validation Loss: 0.0108
Epoch [65/250], Train Loss: 0.0106, Validation Loss: 0.0096
Epoch [66/250], Train Loss: 0.0095, Validation Loss: 0.0086
Epoch [67/250], Train Loss: 0.0085, Validation Loss: 0.0077
Epoch [68/250], Train Loss: 0.0076, Validation Loss: 0.0067
Epoch [69/250], Train Loss: 0.0065, Validation Loss: 0.0054
Epoch [70/250], Train Loss: 0.0052, Validation Loss: 0.0040
Epoch [71/250], Train Loss: 0.0039, Validation Loss: 0.0032
Epoch [72/250], Train Loss: 0.0030, Validation Loss: 0.0025
Epoch [73/250], Train Loss: 0.0025, Validation Loss: 0.0021
Epoch [74/250], Train Loss: 0.0022, Validation Loss: 0.0019
Epoch [75/250], Train Loss: 0.0019, Validation Loss: 0.0017
Epoch [76/250], Train Loss: 0.0018, Validation Loss: 0.0016
Epoch [77/250], Train Loss: 0.0017, Validation Loss: 0.0015
Epoch [78/250], Train Loss: 0.0016, Validation Loss: 0.0015
Epoch [79/250], Train Loss: 0.0016, Validation Loss: 0.0014
Epoch [80/250], Train Loss: 0.0015, Validation Loss: 0.0014
Epoch [81/250], Train Loss: 0.0015, Validation Loss: 0.0013
Epoch [82/250], Train Loss: 0.0014, Validation Loss: 0.0013
Epoch [83/250], Train Loss: 0.0014, Validation Loss: 0.0013
Epoch [84/250], Train Loss: 0.0014, Validation Loss: 0.0013
Epoch [85/250], Train Loss: 0.0014, Validation Loss: 0.0012
Epoch [86/250], Train Loss: 0.0014, Validation Loss: 0.0012
Epoch [87/250], Train Loss: 0.0013, Validation Loss: 0.0012
Epoch [88/250], Train Loss: 0.0013, Validation Loss: 0.0012
Epoch [89/250], Train Loss: 0.0013, Validation Loss: 0.0012
Epoch [90/250], Train Loss: 0.0013, Validation Loss: 0.0012
Epoch [91/250], Train Loss: 0.0013, Validation Loss: 0.0011
Epoch [92/250], Train Loss: 0.0012, Validation Loss: 0.0011
Epoch [93/250], Train Loss: 0.0012, Validation Loss: 0.0011
Epoch [94/250], Train Loss: 0.0012, Validation Loss: 0.0011
Epoch [95/250], Train Loss: 0.0012, Validation Loss: 0.0011
Epoch [96/250], Train Loss: 0.0012, Validation Loss: 0.0010
Epoch [97/250], Train Loss: 0.0012, Validation Loss: 0.0010
Epoch [98/250], Train Loss: 0.0011, Validation Loss: 0.0010
Epoch [99/250], Train Loss: 0.0011, Validation Loss: 0.0010
Epoch [100/250], Train Loss: 0.0011, Validation Loss: 0.0010
Epoch [101/250], Train Loss: 0.0011, Validation Loss: 0.0010
Epoch [102/250], Train Loss: 0.0011, Validation Loss: 0.0010
Epoch [103/250], Train Loss: 0.0011, Validation Loss: 0.0010
Epoch [104/250], Train Loss: 0.0011, Validation Loss: 0.0009
Epoch [105/250], Train Loss: 0.0010, Validation Loss: 0.0009
Epoch [106/250], Train Loss: 0.0010, Validation Loss: 0.0009
Epoch [107/250], Train Loss: 0.0010, Validation Loss: 0.0009
Epoch [108/250], Train Loss: 0.0010, Validation Loss: 0.0009
Epoch [109/250], Train Loss: 0.0010, Validation Loss: 0.0009
Epoch [110/250], Train Loss: 0.0010, Validation Loss: 0.0009
Epoch [111/250], Train Loss: 0.0010, Validation Loss: 0.0009
Epoch [112/250], Train Loss: 0.0010, Validation Loss: 0.0009
Epoch [113/250], Train Loss: 0.0010, Validation Loss: 0.0008
Epoch [114/250], Train Loss: 0.0009, Validation Loss: 0.0008
Epoch [115/250], Train Loss: 0.0009, Validation Loss: 0.0008
Epoch [116/250], Train Loss: 0.0009, Validation Loss: 0.0008
Epoch [117/250], Train Loss: 0.0009, Validation Loss: 0.0008
Epoch [118/250], Train Loss: 0.0009, Validation Loss: 0.0008
Epoch [119/250], Train Loss: 0.0009, Validation Loss: 0.0008
Epoch [120/250], Train Loss: 0.0009, Validation Loss: 0.0008
Epoch [121/250], Train Loss: 0.0009, Validation Loss: 0.0008
Epoch [122/250], Train Loss: 0.0009, Validation Loss: 0.0008
Epoch [123/250], Train Loss: 0.0009, Validation Loss: 0.0008
Epoch [124/250], Train Loss: 0.0009, Validation Loss: 0.0008
Epoch [125/250], Train Loss: 0.0009, Validation Loss: 0.0007
Epoch [126/250], Train Loss: 0.0008, Validation Loss: 0.0007
Epoch [127/250], Train Loss: 0.0008, Validation Loss: 0.0007
Epoch [128/250], Train Loss: 0.0008, Validation Loss: 0.0007
Epoch [129/250], Train Loss: 0.0008, Validation Loss: 0.0007
Epoch [130/250], Train Loss: 0.0008, Validation Loss: 0.0007
Epoch [131/250], Train Loss: 0.0008, Validation Loss: 0.0007
Epoch [132/250], Train Loss: 0.0008, Validation Loss: 0.0007
Epoch [133/250], Train Loss: 0.0008, Validation Loss: 0.0007
Epoch [134/250], Train Loss: 0.0008, Validation Loss: 0.0007
Epoch [135/250], Train Loss: 0.0008, Validation Loss: 0.0007
Epoch [136/250], Train Loss: 0.0008, Validation Loss: 0.0007
Epoch [137/250], Train Loss: 0.0008, Validation Loss: 0.0007
Epoch [138/250], Train Loss: 0.0008, Validation Loss: 0.0007
Epoch [139/250], Train Loss: 0.0008, Validation Loss: 0.0007
Epoch [140/250], Train Loss: 0.0007, Validation Loss: 0.0007
Epoch [141/250], Train Loss: 0.0007, Validation Loss: 0.0006
Epoch [142/250], Train Loss: 0.0007, Validation Loss: 0.0006
Epoch [143/250], Train Loss: 0.0007, Validation Loss: 0.0006
Epoch [144/250], Train Loss: 0.0007, Validation Loss: 0.0006
Epoch [145/250], Train Loss: 0.0007, Validation Loss: 0.0006
Epoch [146/250], Train Loss: 0.0007, Validation Loss: 0.0006
Epoch [147/250], Train Loss: 0.0007, Validation Loss: 0.0006
Epoch [148/250], Train Loss: 0.0007, Validation Loss: 0.0006
Epoch [149/250], Train Loss: 0.0007, Validation Loss: 0.0006
Epoch [150/250], Train Loss: 0.0007, Validation Loss: 0.0006
Epoch [151/250], Train Loss: 0.0007, Validation Loss: 0.0006
Epoch [152/250], Train Loss: 0.0007, Validation Loss: 0.0006
Epoch [153/250], Train Loss: 0.0007, Validation Loss: 0.0006
Epoch [154/250], Train Loss: 0.0007, Validation Loss: 0.0006
Epoch [155/250], Train Loss: 0.0007, Validation Loss: 0.0006
Epoch [156/250], Train Loss: 0.0007, Validation Loss: 0.0006
Epoch [157/250], Train Loss: 0.0007, Validation Loss: 0.0006
Epoch [158/250], Train Loss: 0.0007, Validation Loss: 0.0006
Epoch [159/250], Train Loss: 0.0006, Validation Loss: 0.0006
Epoch [160/250], Train Loss: 0.0006, Validation Loss: 0.0006
Epoch [161/250], Train Loss: 0.0006, Validation Loss: 0.0006
Epoch [162/250], Train Loss: 0.0006, Validation Loss: 0.0006
Epoch [163/250], Train Loss: 0.0006, Validation Loss: 0.0006
Epoch [164/250], Train Loss: 0.0006, Validation Loss: 0.0005
Epoch [165/250], Train Loss: 0.0006, Validation Loss: 0.0005
Epoch [166/250], Train Loss: 0.0006, Validation Loss: 0.0005
Epoch [167/250], Train Loss: 0.0006, Validation Loss: 0.0005
Epoch [168/250], Train Loss: 0.0006, Validation Loss: 0.0005
Epoch [169/250], Train Loss: 0.0006, Validation Loss: 0.0005
Epoch [170/250], Train Loss: 0.0006, Validation Loss: 0.0005
Epoch [171/250], Train Loss: 0.0006, Validation Loss: 0.0005
Epoch [172/250], Train Loss: 0.0006, Validation Loss: 0.0005
Epoch [173/250], Train Loss: 0.0006, Validation Loss: 0.0005
Epoch [174/250], Train Loss: 0.0006, Validation Loss: 0.0005
Epoch [175/250], Train Loss: 0.0006, Validation Loss: 0.0005
Epoch [176/250], Train Loss: 0.0006, Validation Loss: 0.0005
Epoch [177/250], Train Loss: 0.0006, Validation Loss: 0.0005
Epoch [178/250], Train Loss: 0.0006, Validation Loss: 0.0005
Epoch [179/250], Train Loss: 0.0006, Validation Loss: 0.0005
Epoch [180/250], Train Loss: 0.0006, Validation Loss: 0.0005
Epoch [181/250], Train Loss: 0.0006, Validation Loss: 0.0005
Epoch [182/250], Train Loss: 0.0006, Validation Loss: 0.0005
Epoch [183/250], Train Loss: 0.0006, Validation Loss: 0.0005
Epoch [184/250], Train Loss: 0.0006, Validation Loss: 0.0005
Epoch [185/250], Train Loss: 0.0006, Validation Loss: 0.0005
Epoch [186/250], Train Loss: 0.0005, Validation Loss: 0.0005
Epoch [187/250], Train Loss: 0.0005, Validation Loss: 0.0005
Epoch [188/250], Train Loss: 0.0005, Validation Loss: 0.0005
Epoch [189/250], Train Loss: 0.0005, Validation Loss: 0.0005
Epoch [190/250], Train Loss: 0.0005, Validation Loss: 0.0005
Epoch [191/250], Train Loss: 0.0005, Validation Loss: 0.0005
Epoch [192/250], Train Loss: 0.0005, Validation Loss: 0.0005
Epoch [193/250], Train Loss: 0.0005, Validation Loss: 0.0005
Epoch [194/250], Train Loss: 0.0005, Validation Loss: 0.0005
Epoch [195/250], Train Loss: 0.0005, Validation Loss: 0.0005
Epoch [196/250], Train Loss: 0.0005, Validation Loss: 0.0005
Epoch [197/250], Train Loss: 0.0005, Validation Loss: 0.0005
Epoch [198/250], Train Loss: 0.0005, Validation Loss: 0.0005
Epoch [199/250], Train Loss: 0.0005, Validation Loss: 0.0004
Epoch [200/250], Train Loss: 0.0005, Validation Loss: 0.0004
Epoch [201/250], Train Loss: 0.0005, Validation Loss: 0.0004
Epoch [202/250], Train Loss: 0.0005, Validation Loss: 0.0004
Epoch [203/250], Train Loss: 0.0005, Validation Loss: 0.0004
Epoch [204/250], Train Loss: 0.0005, Validation Loss: 0.0004
Epoch [205/250], Train Loss: 0.0005, Validation Loss: 0.0004
Epoch [206/250], Train Loss: 0.0005, Validation Loss: 0.0004
Epoch [207/250], Train Loss: 0.0005, Validation Loss: 0.0004
Epoch [208/250], Train Loss: 0.0005, Validation Loss: 0.0004
Epoch [209/250], Train Loss: 0.0005, Validation Loss: 0.0004
Epoch [210/250], Train Loss: 0.0005, Validation Loss: 0.0004
Epoch [211/250], Train Loss: 0.0005, Validation Loss: 0.0004
Epoch [212/250], Train Loss: 0.0005, Validation Loss: 0.0004
Epoch [213/250], Train Loss: 0.0005, Validation Loss: 0.0004
Epoch [214/250], Train Loss: 0.0005, Validation Loss: 0.0004
Epoch [215/250], Train Loss: 0.0005, Validation Loss: 0.0004
Epoch [216/250], Train Loss: 0.0005, Validation Loss: 0.0004
Epoch [217/250], Train Loss: 0.0005, Validation Loss: 0.0004
Epoch [218/250], Train Loss: 0.0005, Validation Loss: 0.0004
Epoch [219/250], Train Loss: 0.0005, Validation Loss: 0.0004
Epoch [220/250], Train Loss: 0.0005, Validation Loss: 0.0004
Epoch [221/250], Train Loss: 0.0005, Validation Loss: 0.0004
Epoch [222/250], Train Loss: 0.0005, Validation Loss: 0.0004
Epoch [223/250], Train Loss: 0.0005, Validation Loss: 0.0004
Epoch [224/250], Train Loss: 0.0005, Validation Loss: 0.0004
Epoch [225/250], Train Loss: 0.0004, Validation Loss: 0.0004
Epoch [226/250], Train Loss: 0.0004, Validation Loss: 0.0004
Epoch [227/250], Train Loss: 0.0004, Validation Loss: 0.0004
Epoch [228/250], Train Loss: 0.0004, Validation Loss: 0.0004
Epoch [229/250], Train Loss: 0.0004, Validation Loss: 0.0004
Epoch [230/250], Train Loss: 0.0004, Validation Loss: 0.0004
Epoch [231/250], Train Loss: 0.0004, Validation Loss: 0.0004
Epoch [232/250], Train Loss: 0.0004, Validation Loss: 0.0004
Epoch [233/250], Train Loss: 0.0004, Validation Loss: 0.0004
Epoch [234/250], Train Loss: 0.0004, Validation Loss: 0.0004
Epoch [235/250], Train Loss: 0.0004, Validation Loss: 0.0004
Epoch [236/250], Train Loss: 0.0004, Validation Loss: 0.0004
Epoch [237/250], Train Loss: 0.0004, Validation Loss: 0.0004
Epoch [238/250], Train Loss: 0.0004, Validation Loss: 0.0004
Epoch [239/250], Train Loss: 0.0004, Validation Loss: 0.0004
Epoch [240/250], Train Loss: 0.0004, Validation Loss: 0.0004
Epoch [241/250], Train Loss: 0.0004, Validation Loss: 0.0004
Epoch [242/250], Train Loss: 0.0004, Validation Loss: 0.0004
Epoch [243/250], Train Loss: 0.0004, Validation Loss: 0.0004
Epoch [244/250], Train Loss: 0.0004, Validation Loss: 0.0004
Epoch [245/250], Train Loss: 0.0004, Validation Loss: 0.0004
Epoch [246/250], Train Loss: 0.0004, Validation Loss: 0.0004
Epoch [247/250], Train Loss: 0.0004, Validation Loss: 0.0004
Epoch [248/250], Train Loss: 0.0004, Validation Loss: 0.0004
Epoch [249/250], Train Loss: 0.0004, Validation Loss: 0.0004
Epoch [250/250], Train Loss: 0.0004, Validation Loss: 0.0004

Finished Training in 81.7

Noise Sigma:  0.5075
Creating datasets...
Start training...
Epoch [1/250], Train Loss: 0.6547, Validation Loss: 0.7631
Epoch [2/250], Train Loss: 0.7768, Validation Loss: 0.5372
Epoch [3/250], Train Loss: 0.3985, Validation Loss: 0.3178
Epoch [4/250], Train Loss: 0.3918, Validation Loss: 0.3587
Epoch [5/250], Train Loss: 0.3299, Validation Loss: 0.3017
Epoch [6/250], Train Loss: 0.2977, Validation Loss: 0.3302
Epoch [7/250], Train Loss: 0.2955, Validation Loss: 0.3158
Epoch [8/250], Train Loss: 0.2761, Validation Loss: 0.2732
Epoch [9/250], Train Loss: 0.2555, Validation Loss: 0.2570
Epoch [10/250], Train Loss: 0.2621, Validation Loss: 0.2599
Epoch [11/250], Train Loss: 0.2501, Validation Loss: 0.2355
Epoch [12/250], Train Loss: 0.2356, Validation Loss: 0.2344
Epoch [13/250], Train Loss: 0.2252, Validation Loss: 0.2193
Epoch [14/250], Train Loss: 0.2125, Validation Loss: 0.2234
Epoch [15/250], Train Loss: 0.2135, Validation Loss: 0.2052
Epoch [16/250], Train Loss: 0.2246, Validation Loss: 0.2255
Epoch [17/250], Train Loss: 0.2326, Validation Loss: 0.1987
Epoch [18/250], Train Loss: 0.2140, Validation Loss: 0.2091
Epoch [19/250], Train Loss: 0.2004, Validation Loss: 0.1957
Epoch [20/250], Train Loss: 0.1918, Validation Loss: 0.1696
Epoch [21/250], Train Loss: 0.1970, Validation Loss: 0.1987
Epoch [22/250], Train Loss: 0.2081, Validation Loss: 0.1682
Epoch [23/250], Train Loss: 0.1779, Validation Loss: 0.1684
Epoch [24/250], Train Loss: 0.1474, Validation Loss: 0.1520
Epoch [25/250], Train Loss: 0.1517, Validation Loss: 0.1426
Epoch [26/250], Train Loss: 0.1550, Validation Loss: 0.1350
Epoch [27/250], Train Loss: 0.1306, Validation Loss: 0.1431
Epoch [28/250], Train Loss: 0.1477, Validation Loss: 0.1284
Epoch [29/250], Train Loss: 0.1377, Validation Loss: 0.1343
Epoch [30/250], Train Loss: 0.1465, Validation Loss: 0.1432
Epoch [31/250], Train Loss: 0.1547, Validation Loss: 0.1247
Epoch [32/250], Train Loss: 0.1156, Validation Loss: 0.1151
Epoch [33/250], Train Loss: 0.1349, Validation Loss: 0.1067
Epoch [34/250], Train Loss: 0.1332, Validation Loss: 0.1195
Epoch [35/250], Train Loss: 0.1424, Validation Loss: 0.1046
Epoch [36/250], Train Loss: 0.1117, Validation Loss: 0.1317
Epoch [37/250], Train Loss: 0.1264, Validation Loss: 0.1267
Epoch [38/250], Train Loss: 0.1078, Validation Loss: 0.1026
Epoch [39/250], Train Loss: 0.1000, Validation Loss: 0.1047
Epoch [40/250], Train Loss: 0.1140, Validation Loss: 0.0975
Epoch [41/250], Train Loss: 0.1017, Validation Loss: 0.0977
Epoch [42/250], Train Loss: 0.1135, Validation Loss: 0.1094
Epoch [43/250], Train Loss: 0.1077, Validation Loss: 0.0894
Epoch [44/250], Train Loss: 0.1148, Validation Loss: 0.0943
Epoch [45/250], Train Loss: 0.0975, Validation Loss: 0.0900
Epoch [46/250], Train Loss: 0.1067, Validation Loss: 0.0940
Epoch [47/250], Train Loss: 0.0960, Validation Loss: 0.0872
Epoch [48/250], Train Loss: 0.0873, Validation Loss: 0.0870
Epoch [49/250], Train Loss: 0.0940, Validation Loss: 0.0987
Epoch [50/250], Train Loss: 0.0971, Validation Loss: 0.0842
Epoch [51/250], Train Loss: 0.0839, Validation Loss: 0.0918
Epoch [52/250], Train Loss: 0.0790, Validation Loss: 0.0826
Epoch [53/250], Train Loss: 0.1007, Validation Loss: 0.0868
Epoch [54/250], Train Loss: 0.0777, Validation Loss: 0.0879
Epoch [55/250], Train Loss: 0.0788, Validation Loss: 0.0837
Epoch [56/250], Train Loss: 0.0844, Validation Loss: 0.0844
Epoch [57/250], Train Loss: 0.0898, Validation Loss: 0.0721
Epoch [58/250], Train Loss: 0.0904, Validation Loss: 0.0823
Epoch [59/250], Train Loss: 0.0867, Validation Loss: 0.0793
Epoch [60/250], Train Loss: 0.0832, Validation Loss: 0.0745
Epoch [61/250], Train Loss: 0.0943, Validation Loss: 0.0833
Epoch [62/250], Train Loss: 0.0777, Validation Loss: 0.0800
Epoch [63/250], Train Loss: 0.0721, Validation Loss: 0.1042
Epoch [64/250], Train Loss: 0.1040, Validation Loss: 0.0675
Epoch [65/250], Train Loss: 0.0922, Validation Loss: 0.0902
Epoch [66/250], Train Loss: 0.0888, Validation Loss: 0.0842
Epoch [67/250], Train Loss: 0.0810, Validation Loss: 0.0906
Epoch [68/250], Train Loss: 0.0975, Validation Loss: 0.0807
Epoch [69/250], Train Loss: 0.0776, Validation Loss: 0.0990
Epoch [70/250], Train Loss: 0.0765, Validation Loss: 0.0853
Epoch [71/250], Train Loss: 0.0833, Validation Loss: 0.0702
Epoch [72/250], Train Loss: 0.0856, Validation Loss: 0.0781
Epoch [73/250], Train Loss: 0.0759, Validation Loss: 0.1073
Epoch [74/250], Train Loss: 0.0921, Validation Loss: 0.0727
Epoch [75/250], Train Loss: 0.0728, Validation Loss: 0.0629
Epoch [76/250], Train Loss: 0.0583, Validation Loss: 0.0692
Epoch [77/250], Train Loss: 0.0648, Validation Loss: 0.0701
Epoch [78/250], Train Loss: 0.0770, Validation Loss: 0.0665
Epoch [79/250], Train Loss: 0.0647, Validation Loss: 0.0725
Epoch [80/250], Train Loss: 0.0687, Validation Loss: 0.0661
Epoch [81/250], Train Loss: 0.0642, Validation Loss: 0.0632
Epoch [82/250], Train Loss: 0.0655, Validation Loss: 0.0587
Epoch [83/250], Train Loss: 0.0655, Validation Loss: 0.0568
Epoch [84/250], Train Loss: 0.0663, Validation Loss: 0.0703
Epoch [85/250], Train Loss: 0.0621, Validation Loss: 0.0610
Epoch [86/250], Train Loss: 0.0694, Validation Loss: 0.0662
Epoch [87/250], Train Loss: 0.0708, Validation Loss: 0.0620
Epoch [88/250], Train Loss: 0.0602, Validation Loss: 0.0670
Epoch [89/250], Train Loss: 0.0713, Validation Loss: 0.0671
Epoch [90/250], Train Loss: 0.0765, Validation Loss: 0.0559
Epoch [91/250], Train Loss: 0.0619, Validation Loss: 0.0629
Epoch [92/250], Train Loss: 0.0605, Validation Loss: 0.0623
Epoch [93/250], Train Loss: 0.0677, Validation Loss: 0.0558
Epoch [94/250], Train Loss: 0.0616, Validation Loss: 0.0600
Epoch [95/250], Train Loss: 0.0601, Validation Loss: 0.0546
Epoch [96/250], Train Loss: 0.0603, Validation Loss: 0.0557
Epoch [97/250], Train Loss: 0.0593, Validation Loss: 0.0731
Epoch [98/250], Train Loss: 0.0794, Validation Loss: 0.0597
Epoch [99/250], Train Loss: 0.0907, Validation Loss: 0.0608
Epoch [100/250], Train Loss: 0.0666, Validation Loss: 0.0734
Epoch [101/250], Train Loss: 0.0653, Validation Loss: 0.0570
Epoch [102/250], Train Loss: 0.0605, Validation Loss: 0.0515
Epoch [103/250], Train Loss: 0.0741, Validation Loss: 0.0616
Epoch [104/250], Train Loss: 0.0615, Validation Loss: 0.0584
Epoch [105/250], Train Loss: 0.0673, Validation Loss: 0.0646
Epoch [106/250], Train Loss: 0.0626, Validation Loss: 0.0573
Epoch [107/250], Train Loss: 0.0523, Validation Loss: 0.0545
Epoch [108/250], Train Loss: 0.0556, Validation Loss: 0.0541
Epoch [109/250], Train Loss: 0.0648, Validation Loss: 0.0517
Epoch [110/250], Train Loss: 0.0514, Validation Loss: 0.0493
Epoch [111/250], Train Loss: 0.0680, Validation Loss: 0.0546
Epoch [112/250], Train Loss: 0.0600, Validation Loss: 0.0711
Epoch [113/250], Train Loss: 0.0637, Validation Loss: 0.0611
Epoch [114/250], Train Loss: 0.0635, Validation Loss: 0.0578
Epoch [115/250], Train Loss: 0.0519, Validation Loss: 0.0508
Epoch [116/250], Train Loss: 0.0536, Validation Loss: 0.0439
Epoch [117/250], Train Loss: 0.0641, Validation Loss: 0.0488
Epoch [118/250], Train Loss: 0.0476, Validation Loss: 0.0611
Epoch [119/250], Train Loss: 0.0511, Validation Loss: 0.0620
Epoch [120/250], Train Loss: 0.0610, Validation Loss: 0.0530
Epoch [121/250], Train Loss: 0.0641, Validation Loss: 0.0465
Epoch [122/250], Train Loss: 0.0474, Validation Loss: 0.0554
Epoch [123/250], Train Loss: 0.0433, Validation Loss: 0.0417
Epoch [124/250], Train Loss: 0.0398, Validation Loss: 0.0593
Epoch [125/250], Train Loss: 0.0478, Validation Loss: 0.0440
Epoch [126/250], Train Loss: 0.0496, Validation Loss: 0.0417
Epoch [127/250], Train Loss: 0.0467, Validation Loss: 0.0498
Epoch [128/250], Train Loss: 0.0431, Validation Loss: 0.0475
Epoch [129/250], Train Loss: 0.0508, Validation Loss: 0.0408
Epoch [130/250], Train Loss: 0.0506, Validation Loss: 0.0482
Epoch [131/250], Train Loss: 0.0480, Validation Loss: 0.0358
Epoch [132/250], Train Loss: 0.0638, Validation Loss: 0.0443
Epoch [133/250], Train Loss: 0.0479, Validation Loss: 0.0511
Epoch [134/250], Train Loss: 0.0519, Validation Loss: 0.0648
Epoch [135/250], Train Loss: 0.0495, Validation Loss: 0.0446
Epoch [136/250], Train Loss: 0.0562, Validation Loss: 0.0453
Epoch [137/250], Train Loss: 0.0682, Validation Loss: 0.0510
Epoch [138/250], Train Loss: 0.0468, Validation Loss: 0.0565
Epoch [139/250], Train Loss: 0.0595, Validation Loss: 0.0624
Epoch [140/250], Train Loss: 0.0688, Validation Loss: 0.0451
Epoch [141/250], Train Loss: 0.0534, Validation Loss: 0.0552
Epoch [142/250], Train Loss: 0.0517, Validation Loss: 0.0620
Epoch [143/250], Train Loss: 0.0541, Validation Loss: 0.0445
Epoch [144/250], Train Loss: 0.0637, Validation Loss: 0.0440
Epoch [145/250], Train Loss: 0.0507, Validation Loss: 0.0403
Epoch [146/250], Train Loss: 0.0363, Validation Loss: 0.0437
Epoch [147/250], Train Loss: 0.0498, Validation Loss: 0.0470
Epoch [148/250], Train Loss: 0.0457, Validation Loss: 0.0316
Epoch [149/250], Train Loss: 0.0383, Validation Loss: 0.0449
Epoch [150/250], Train Loss: 0.0458, Validation Loss: 0.0547
Epoch [151/250], Train Loss: 0.0463, Validation Loss: 0.0339
Epoch [152/250], Train Loss: 0.0500, Validation Loss: 0.0423
Epoch [153/250], Train Loss: 0.0338, Validation Loss: 0.0564
Epoch [154/250], Train Loss: 0.0484, Validation Loss: 0.0439
Epoch [155/250], Train Loss: 0.0414, Validation Loss: 0.0390
Epoch [156/250], Train Loss: 0.0490, Validation Loss: 0.0401
Epoch [157/250], Train Loss: 0.0421, Validation Loss: 0.0390
Epoch [158/250], Train Loss: 0.0457, Validation Loss: 0.0440
Epoch [159/250], Train Loss: 0.0455, Validation Loss: 0.0339
Epoch [160/250], Train Loss: 0.0386, Validation Loss: 0.0369
Epoch [161/250], Train Loss: 0.0325, Validation Loss: 0.0366
Epoch [162/250], Train Loss: 0.0386, Validation Loss: 0.0566
Epoch [163/250], Train Loss: 0.0605, Validation Loss: 0.0390
Epoch [164/250], Train Loss: 0.0419, Validation Loss: 0.0439
Epoch [165/250], Train Loss: 0.0477, Validation Loss: 0.0597
Epoch [166/250], Train Loss: 0.0595, Validation Loss: 0.0420
Epoch [167/250], Train Loss: 0.0445, Validation Loss: 0.0411
Epoch [168/250], Train Loss: 0.0458, Validation Loss: 0.0302
Epoch [169/250], Train Loss: 0.0391, Validation Loss: 0.0396
Epoch [170/250], Train Loss: 0.0423, Validation Loss: 0.0317
Epoch [171/250], Train Loss: 0.0356, Validation Loss: 0.0351
Epoch [172/250], Train Loss: 0.0406, Validation Loss: 0.0350
Epoch [173/250], Train Loss: 0.0453, Validation Loss: 0.0370
Epoch [174/250], Train Loss: 0.0412, Validation Loss: 0.0441
Epoch [175/250], Train Loss: 0.0411, Validation Loss: 0.0442
Epoch [176/250], Train Loss: 0.0454, Validation Loss: 0.0476
Epoch [177/250], Train Loss: 0.0307, Validation Loss: 0.0349
Epoch [178/250], Train Loss: 0.0403, Validation Loss: 0.0371
Epoch [179/250], Train Loss: 0.0360, Validation Loss: 0.0342
Epoch [180/250], Train Loss: 0.0362, Validation Loss: 0.0364
Epoch [181/250], Train Loss: 0.0351, Validation Loss: 0.0359
Epoch [182/250], Train Loss: 0.0346, Validation Loss: 0.0287
Epoch [183/250], Train Loss: 0.0395, Validation Loss: 0.0322
Epoch [184/250], Train Loss: 0.0420, Validation Loss: 0.0309
Epoch [185/250], Train Loss: 0.0296, Validation Loss: 0.0351
Epoch [186/250], Train Loss: 0.0402, Validation Loss: 0.0300
Epoch [187/250], Train Loss: 0.0375, Validation Loss: 0.0391
Epoch [188/250], Train Loss: 0.0349, Validation Loss: 0.0321
Epoch [189/250], Train Loss: 0.0337, Validation Loss: 0.0347
Epoch [190/250], Train Loss: 0.0372, Validation Loss: 0.0452
Epoch [191/250], Train Loss: 0.0436, Validation Loss: 0.0242
Epoch [192/250], Train Loss: 0.0418, Validation Loss: 0.0339
Epoch [193/250], Train Loss: 0.0368, Validation Loss: 0.0313
Epoch [194/250], Train Loss: 0.0397, Validation Loss: 0.0283
Epoch [195/250], Train Loss: 0.0320, Validation Loss: 0.0369
Epoch [196/250], Train Loss: 0.0473, Validation Loss: 0.0423
Epoch [197/250], Train Loss: 0.0362, Validation Loss: 0.0395
Epoch [198/250], Train Loss: 0.0334, Validation Loss: 0.0312
Epoch [199/250], Train Loss: 0.0382, Validation Loss: 0.0408
Epoch [200/250], Train Loss: 0.0360, Validation Loss: 0.0346
Epoch [201/250], Train Loss: 0.0330, Validation Loss: 0.0372
Epoch [202/250], Train Loss: 0.0464, Validation Loss: 0.0299
Epoch [203/250], Train Loss: 0.0378, Validation Loss: 0.0389
Epoch [204/250], Train Loss: 0.0340, Validation Loss: 0.0346
Epoch [205/250], Train Loss: 0.0282, Validation Loss: 0.0360
Epoch [206/250], Train Loss: 0.0363, Validation Loss: 0.0356
Epoch [207/250], Train Loss: 0.0298, Validation Loss: 0.0323
Epoch [208/250], Train Loss: 0.0388, Validation Loss: 0.0350
Epoch [209/250], Train Loss: 0.0316, Validation Loss: 0.0353
Epoch [210/250], Train Loss: 0.0301, Validation Loss: 0.0358
Epoch [211/250], Train Loss: 0.0316, Validation Loss: 0.0370
Epoch [212/250], Train Loss: 0.0354, Validation Loss: 0.0317
Epoch [213/250], Train Loss: 0.0317, Validation Loss: 0.0260
Epoch [214/250], Train Loss: 0.0302, Validation Loss: 0.0368
Epoch [215/250], Train Loss: 0.0312, Validation Loss: 0.0266
Epoch [216/250], Train Loss: 0.0270, Validation Loss: 0.0278
Epoch [217/250], Train Loss: 0.0336, Validation Loss: 0.0261
Epoch [218/250], Train Loss: 0.0344, Validation Loss: 0.0342
Epoch [219/250], Train Loss: 0.0291, Validation Loss: 0.0370
Epoch [220/250], Train Loss: 0.0346, Validation Loss: 0.0478
Epoch [221/250], Train Loss: 0.0376, Validation Loss: 0.0396
Epoch [222/250], Train Loss: 0.0428, Validation Loss: 0.0334
Epoch [223/250], Train Loss: 0.0301, Validation Loss: 0.0308
Epoch [224/250], Train Loss: 0.0352, Validation Loss: 0.0311
Epoch [225/250], Train Loss: 0.0314, Validation Loss: 0.0206
Epoch [226/250], Train Loss: 0.0273, Validation Loss: 0.0344
Epoch [227/250], Train Loss: 0.0290, Validation Loss: 0.0274
Epoch [228/250], Train Loss: 0.0287, Validation Loss: 0.0300
Epoch [229/250], Train Loss: 0.0334, Validation Loss: 0.0318
Epoch [230/250], Train Loss: 0.0302, Validation Loss: 0.0267
Epoch [231/250], Train Loss: 0.0326, Validation Loss: 0.0265
Epoch [232/250], Train Loss: 0.0276, Validation Loss: 0.0260
Epoch [233/250], Train Loss: 0.0229, Validation Loss: 0.0288
Epoch [234/250], Train Loss: 0.0315, Validation Loss: 0.0253
Epoch [235/250], Train Loss: 0.0355, Validation Loss: 0.0371
Epoch [236/250], Train Loss: 0.0254, Validation Loss: 0.0219
Epoch [237/250], Train Loss: 0.0238, Validation Loss: 0.0287
Epoch [238/250], Train Loss: 0.0266, Validation Loss: 0.0292
Epoch [239/250], Train Loss: 0.0246, Validation Loss: 0.0328
Epoch [240/250], Train Loss: 0.0363, Validation Loss: 0.0240
Epoch [241/250], Train Loss: 0.0357, Validation Loss: 0.0249
Epoch [242/250], Train Loss: 0.0281, Validation Loss: 0.0306
Epoch [243/250], Train Loss: 0.0271, Validation Loss: 0.0393
Epoch [244/250], Train Loss: 0.0275, Validation Loss: 0.0318
Epoch [245/250], Train Loss: 0.0265, Validation Loss: 0.0307
Epoch [246/250], Train Loss: 0.0248, Validation Loss: 0.0316
Epoch [247/250], Train Loss: 0.0278, Validation Loss: 0.0223
Epoch [248/250], Train Loss: 0.0261, Validation Loss: 0.0179
Epoch [249/250], Train Loss: 0.0223, Validation Loss: 0.0266
Epoch [250/250], Train Loss: 0.0260, Validation Loss: 0.0247

Finished Training in 80.8

Noise Sigma:  1.005
Creating datasets...
Start training...
Epoch [1/250], Train Loss: 0.8063, Validation Loss: 0.4991
Epoch [2/250], Train Loss: 0.4084, Validation Loss: 0.4559
Epoch [3/250], Train Loss: 0.4046, Validation Loss: 0.3334
Epoch [4/250], Train Loss: 0.3060, Validation Loss: 0.3032
Epoch [5/250], Train Loss: 0.2888, Validation Loss: 0.3117
Epoch [6/250], Train Loss: 0.3157, Validation Loss: 0.2820
Epoch [7/250], Train Loss: 0.3237, Validation Loss: 0.2878
Epoch [8/250], Train Loss: 0.2865, Validation Loss: 0.2828
Epoch [9/250], Train Loss: 0.3324, Validation Loss: 0.2774
Epoch [10/250], Train Loss: 0.3053, Validation Loss: 0.3122
Epoch [11/250], Train Loss: 0.3112, Validation Loss: 0.2508
Epoch [12/250], Train Loss: 0.2463, Validation Loss: 0.2688
Epoch [13/250], Train Loss: 0.2531, Validation Loss: 0.2481
Epoch [14/250], Train Loss: 0.2426, Validation Loss: 0.2359
Epoch [15/250], Train Loss: 0.2467, Validation Loss: 0.2583
Epoch [16/250], Train Loss: 0.2347, Validation Loss: 0.2382
Epoch [17/250], Train Loss: 0.2517, Validation Loss: 0.2297
Epoch [18/250], Train Loss: 0.2576, Validation Loss: 0.2129
Epoch [19/250], Train Loss: 0.2184, Validation Loss: 0.2428
Epoch [20/250], Train Loss: 0.2324, Validation Loss: 0.2137
Epoch [21/250], Train Loss: 0.2104, Validation Loss: 0.2049
Epoch [22/250], Train Loss: 0.2356, Validation Loss: 0.1957
Epoch [23/250], Train Loss: 0.2115, Validation Loss: 0.1952
Epoch [24/250], Train Loss: 0.2282, Validation Loss: 0.1984
Epoch [25/250], Train Loss: 0.2378, Validation Loss: 0.2090
Epoch [26/250], Train Loss: 0.2082, Validation Loss: 0.2205
Epoch [27/250], Train Loss: 0.2239, Validation Loss: 0.2036
Epoch [28/250], Train Loss: 0.2114, Validation Loss: 0.1969
Epoch [29/250], Train Loss: 0.2303, Validation Loss: 0.2283
Epoch [30/250], Train Loss: 0.2158, Validation Loss: 0.1960
Epoch [31/250], Train Loss: 0.2014, Validation Loss: 0.2479
Epoch [32/250], Train Loss: 0.2193, Validation Loss: 0.2034
Epoch [33/250], Train Loss: 0.2188, Validation Loss: 0.2136
Epoch [34/250], Train Loss: 0.2219, Validation Loss: 0.1831
Epoch [35/250], Train Loss: 0.2128, Validation Loss: 0.1941
Epoch [36/250], Train Loss: 0.2061, Validation Loss: 0.2157
Epoch [37/250], Train Loss: 0.2337, Validation Loss: 0.1986
Epoch [38/250], Train Loss: 0.1913, Validation Loss: 0.1911
Epoch [39/250], Train Loss: 0.2390, Validation Loss: 0.2331
Epoch [40/250], Train Loss: 0.2764, Validation Loss: 0.1757
Epoch [41/250], Train Loss: 0.2363, Validation Loss: 0.2068
Epoch [42/250], Train Loss: 0.2146, Validation Loss: 0.2490
Epoch [43/250], Train Loss: 0.1895, Validation Loss: 0.2155
Epoch [44/250], Train Loss: 0.2082, Validation Loss: 0.2671
Epoch [45/250], Train Loss: 0.2741, Validation Loss: 0.1991
Epoch [46/250], Train Loss: 0.2074, Validation Loss: 0.1911
Epoch [47/250], Train Loss: 0.2064, Validation Loss: 0.1865
Epoch [48/250], Train Loss: 0.2272, Validation Loss: 0.2020
Epoch [49/250], Train Loss: 0.2077, Validation Loss: 0.1810
Epoch [50/250], Train Loss: 0.2067, Validation Loss: 0.1706
Epoch [51/250], Train Loss: 0.1797, Validation Loss: 0.1854
Epoch [52/250], Train Loss: 0.1800, Validation Loss: 0.1869
Epoch [53/250], Train Loss: 0.1868, Validation Loss: 0.1868
Epoch [54/250], Train Loss: 0.1905, Validation Loss: 0.1912
Epoch [55/250], Train Loss: 0.1833, Validation Loss: 0.1941
Epoch [56/250], Train Loss: 0.1870, Validation Loss: 0.1879
Epoch [57/250], Train Loss: 0.2081, Validation Loss: 0.1681
Epoch [58/250], Train Loss: 0.1921, Validation Loss: 0.2320
Epoch [59/250], Train Loss: 0.2240, Validation Loss: 0.1747
Epoch [60/250], Train Loss: 0.1973, Validation Loss: 0.1824
Epoch [61/250], Train Loss: 0.1902, Validation Loss: 0.1755
Epoch [62/250], Train Loss: 0.1931, Validation Loss: 0.1805
Epoch [63/250], Train Loss: 0.1958, Validation Loss: 0.1619
Epoch [64/250], Train Loss: 0.1866, Validation Loss: 0.1786
Epoch [65/250], Train Loss: 0.1938, Validation Loss: 0.1658
Epoch [66/250], Train Loss: 0.1831, Validation Loss: 0.2078
Epoch [67/250], Train Loss: 0.1857, Validation Loss: 0.1842
Epoch [68/250], Train Loss: 0.1760, Validation Loss: 0.2390
Epoch [69/250], Train Loss: 0.2651, Validation Loss: 0.1724
Epoch [70/250], Train Loss: 0.1900, Validation Loss: 0.1789
Epoch [71/250], Train Loss: 0.1757, Validation Loss: 0.2170
Epoch [72/250], Train Loss: 0.2079, Validation Loss: 0.1736
Epoch [73/250], Train Loss: 0.1753, Validation Loss: 0.1704
Epoch [74/250], Train Loss: 0.1840, Validation Loss: 0.2077
Epoch [75/250], Train Loss: 0.2225, Validation Loss: 0.1728
Epoch [76/250], Train Loss: 0.1839, Validation Loss: 0.1812
Epoch [77/250], Train Loss: 0.1907, Validation Loss: 0.1727
Epoch [78/250], Train Loss: 0.1827, Validation Loss: 0.2258
Epoch [79/250], Train Loss: 0.2009, Validation Loss: 0.1666
Epoch [80/250], Train Loss: 0.2037, Validation Loss: 0.1600
Epoch [81/250], Train Loss: 0.1856, Validation Loss: 0.1708
Epoch [82/250], Train Loss: 0.2110, Validation Loss: 0.1518
Epoch [83/250], Train Loss: 0.1572, Validation Loss: 0.1506
Epoch [84/250], Train Loss: 0.1666, Validation Loss: 0.1614
Epoch [85/250], Train Loss: 0.1588, Validation Loss: 0.1691
Epoch [86/250], Train Loss: 0.1686, Validation Loss: 0.1648
Epoch [87/250], Train Loss: 0.1670, Validation Loss: 0.1452
Epoch [88/250], Train Loss: 0.1499, Validation Loss: 0.1546
Epoch [89/250], Train Loss: 0.1593, Validation Loss: 0.1495
Epoch [90/250], Train Loss: 0.1702, Validation Loss: 0.1700
Epoch [91/250], Train Loss: 0.1650, Validation Loss: 0.1537
Epoch [92/250], Train Loss: 0.1582, Validation Loss: 0.1698
Epoch [93/250], Train Loss: 0.2075, Validation Loss: 0.1540
Epoch [94/250], Train Loss: 0.1532, Validation Loss: 0.1774
Epoch [95/250], Train Loss: 0.1704, Validation Loss: 0.1485
Epoch [96/250], Train Loss: 0.1773, Validation Loss: 0.1434
Epoch [97/250], Train Loss: 0.1560, Validation Loss: 0.1497
Epoch [98/250], Train Loss: 0.1532, Validation Loss: 0.1599
Epoch [99/250], Train Loss: 0.1828, Validation Loss: 0.1567
Epoch [100/250], Train Loss: 0.1828, Validation Loss: 0.1641
Epoch [101/250], Train Loss: 0.1686, Validation Loss: 0.1507
Epoch [102/250], Train Loss: 0.1594, Validation Loss: 0.1368
Epoch [103/250], Train Loss: 0.1510, Validation Loss: 0.1491
Epoch [104/250], Train Loss: 0.1577, Validation Loss: 0.1632
Epoch [105/250], Train Loss: 0.1612, Validation Loss: 0.1370
Epoch [106/250], Train Loss: 0.1679, Validation Loss: 0.1729
Epoch [107/250], Train Loss: 0.1644, Validation Loss: 0.1352
Epoch [108/250], Train Loss: 0.1769, Validation Loss: 0.1674
Epoch [109/250], Train Loss: 0.1673, Validation Loss: 0.1384
Epoch [110/250], Train Loss: 0.1505, Validation Loss: 0.1582
Epoch [111/250], Train Loss: 0.1558, Validation Loss: 0.1428
Epoch [112/250], Train Loss: 0.1450, Validation Loss: 0.1359
Epoch [113/250], Train Loss: 0.1841, Validation Loss: 0.1510
Epoch [114/250], Train Loss: 0.1582, Validation Loss: 0.1346
Epoch [115/250], Train Loss: 0.1381, Validation Loss: 0.1548
Epoch [116/250], Train Loss: 0.1892, Validation Loss: 0.1636
Epoch [117/250], Train Loss: 0.1779, Validation Loss: 0.1686
Epoch [118/250], Train Loss: 0.1905, Validation Loss: 0.1334
Epoch [119/250], Train Loss: 0.1623, Validation Loss: 0.1564
Epoch [120/250], Train Loss: 0.1771, Validation Loss: 0.1540
Epoch [121/250], Train Loss: 0.1499, Validation Loss: 0.1366
Epoch [122/250], Train Loss: 0.1667, Validation Loss: 0.1772
Epoch [123/250], Train Loss: 0.1516, Validation Loss: 0.1744
Epoch [124/250], Train Loss: 0.1684, Validation Loss: 0.1413
Epoch [125/250], Train Loss: 0.1630, Validation Loss: 0.1361
Epoch [126/250], Train Loss: 0.1559, Validation Loss: 0.1636
Epoch [127/250], Train Loss: 0.1544, Validation Loss: 0.1564
Epoch [128/250], Train Loss: 0.1524, Validation Loss: 0.1790
Epoch [129/250], Train Loss: 0.1676, Validation Loss: 0.1569
Epoch [130/250], Train Loss: 0.1791, Validation Loss: 0.1380
Epoch [131/250], Train Loss: 0.1411, Validation Loss: 0.1315
Epoch [132/250], Train Loss: 0.1539, Validation Loss: 0.1613
Epoch [133/250], Train Loss: 0.1597, Validation Loss: 0.1603
Epoch [134/250], Train Loss: 0.1590, Validation Loss: 0.1528
Epoch [135/250], Train Loss: 0.1571, Validation Loss: 0.1335
Epoch [136/250], Train Loss: 0.1676, Validation Loss: 0.1460
Epoch [137/250], Train Loss: 0.1562, Validation Loss: 0.1456
Epoch [138/250], Train Loss: 0.1668, Validation Loss: 0.1365
Epoch [139/250], Train Loss: 0.1555, Validation Loss: 0.1402
Epoch [140/250], Train Loss: 0.1379, Validation Loss: 0.1711
Epoch [141/250], Train Loss: 0.1650, Validation Loss: 0.1607
Epoch [142/250], Train Loss: 0.1563, Validation Loss: 0.1699
Epoch [143/250], Train Loss: 0.1594, Validation Loss: 0.1219
Epoch [144/250], Train Loss: 0.1556, Validation Loss: 0.1450
Epoch [145/250], Train Loss: 0.1599, Validation Loss: 0.1483
Epoch [146/250], Train Loss: 0.1555, Validation Loss: 0.1476
Epoch [147/250], Train Loss: 0.1709, Validation Loss: 0.1220
Epoch [148/250], Train Loss: 0.1612, Validation Loss: 0.1323
Epoch [149/250], Train Loss: 0.1504, Validation Loss: 0.1337
Epoch [150/250], Train Loss: 0.1446, Validation Loss: 0.1825
Epoch [151/250], Train Loss: 0.1610, Validation Loss: 0.1491
Epoch [152/250], Train Loss: 0.1398, Validation Loss: 0.1367
Epoch [153/250], Train Loss: 0.1474, Validation Loss: 0.1449
Epoch [154/250], Train Loss: 0.1396, Validation Loss: 0.1399
Epoch [155/250], Train Loss: 0.1509, Validation Loss: 0.1455
Epoch [156/250], Train Loss: 0.1475, Validation Loss: 0.1375
Epoch [157/250], Train Loss: 0.1362, Validation Loss: 0.1364
Epoch [158/250], Train Loss: 0.1456, Validation Loss: 0.1531
Epoch [159/250], Train Loss: 0.1454, Validation Loss: 0.1376
Epoch [160/250], Train Loss: 0.1514, Validation Loss: 0.1416
Epoch [161/250], Train Loss: 0.1594, Validation Loss: 0.1472
Epoch [162/250], Train Loss: 0.1495, Validation Loss: 0.1362
Epoch [163/250], Train Loss: 0.1456, Validation Loss: 0.1350
Epoch [164/250], Train Loss: 0.1609, Validation Loss: 0.1412
Epoch [165/250], Train Loss: 0.1305, Validation Loss: 0.1336
Epoch [166/250], Train Loss: 0.1434, Validation Loss: 0.1407
Epoch [167/250], Train Loss: 0.1138, Validation Loss: 0.1484
Epoch [168/250], Train Loss: 0.1445, Validation Loss: 0.1201
Epoch [169/250], Train Loss: 0.1337, Validation Loss: 0.1351
Epoch [170/250], Train Loss: 0.1115, Validation Loss: 0.1394
Epoch [171/250], Train Loss: 0.1205, Validation Loss: 0.1132
Epoch [172/250], Train Loss: 0.1435, Validation Loss: 0.1245
Epoch [173/250], Train Loss: 0.1434, Validation Loss: 0.2152
Epoch [174/250], Train Loss: 0.1931, Validation Loss: 0.1260
Epoch [175/250], Train Loss: 0.1497, Validation Loss: 0.1174
Epoch [176/250], Train Loss: 0.1262, Validation Loss: 0.1365
Epoch [177/250], Train Loss: 0.1301, Validation Loss: 0.1480
Epoch [178/250], Train Loss: 0.1340, Validation Loss: 0.1454
Epoch [179/250], Train Loss: 0.1319, Validation Loss: 0.1590
Epoch [180/250], Train Loss: 0.1501, Validation Loss: 0.1531
Epoch [181/250], Train Loss: 0.1323, Validation Loss: 0.1314
Epoch [182/250], Train Loss: 0.1393, Validation Loss: 0.1919
Epoch [183/250], Train Loss: 0.1537, Validation Loss: 0.1385
Epoch [184/250], Train Loss: 0.1973, Validation Loss: 0.1287
Epoch [185/250], Train Loss: 0.1647, Validation Loss: 0.1835
Epoch [186/250], Train Loss: 0.1691, Validation Loss: 0.1909
Epoch [187/250], Train Loss: 0.1799, Validation Loss: 0.1893
Epoch [188/250], Train Loss: 0.2000, Validation Loss: 0.1405
Epoch [189/250], Train Loss: 0.1712, Validation Loss: 0.1473
Epoch [190/250], Train Loss: 0.1317, Validation Loss: 0.1483
Epoch [191/250], Train Loss: 0.1300, Validation Loss: 0.1345
Epoch [192/250], Train Loss: 0.1282, Validation Loss: 0.1413
Epoch [193/250], Train Loss: 0.1415, Validation Loss: 0.1274
Epoch [194/250], Train Loss: 0.1489, Validation Loss: 0.1104
Epoch [195/250], Train Loss: 0.1453, Validation Loss: 0.1404
Epoch [196/250], Train Loss: 0.1358, Validation Loss: 0.1329
Epoch [197/250], Train Loss: 0.1169, Validation Loss: 0.1274
Epoch [198/250], Train Loss: 0.1351, Validation Loss: 0.1087
Epoch [199/250], Train Loss: 0.1406, Validation Loss: 0.1302
Epoch [200/250], Train Loss: 0.1486, Validation Loss: 0.1433
Epoch [201/250], Train Loss: 0.1337, Validation Loss: 0.1581
Epoch [202/250], Train Loss: 0.1683, Validation Loss: 0.1575
Epoch [203/250], Train Loss: 0.1557, Validation Loss: 0.1276
Epoch [204/250], Train Loss: 0.1542, Validation Loss: 0.1451
Epoch [205/250], Train Loss: 0.1463, Validation Loss: 0.1372
Epoch [206/250], Train Loss: 0.1324, Validation Loss: 0.1187
Epoch [207/250], Train Loss: 0.1347, Validation Loss: 0.1445
Epoch [208/250], Train Loss: 0.1608, Validation Loss: 0.1389
Epoch [209/250], Train Loss: 0.1491, Validation Loss: 0.1460
Epoch [210/250], Train Loss: 0.1664, Validation Loss: 0.1205
Epoch [211/250], Train Loss: 0.1659, Validation Loss: 0.1224
Epoch [212/250], Train Loss: 0.1449, Validation Loss: 0.1800
Epoch [213/250], Train Loss: 0.1757, Validation Loss: 0.1258
Epoch [214/250], Train Loss: 0.1619, Validation Loss: 0.1275
Epoch [215/250], Train Loss: 0.1457, Validation Loss: 0.1404
Epoch [216/250], Train Loss: 0.1563, Validation Loss: 0.1472
Epoch [217/250], Train Loss: 0.1481, Validation Loss: 0.1309
Epoch [218/250], Train Loss: 0.1394, Validation Loss: 0.1137
Epoch [219/250], Train Loss: 0.1428, Validation Loss: 0.1285
Epoch [220/250], Train Loss: 0.1486, Validation Loss: 0.1295
Epoch [221/250], Train Loss: 0.1348, Validation Loss: 0.1184
Epoch [222/250], Train Loss: 0.1294, Validation Loss: 0.1122
Epoch [223/250], Train Loss: 0.1244, Validation Loss: 0.1508
Epoch [224/250], Train Loss: 0.1226, Validation Loss: 0.1332
Epoch [225/250], Train Loss: 0.1315, Validation Loss: 0.1205
Epoch [226/250], Train Loss: 0.1292, Validation Loss: 0.1186
Epoch [227/250], Train Loss: 0.1416, Validation Loss: 0.1316
Epoch [228/250], Train Loss: 0.1398, Validation Loss: 0.1472
Epoch [229/250], Train Loss: 0.1335, Validation Loss: 0.1275
Epoch [230/250], Train Loss: 0.1271, Validation Loss: 0.1220
Epoch [231/250], Train Loss: 0.1225, Validation Loss: 0.1325
Epoch [232/250], Train Loss: 0.1171, Validation Loss: 0.1361
Epoch [233/250], Train Loss: 0.1353, Validation Loss: 0.1309
Epoch [234/250], Train Loss: 0.1317, Validation Loss: 0.1233
Epoch [235/250], Train Loss: 0.1191, Validation Loss: 0.1278
Epoch [236/250], Train Loss: 0.1247, Validation Loss: 0.1194
Epoch [237/250], Train Loss: 0.1579, Validation Loss: 0.1239
Epoch [238/250], Train Loss: 0.1302, Validation Loss: 0.1257
Epoch [239/250], Train Loss: 0.1228, Validation Loss: 0.1486
Epoch [240/250], Train Loss: 0.1242, Validation Loss: 0.1388
Epoch [241/250], Train Loss: 0.1241, Validation Loss: 0.1223
Epoch [242/250], Train Loss: 0.1327, Validation Loss: 0.1189
Epoch [243/250], Train Loss: 0.1480, Validation Loss: 0.1304
Epoch [244/250], Train Loss: 0.1588, Validation Loss: 0.1349
Epoch [245/250], Train Loss: 0.1299, Validation Loss: 0.1591
Epoch [246/250], Train Loss: 0.1320, Validation Loss: 0.1214
Epoch [247/250], Train Loss: 0.1386, Validation Loss: 0.1092
Epoch [248/250], Train Loss: 0.1431, Validation Loss: 0.1402
Epoch [249/250], Train Loss: 0.1458, Validation Loss: 0.1321
Epoch [250/250], Train Loss: 0.1334, Validation Loss: 0.1234

Finished Training in 80.7

Noise Sigma:  1.5025
Creating datasets...
Start training...
Epoch [1/250], Train Loss: 0.5379, Validation Loss: 0.4731
Epoch [2/250], Train Loss: 0.3641, Validation Loss: 0.4223
Epoch [3/250], Train Loss: 0.3736, Validation Loss: 0.3651
Epoch [4/250], Train Loss: 0.3622, Validation Loss: 0.3264
Epoch [5/250], Train Loss: 0.3323, Validation Loss: 0.3381
Epoch [6/250], Train Loss: 0.3462, Validation Loss: 0.3241
Epoch [7/250], Train Loss: 0.3223, Validation Loss: 0.3074
Epoch [8/250], Train Loss: 0.3319, Validation Loss: 0.2960
Epoch [9/250], Train Loss: 0.2941, Validation Loss: 0.3155
Epoch [10/250], Train Loss: 0.2996, Validation Loss: 0.3082
Epoch [11/250], Train Loss: 0.3219, Validation Loss: 0.2940
Epoch [12/250], Train Loss: 0.3013, Validation Loss: 0.2655
Epoch [13/250], Train Loss: 0.2860, Validation Loss: 0.2909
Epoch [14/250], Train Loss: 0.2943, Validation Loss: 0.2843
Epoch [15/250], Train Loss: 0.3019, Validation Loss: 0.2869
Epoch [16/250], Train Loss: 0.2952, Validation Loss: 0.2540
Epoch [17/250], Train Loss: 0.2638, Validation Loss: 0.2829
Epoch [18/250], Train Loss: 0.2758, Validation Loss: 0.2583
Epoch [19/250], Train Loss: 0.2769, Validation Loss: 0.2796
Epoch [20/250], Train Loss: 0.2801, Validation Loss: 0.2896
Epoch [21/250], Train Loss: 0.2598, Validation Loss: 0.2659
Epoch [22/250], Train Loss: 0.2824, Validation Loss: 0.2604
Epoch [23/250], Train Loss: 0.2818, Validation Loss: 0.2636
Epoch [24/250], Train Loss: 0.2646, Validation Loss: 0.2471
Epoch [25/250], Train Loss: 0.2458, Validation Loss: 0.2575
Epoch [26/250], Train Loss: 0.2549, Validation Loss: 0.2580
Epoch [27/250], Train Loss: 0.2737, Validation Loss: 0.2648
Epoch [28/250], Train Loss: 0.2517, Validation Loss: 0.2413
Epoch [29/250], Train Loss: 0.2355, Validation Loss: 0.2685
Epoch [30/250], Train Loss: 0.2764, Validation Loss: 0.2769
Epoch [31/250], Train Loss: 0.3014, Validation Loss: 0.2456
Epoch [32/250], Train Loss: 0.2762, Validation Loss: 0.2523
Epoch [33/250], Train Loss: 0.2690, Validation Loss: 0.2866
Epoch [34/250], Train Loss: 0.2862, Validation Loss: 0.2524
Epoch [35/250], Train Loss: 0.2535, Validation Loss: 0.2426
Epoch [36/250], Train Loss: 0.2682, Validation Loss: 0.2312
Epoch [37/250], Train Loss: 0.2599, Validation Loss: 0.2803
Epoch [38/250], Train Loss: 0.2447, Validation Loss: 0.2909
Epoch [39/250], Train Loss: 0.2913, Validation Loss: 0.2787
Epoch [40/250], Train Loss: 0.2429, Validation Loss: 0.2686
Epoch [41/250], Train Loss: 0.2393, Validation Loss: 0.2297
Epoch [42/250], Train Loss: 0.2726, Validation Loss: 0.2361
Epoch [43/250], Train Loss: 0.2629, Validation Loss: 0.2661
Epoch [44/250], Train Loss: 0.2440, Validation Loss: 0.2418
Epoch [45/250], Train Loss: 0.2530, Validation Loss: 0.2630
Epoch [46/250], Train Loss: 0.2314, Validation Loss: 0.2662
Epoch [47/250], Train Loss: 0.2678, Validation Loss: 0.2441
Epoch [48/250], Train Loss: 0.2429, Validation Loss: 0.2326
Epoch [49/250], Train Loss: 0.2166, Validation Loss: 0.2570
Epoch [50/250], Train Loss: 0.2576, Validation Loss: 0.2363
Epoch [51/250], Train Loss: 0.2427, Validation Loss: 0.2603
Epoch [52/250], Train Loss: 0.2605, Validation Loss: 0.2359
Epoch [53/250], Train Loss: 0.2533, Validation Loss: 0.2439
Epoch [54/250], Train Loss: 0.2116, Validation Loss: 0.2543
Epoch [55/250], Train Loss: 0.2442, Validation Loss: 0.2525
Epoch [56/250], Train Loss: 0.2242, Validation Loss: 0.2373
Epoch [57/250], Train Loss: 0.2477, Validation Loss: 0.2063
Epoch [58/250], Train Loss: 0.2345, Validation Loss: 0.2294
Epoch [59/250], Train Loss: 0.2507, Validation Loss: 0.2744
Epoch [60/250], Train Loss: 0.2758, Validation Loss: 0.3004
Epoch [61/250], Train Loss: 0.3588, Validation Loss: 0.2249
Epoch [62/250], Train Loss: 0.3017, Validation Loss: 0.2779
Epoch [63/250], Train Loss: 0.2450, Validation Loss: 0.3021
Epoch [64/250], Train Loss: 0.3012, Validation Loss: 0.2358
Epoch [65/250], Train Loss: 0.2891, Validation Loss: 0.2902
Epoch [66/250], Train Loss: 0.2330, Validation Loss: 0.2450
Epoch [67/250], Train Loss: 0.2550, Validation Loss: 0.2445
Epoch [68/250], Train Loss: 0.2470, Validation Loss: 0.2408
Epoch [69/250], Train Loss: 0.2124, Validation Loss: 0.2370
Epoch [70/250], Train Loss: 0.2428, Validation Loss: 0.2266
Epoch [71/250], Train Loss: 0.2412, Validation Loss: 0.2482
Epoch [72/250], Train Loss: 0.2403, Validation Loss: 0.2232
Epoch [73/250], Train Loss: 0.2272, Validation Loss: 0.2330
Epoch [74/250], Train Loss: 0.2317, Validation Loss: 0.2356
Epoch [75/250], Train Loss: 0.2339, Validation Loss: 0.2306
Epoch [76/250], Train Loss: 0.2433, Validation Loss: 0.2211
Epoch [77/250], Train Loss: 0.2403, Validation Loss: 0.2127
Epoch [78/250], Train Loss: 0.2363, Validation Loss: 0.2538
Epoch [79/250], Train Loss: 0.2511, Validation Loss: 0.2267
Epoch [80/250], Train Loss: 0.2354, Validation Loss: 0.2499
Epoch [81/250], Train Loss: 0.2159, Validation Loss: 0.2730
Epoch [82/250], Train Loss: 0.2516, Validation Loss: 0.2212
Epoch [83/250], Train Loss: 0.2758, Validation Loss: 0.2632
Epoch [84/250], Train Loss: 0.2714, Validation Loss: 0.2863
Epoch [85/250], Train Loss: 0.2399, Validation Loss: 0.2503
Epoch [86/250], Train Loss: 0.2403, Validation Loss: 0.2431
Epoch [87/250], Train Loss: 0.2364, Validation Loss: 0.2287
Epoch [88/250], Train Loss: 0.2383, Validation Loss: 0.2221
Epoch [89/250], Train Loss: 0.1954, Validation Loss: 0.2263
Epoch [90/250], Train Loss: 0.2166, Validation Loss: 0.2394
Epoch [91/250], Train Loss: 0.2578, Validation Loss: 0.2261
Epoch [92/250], Train Loss: 0.2204, Validation Loss: 0.2365
Epoch [93/250], Train Loss: 0.2378, Validation Loss: 0.2162
Epoch [94/250], Train Loss: 0.2126, Validation Loss: 0.2235
Epoch [95/250], Train Loss: 0.2178, Validation Loss: 0.1999
Epoch [96/250], Train Loss: 0.2229, Validation Loss: 0.2059
Epoch [97/250], Train Loss: 0.2285, Validation Loss: 0.2202
Epoch [98/250], Train Loss: 0.2037, Validation Loss: 0.2128
Epoch [99/250], Train Loss: 0.1943, Validation Loss: 0.2154
Epoch [100/250], Train Loss: 0.2155, Validation Loss: 0.2178
Epoch [101/250], Train Loss: 0.2147, Validation Loss: 0.2104
Epoch [102/250], Train Loss: 0.2173, Validation Loss: 0.1840
Epoch [103/250], Train Loss: 0.2151, Validation Loss: 0.2788
Epoch [104/250], Train Loss: 0.2383, Validation Loss: 0.2178
Epoch [105/250], Train Loss: 0.2204, Validation Loss: 0.2228
Epoch [106/250], Train Loss: 0.2233, Validation Loss: 0.2744
Epoch [107/250], Train Loss: 0.2657, Validation Loss: 0.2292
Epoch [108/250], Train Loss: 0.2280, Validation Loss: 0.2184
Epoch [109/250], Train Loss: 0.2114, Validation Loss: 0.2431
Epoch [110/250], Train Loss: 0.2276, Validation Loss: 0.2430
Epoch [111/250], Train Loss: 0.2433, Validation Loss: 0.2074
Epoch [112/250], Train Loss: 0.2121, Validation Loss: 0.2304
Epoch [113/250], Train Loss: 0.2291, Validation Loss: 0.1989
Epoch [114/250], Train Loss: 0.2106, Validation Loss: 0.2083
Epoch [115/250], Train Loss: 0.1931, Validation Loss: 0.2188
Epoch [116/250], Train Loss: 0.2240, Validation Loss: 0.2043
Epoch [117/250], Train Loss: 0.2230, Validation Loss: 0.2238
Epoch [118/250], Train Loss: 0.2278, Validation Loss: 0.2017
Epoch [119/250], Train Loss: 0.2236, Validation Loss: 0.2102
Epoch [120/250], Train Loss: 0.1983, Validation Loss: 0.2467
Epoch [121/250], Train Loss: 0.2309, Validation Loss: 0.2127
Epoch [122/250], Train Loss: 0.2065, Validation Loss: 0.2259
Epoch [123/250], Train Loss: 0.2331, Validation Loss: 0.2268
Epoch [124/250], Train Loss: 0.2037, Validation Loss: 0.1940
Epoch [125/250], Train Loss: 0.2270, Validation Loss: 0.1988
Epoch [126/250], Train Loss: 0.2009, Validation Loss: 0.2073
Epoch [127/250], Train Loss: 0.1866, Validation Loss: 0.1860
Epoch [128/250], Train Loss: 0.2446, Validation Loss: 0.2002
Epoch [129/250], Train Loss: 0.2318, Validation Loss: 0.2404
Epoch [130/250], Train Loss: 0.2366, Validation Loss: 0.2515
Epoch [131/250], Train Loss: 0.2272, Validation Loss: 0.2754
Epoch [132/250], Train Loss: 0.2677, Validation Loss: 0.2561
Epoch [133/250], Train Loss: 0.2549, Validation Loss: 0.1984
Epoch [134/250], Train Loss: 0.2336, Validation Loss: 0.2198
Epoch [135/250], Train Loss: 0.2203, Validation Loss: 0.2227
Epoch [136/250], Train Loss: 0.2158, Validation Loss: 0.2048
Epoch [137/250], Train Loss: 0.2058, Validation Loss: 0.2113
Epoch [138/250], Train Loss: 0.2398, Validation Loss: 0.1972
Epoch [139/250], Train Loss: 0.2299, Validation Loss: 0.2084
Epoch [140/250], Train Loss: 0.2002, Validation Loss: 0.1938
Epoch [141/250], Train Loss: 0.2193, Validation Loss: 0.2191
Epoch [142/250], Train Loss: 0.2342, Validation Loss: 0.2098
Epoch [143/250], Train Loss: 0.1977, Validation Loss: 0.1803
Epoch [144/250], Train Loss: 0.2130, Validation Loss: 0.2069
Epoch [145/250], Train Loss: 0.1922, Validation Loss: 0.2009
Epoch [146/250], Train Loss: 0.2183, Validation Loss: 0.2112
Epoch [147/250], Train Loss: 0.2056, Validation Loss: 0.2056
Epoch [148/250], Train Loss: 0.2358, Validation Loss: 0.1771
Epoch [149/250], Train Loss: 0.2022, Validation Loss: 0.1887
Epoch [150/250], Train Loss: 0.1986, Validation Loss: 0.1860
Epoch [151/250], Train Loss: 0.1893, Validation Loss: 0.1895
Epoch [152/250], Train Loss: 0.2181, Validation Loss: 0.2053
Epoch [153/250], Train Loss: 0.2251, Validation Loss: 0.1820
Epoch [154/250], Train Loss: 0.2050, Validation Loss: 0.1774
Epoch [155/250], Train Loss: 0.2069, Validation Loss: 0.1990
Epoch [156/250], Train Loss: 0.2169, Validation Loss: 0.1919
Epoch [157/250], Train Loss: 0.2043, Validation Loss: 0.1993
Epoch [158/250], Train Loss: 0.2015, Validation Loss: 0.1843
Epoch [159/250], Train Loss: 0.1894, Validation Loss: 0.2202
Epoch [160/250], Train Loss: 0.2083, Validation Loss: 0.1946
Epoch [161/250], Train Loss: 0.1889, Validation Loss: 0.1857
Epoch [162/250], Train Loss: 0.1846, Validation Loss: 0.1847
Epoch [163/250], Train Loss: 0.2067, Validation Loss: 0.2133
Epoch [164/250], Train Loss: 0.2189, Validation Loss: 0.2013
Epoch [165/250], Train Loss: 0.2009, Validation Loss: 0.2027
Epoch [166/250], Train Loss: 0.2039, Validation Loss: 0.1749
Epoch [167/250], Train Loss: 0.1952, Validation Loss: 0.1841
Epoch [168/250], Train Loss: 0.2004, Validation Loss: 0.2196
Epoch [169/250], Train Loss: 0.2000, Validation Loss: 0.1866
Epoch [170/250], Train Loss: 0.1920, Validation Loss: 0.2143
Epoch [171/250], Train Loss: 0.1851, Validation Loss: 0.1871
Epoch [172/250], Train Loss: 0.1702, Validation Loss: 0.1783
Epoch [173/250], Train Loss: 0.2006, Validation Loss: 0.1954
Epoch [174/250], Train Loss: 0.1952, Validation Loss: 0.1714
Epoch [175/250], Train Loss: 0.1879, Validation Loss: 0.1747
Epoch [176/250], Train Loss: 0.1924, Validation Loss: 0.1910
Epoch [177/250], Train Loss: 0.1942, Validation Loss: 0.1759
Epoch [178/250], Train Loss: 0.1984, Validation Loss: 0.1980
Epoch [179/250], Train Loss: 0.1858, Validation Loss: 0.2054
Epoch [180/250], Train Loss: 0.2211, Validation Loss: 0.1998
Epoch [181/250], Train Loss: 0.2233, Validation Loss: 0.2007
Epoch [182/250], Train Loss: 0.1953, Validation Loss: 0.2103
Epoch [183/250], Train Loss: 0.2009, Validation Loss: 0.1968
Epoch [184/250], Train Loss: 0.2153, Validation Loss: 0.1915
Epoch [185/250], Train Loss: 0.1883, Validation Loss: 0.1991
Epoch [186/250], Train Loss: 0.1941, Validation Loss: 0.1903
Epoch [187/250], Train Loss: 0.1973, Validation Loss: 0.1767
Epoch [188/250], Train Loss: 0.2029, Validation Loss: 0.2099
Epoch [189/250], Train Loss: 0.1911, Validation Loss: 0.1886
Epoch [190/250], Train Loss: 0.2016, Validation Loss: 0.1780
Epoch [191/250], Train Loss: 0.2086, Validation Loss: 0.1737
Epoch [192/250], Train Loss: 0.1871, Validation Loss: 0.1962
Epoch [193/250], Train Loss: 0.2242, Validation Loss: 0.1684
Epoch [194/250], Train Loss: 0.1782, Validation Loss: 0.1912
Epoch [195/250], Train Loss: 0.2104, Validation Loss: 0.1842
Epoch [196/250], Train Loss: 0.1950, Validation Loss: 0.1804
Epoch [197/250], Train Loss: 0.1793, Validation Loss: 0.1820
Epoch [198/250], Train Loss: 0.1743, Validation Loss: 0.1831
Epoch [199/250], Train Loss: 0.2155, Validation Loss: 0.1637
Epoch [200/250], Train Loss: 0.1688, Validation Loss: 0.2013
Epoch [201/250], Train Loss: 0.1866, Validation Loss: 0.1769
Epoch [202/250], Train Loss: 0.1725, Validation Loss: 0.1858
Epoch [203/250], Train Loss: 0.1846, Validation Loss: 0.1836
Epoch [204/250], Train Loss: 0.1910, Validation Loss: 0.1710
Epoch [205/250], Train Loss: 0.2032, Validation Loss: 0.1893
Epoch [206/250], Train Loss: 0.1855, Validation Loss: 0.1757
Epoch [207/250], Train Loss: 0.1875, Validation Loss: 0.1909
Epoch [208/250], Train Loss: 0.1848, Validation Loss: 0.1942
Epoch [209/250], Train Loss: 0.1890, Validation Loss: 0.1956
Epoch [210/250], Train Loss: 0.1680, Validation Loss: 0.2086
Epoch [211/250], Train Loss: 0.1884, Validation Loss: 0.1654
Epoch [212/250], Train Loss: 0.1867, Validation Loss: 0.2009
Epoch [213/250], Train Loss: 0.1672, Validation Loss: 0.2146
Epoch [214/250], Train Loss: 0.2005, Validation Loss: 0.1908
Epoch [215/250], Train Loss: 0.1876, Validation Loss: 0.1860
Epoch [216/250], Train Loss: 0.1624, Validation Loss: 0.1709
Epoch [217/250], Train Loss: 0.1892, Validation Loss: 0.1789
Epoch [218/250], Train Loss: 0.1643, Validation Loss: 0.1930
Epoch [219/250], Train Loss: 0.1670, Validation Loss: 0.1558
Epoch [220/250], Train Loss: 0.1722, Validation Loss: 0.1970
Epoch [221/250], Train Loss: 0.1937, Validation Loss: 0.2163
Epoch [222/250], Train Loss: 0.2233, Validation Loss: 0.1953
Epoch [223/250], Train Loss: 0.2087, Validation Loss: 0.1861
Epoch [224/250], Train Loss: 0.2023, Validation Loss: 0.1818
Epoch [225/250], Train Loss: 0.1700, Validation Loss: 0.1889
Epoch [226/250], Train Loss: 0.1733, Validation Loss: 0.1875
Epoch [227/250], Train Loss: 0.1829, Validation Loss: 0.1668
Epoch [228/250], Train Loss: 0.1704, Validation Loss: 0.1696
Epoch [229/250], Train Loss: 0.1794, Validation Loss: 0.1895
Epoch [230/250], Train Loss: 0.1993, Validation Loss: 0.1848
Epoch [231/250], Train Loss: 0.2385, Validation Loss: 0.1931
Epoch [232/250], Train Loss: 0.2301, Validation Loss: 0.2457
Epoch [233/250], Train Loss: 0.2435, Validation Loss: 0.2481
Epoch [234/250], Train Loss: 0.2564, Validation Loss: 0.1817
Epoch [235/250], Train Loss: 0.1909, Validation Loss: 0.2670
Epoch [236/250], Train Loss: 0.2154, Validation Loss: 0.2073
Epoch [237/250], Train Loss: 0.2061, Validation Loss: 0.2156
Epoch [238/250], Train Loss: 0.1909, Validation Loss: 0.1933
Epoch [239/250], Train Loss: 0.1780, Validation Loss: 0.1980
Epoch [240/250], Train Loss: 0.1818, Validation Loss: 0.1702
Epoch [241/250], Train Loss: 0.1854, Validation Loss: 0.2051
Epoch [242/250], Train Loss: 0.1832, Validation Loss: 0.2048
Epoch [243/250], Train Loss: 0.1956, Validation Loss: 0.1683
Epoch [244/250], Train Loss: 0.1730, Validation Loss: 0.1729
Epoch [245/250], Train Loss: 0.1742, Validation Loss: 0.1837
Epoch [246/250], Train Loss: 0.2054, Validation Loss: 0.1740
Epoch [247/250], Train Loss: 0.1864, Validation Loss: 0.2068
Epoch [248/250], Train Loss: 0.1711, Validation Loss: 0.1797
Epoch [249/250], Train Loss: 0.1770, Validation Loss: 0.1842
Epoch [250/250], Train Loss: 0.1747, Validation Loss: 0.2110

Finished Training in 81.9

Noise Sigma:  2.0
Creating datasets...
Start training...
Epoch [1/250], Train Loss: 0.3608, Validation Loss: 0.3015
Epoch [2/250], Train Loss: 0.3151, Validation Loss: 0.2640
Epoch [3/250], Train Loss: 0.2616, Validation Loss: 0.3095
Epoch [4/250], Train Loss: 0.3234, Validation Loss: 0.2432
Epoch [5/250], Train Loss: 0.2639, Validation Loss: 0.2465
Epoch [6/250], Train Loss: 0.2670, Validation Loss: 0.2622
Epoch [7/250], Train Loss: 0.2331, Validation Loss: 0.2523
Epoch [8/250], Train Loss: 0.2167, Validation Loss: 0.2381
Epoch [9/250], Train Loss: 0.2395, Validation Loss: 0.2339
Epoch [10/250], Train Loss: 0.2187, Validation Loss: 0.2435
Epoch [11/250], Train Loss: 0.2409, Validation Loss: 0.2293
Epoch [12/250], Train Loss: 0.2071, Validation Loss: 0.2309
Epoch [13/250], Train Loss: 0.2338, Validation Loss: 0.2187
Epoch [14/250], Train Loss: 0.2148, Validation Loss: 0.2358
Epoch [15/250], Train Loss: 0.2324, Validation Loss: 0.2231
Epoch [16/250], Train Loss: 0.2165, Validation Loss: 0.2153
Epoch [17/250], Train Loss: 0.2242, Validation Loss: 0.2227
Epoch [18/250], Train Loss: 0.2284, Validation Loss: 0.2364
Epoch [19/250], Train Loss: 0.2247, Validation Loss: 0.2345
Epoch [20/250], Train Loss: 0.2448, Validation Loss: 0.2243
Epoch [21/250], Train Loss: 0.2317, Validation Loss: 0.2169
Epoch [22/250], Train Loss: 0.2588, Validation Loss: 0.2133
Epoch [23/250], Train Loss: 0.2426, Validation Loss: 0.2158
Epoch [24/250], Train Loss: 0.2250, Validation Loss: 0.2035
Epoch [25/250], Train Loss: 0.2225, Validation Loss: 0.2321
Epoch [26/250], Train Loss: 0.2205, Validation Loss: 0.2262
Epoch [27/250], Train Loss: 0.2479, Validation Loss: 0.2207
Epoch [28/250], Train Loss: 0.2184, Validation Loss: 0.2246
Epoch [29/250], Train Loss: 0.2183, Validation Loss: 0.2129
Epoch [30/250], Train Loss: 0.2199, Validation Loss: 0.2161
Epoch [31/250], Train Loss: 0.2204, Validation Loss: 0.2283
Epoch [32/250], Train Loss: 0.2435, Validation Loss: 0.2056
Epoch [33/250], Train Loss: 0.2349, Validation Loss: 0.2350
Epoch [34/250], Train Loss: 0.2321, Validation Loss: 0.2552
Epoch [35/250], Train Loss: 0.2539, Validation Loss: 0.2264
Epoch [36/250], Train Loss: 0.2283, Validation Loss: 0.2216
Epoch [37/250], Train Loss: 0.2220, Validation Loss: 0.2424
Epoch [38/250], Train Loss: 0.2386, Validation Loss: 0.2191
Epoch [39/250], Train Loss: 0.2301, Validation Loss: 0.2121
Epoch [40/250], Train Loss: 0.2351, Validation Loss: 0.2144
Epoch [41/250], Train Loss: 0.2293, Validation Loss: 0.2240
Epoch [42/250], Train Loss: 0.2094, Validation Loss: 0.2263
Epoch [43/250], Train Loss: 0.2072, Validation Loss: 0.2151
Epoch [44/250], Train Loss: 0.2044, Validation Loss: 0.2025
Epoch [45/250], Train Loss: 0.2178, Validation Loss: 0.1949
Epoch [46/250], Train Loss: 0.1954, Validation Loss: 0.2319
Epoch [47/250], Train Loss: 0.2170, Validation Loss: 0.2179
Epoch [48/250], Train Loss: 0.2307, Validation Loss: 0.2073
Epoch [49/250], Train Loss: 0.1898, Validation Loss: 0.2302
Epoch [50/250], Train Loss: 0.2202, Validation Loss: 0.2161
Epoch [51/250], Train Loss: 0.2044, Validation Loss: 0.2228
Epoch [52/250], Train Loss: 0.2249, Validation Loss: 0.1895
Epoch [53/250], Train Loss: 0.1831, Validation Loss: 0.1959
Epoch [54/250], Train Loss: 0.1968, Validation Loss: 0.2251
Epoch [55/250], Train Loss: 0.2344, Validation Loss: 0.2055
Epoch [56/250], Train Loss: 0.1981, Validation Loss: 0.1924
Epoch [57/250], Train Loss: 0.1936, Validation Loss: 0.2017
Epoch [58/250], Train Loss: 0.1927, Validation Loss: 0.2010
Epoch [59/250], Train Loss: 0.1980, Validation Loss: 0.2038
Epoch [60/250], Train Loss: 0.2020, Validation Loss: 0.2129
Epoch [61/250], Train Loss: 0.1829, Validation Loss: 0.1953
Epoch [62/250], Train Loss: 0.1912, Validation Loss: 0.1971
Epoch [63/250], Train Loss: 0.2188, Validation Loss: 0.1870
Epoch [64/250], Train Loss: 0.1901, Validation Loss: 0.2187
Epoch [65/250], Train Loss: 0.2033, Validation Loss: 0.2255
Epoch [66/250], Train Loss: 0.2049, Validation Loss: 0.1921
Epoch [67/250], Train Loss: 0.1983, Validation Loss: 0.2072
Epoch [68/250], Train Loss: 0.2061, Validation Loss: 0.2089
Epoch [69/250], Train Loss: 0.2161, Validation Loss: 0.2070
Epoch [70/250], Train Loss: 0.2005, Validation Loss: 0.1971
Epoch [71/250], Train Loss: 0.1815, Validation Loss: 0.1851
Epoch [72/250], Train Loss: 0.1972, Validation Loss: 0.1940
Epoch [73/250], Train Loss: 0.2007, Validation Loss: 0.2284
Epoch [74/250], Train Loss: 0.2137, Validation Loss: 0.2054
Epoch [75/250], Train Loss: 0.2332, Validation Loss: 0.2111
Epoch [76/250], Train Loss: 0.2211, Validation Loss: 0.2079
Epoch [77/250], Train Loss: 0.2037, Validation Loss: 0.1933
Epoch [78/250], Train Loss: 0.2049, Validation Loss: 0.2089
Epoch [79/250], Train Loss: 0.2062, Validation Loss: 0.2292
Epoch [80/250], Train Loss: 0.2474, Validation Loss: 0.1953
Epoch [81/250], Train Loss: 0.2169, Validation Loss: 0.2111
Epoch [82/250], Train Loss: 0.1986, Validation Loss: 0.2128
Epoch [83/250], Train Loss: 0.2204, Validation Loss: 0.2089
Epoch [84/250], Train Loss: 0.1953, Validation Loss: 0.2162
Epoch [85/250], Train Loss: 0.2035, Validation Loss: 0.1914
Epoch [86/250], Train Loss: 0.1894, Validation Loss: 0.1933
Epoch [87/250], Train Loss: 0.2046, Validation Loss: 0.2042
Epoch [88/250], Train Loss: 0.2069, Validation Loss: 0.2033
Epoch [89/250], Train Loss: 0.2097, Validation Loss: 0.2020
Epoch [90/250], Train Loss: 0.1751, Validation Loss: 0.2076
Epoch [91/250], Train Loss: 0.2115, Validation Loss: 0.2021
Epoch [92/250], Train Loss: 0.2170, Validation Loss: 0.2063
Epoch [93/250], Train Loss: 0.2138, Validation Loss: 0.1853
Epoch [94/250], Train Loss: 0.2036, Validation Loss: 0.2262
Epoch [95/250], Train Loss: 0.2128, Validation Loss: 0.2117
Epoch [96/250], Train Loss: 0.2131, Validation Loss: 0.1873
Epoch [97/250], Train Loss: 0.1922, Validation Loss: 0.2238
Epoch [98/250], Train Loss: 0.1855, Validation Loss: 0.1961
Epoch [99/250], Train Loss: 0.2091, Validation Loss: 0.1774
Epoch [100/250], Train Loss: 0.1880, Validation Loss: 0.2038
Epoch [101/250], Train Loss: 0.1955, Validation Loss: 0.2011
Epoch [102/250], Train Loss: 0.1741, Validation Loss: 0.1764
Epoch [103/250], Train Loss: 0.1795, Validation Loss: 0.1864
Epoch [104/250], Train Loss: 0.1862, Validation Loss: 0.1824
Epoch [105/250], Train Loss: 0.2163, Validation Loss: 0.1914
Epoch [106/250], Train Loss: 0.2263, Validation Loss: 0.1949
Epoch [107/250], Train Loss: 0.1972, Validation Loss: 0.1988
Epoch [108/250], Train Loss: 0.2128, Validation Loss: 0.1921
Epoch [109/250], Train Loss: 0.1906, Validation Loss: 0.1830
Epoch [110/250], Train Loss: 0.1884, Validation Loss: 0.1916
Epoch [111/250], Train Loss: 0.2061, Validation Loss: 0.1842
Epoch [112/250], Train Loss: 0.1810, Validation Loss: 0.1745
Epoch [113/250], Train Loss: 0.1865, Validation Loss: 0.1816
Epoch [114/250], Train Loss: 0.1952, Validation Loss: 0.1777
Epoch [115/250], Train Loss: 0.2062, Validation Loss: 0.1889
Epoch [116/250], Train Loss: 0.2339, Validation Loss: 0.1992
Epoch [117/250], Train Loss: 0.2212, Validation Loss: 0.1977
Epoch [118/250], Train Loss: 0.1935, Validation Loss: 0.2048
Epoch [119/250], Train Loss: 0.1935, Validation Loss: 0.2154
Epoch [120/250], Train Loss: 0.2213, Validation Loss: 0.1947
Epoch [121/250], Train Loss: 0.1974, Validation Loss: 0.2128
Epoch [122/250], Train Loss: 0.1868, Validation Loss: 0.2089
Epoch [123/250], Train Loss: 0.2019, Validation Loss: 0.1726
Epoch [124/250], Train Loss: 0.1951, Validation Loss: 0.2073
Epoch [125/250], Train Loss: 0.1949, Validation Loss: 0.1737
Epoch [126/250], Train Loss: 0.2054, Validation Loss: 0.1891
Epoch [127/250], Train Loss: 0.1824, Validation Loss: 0.1906
Epoch [128/250], Train Loss: 0.1910, Validation Loss: 0.1851
Epoch [129/250], Train Loss: 0.2149, Validation Loss: 0.1861
Epoch [130/250], Train Loss: 0.2241, Validation Loss: 0.1913
Epoch [131/250], Train Loss: 0.1801, Validation Loss: 0.2221
Epoch [132/250], Train Loss: 0.1819, Validation Loss: 0.1927
Epoch [133/250], Train Loss: 0.1870, Validation Loss: 0.1941
Epoch [134/250], Train Loss: 0.1857, Validation Loss: 0.1945
Epoch [135/250], Train Loss: 0.1820, Validation Loss: 0.1818
Epoch [136/250], Train Loss: 0.2285, Validation Loss: 0.1778
Epoch [137/250], Train Loss: 0.2240, Validation Loss: 0.2361
Epoch [138/250], Train Loss: 0.1934, Validation Loss: 0.2037
Epoch [139/250], Train Loss: 0.2293, Validation Loss: 0.2150
Epoch [140/250], Train Loss: 0.2130, Validation Loss: 0.1917
Epoch [141/250], Train Loss: 0.1956, Validation Loss: 0.1868
Epoch [142/250], Train Loss: 0.1905, Validation Loss: 0.1883
Epoch [143/250], Train Loss: 0.1903, Validation Loss: 0.1913
Epoch [144/250], Train Loss: 0.1868, Validation Loss: 0.2058
Epoch [145/250], Train Loss: 0.2045, Validation Loss: 0.1723
Epoch [146/250], Train Loss: 0.2012, Validation Loss: 0.1927
Epoch [147/250], Train Loss: 0.1979, Validation Loss: 0.1736
Epoch [148/250], Train Loss: 0.1891, Validation Loss: 0.1848
Epoch [149/250], Train Loss: 0.1885, Validation Loss: 0.1805
Epoch [150/250], Train Loss: 0.1952, Validation Loss: 0.1831
Epoch [151/250], Train Loss: 0.1608, Validation Loss: 0.1914
Epoch [152/250], Train Loss: 0.1818, Validation Loss: 0.1825
Epoch [153/250], Train Loss: 0.1879, Validation Loss: 0.1880
Epoch [154/250], Train Loss: 0.1902, Validation Loss: 0.1809
Epoch [155/250], Train Loss: 0.1879, Validation Loss: 0.1774
Epoch [156/250], Train Loss: 0.1890, Validation Loss: 0.1756
Epoch [157/250], Train Loss: 0.1883, Validation Loss: 0.2011
Epoch [158/250], Train Loss: 0.2048, Validation Loss: 0.1734
Epoch [159/250], Train Loss: 0.1680, Validation Loss: 0.2156
Epoch [160/250], Train Loss: 0.1943, Validation Loss: 0.1912
Epoch [161/250], Train Loss: 0.2035, Validation Loss: 0.1946
Epoch [162/250], Train Loss: 0.1959, Validation Loss: 0.1846
Epoch [163/250], Train Loss: 0.1818, Validation Loss: 0.1729
Epoch [164/250], Train Loss: 0.1871, Validation Loss: 0.1778
Epoch [165/250], Train Loss: 0.1927, Validation Loss: 0.1845
Epoch [166/250], Train Loss: 0.1865, Validation Loss: 0.1852
Epoch [167/250], Train Loss: 0.1785, Validation Loss: 0.1862
Epoch [168/250], Train Loss: 0.1682, Validation Loss: 0.1672
Epoch [169/250], Train Loss: 0.2013, Validation Loss: 0.1704
Epoch [170/250], Train Loss: 0.1972, Validation Loss: 0.1932
Epoch [171/250], Train Loss: 0.1972, Validation Loss: 0.2070
Epoch [172/250], Train Loss: 0.1846, Validation Loss: 0.1666
Epoch [173/250], Train Loss: 0.2029, Validation Loss: 0.1918
Epoch [174/250], Train Loss: 0.2035, Validation Loss: 0.2021
Epoch [175/250], Train Loss: 0.1778, Validation Loss: 0.1851
Epoch [176/250], Train Loss: 0.1972, Validation Loss: 0.1838
Epoch [177/250], Train Loss: 0.1913, Validation Loss: 0.1967
Epoch [178/250], Train Loss: 0.1904, Validation Loss: 0.2206
Epoch [179/250], Train Loss: 0.1856, Validation Loss: 0.1551
Epoch [180/250], Train Loss: 0.1932, Validation Loss: 0.1854
Epoch [181/250], Train Loss: 0.1747, Validation Loss: 0.1855
Epoch [182/250], Train Loss: 0.1984, Validation Loss: 0.1856
Epoch [183/250], Train Loss: 0.1758, Validation Loss: 0.1887
Epoch [184/250], Train Loss: 0.1840, Validation Loss: 0.1759
Epoch [185/250], Train Loss: 0.1828, Validation Loss: 0.1796
Epoch [186/250], Train Loss: 0.1722, Validation Loss: 0.1752
Epoch [187/250], Train Loss: 0.1911, Validation Loss: 0.2063
Epoch [188/250], Train Loss: 0.1855, Validation Loss: 0.1648
Epoch [189/250], Train Loss: 0.1931, Validation Loss: 0.1960
Epoch [190/250], Train Loss: 0.1766, Validation Loss: 0.1645
Epoch [191/250], Train Loss: 0.1796, Validation Loss: 0.1765
Epoch [192/250], Train Loss: 0.1703, Validation Loss: 0.1759
Epoch [193/250], Train Loss: 0.1748, Validation Loss: 0.1639
Epoch [194/250], Train Loss: 0.1916, Validation Loss: 0.1682
Epoch [195/250], Train Loss: 0.1758, Validation Loss: 0.1836
Epoch [196/250], Train Loss: 0.1743, Validation Loss: 0.1632
Epoch [197/250], Train Loss: 0.1967, Validation Loss: 0.1734
Epoch [198/250], Train Loss: 0.1794, Validation Loss: 0.1482
Epoch [199/250], Train Loss: 0.1789, Validation Loss: 0.1720
Epoch [200/250], Train Loss: 0.1574, Validation Loss: 0.1856
Epoch [201/250], Train Loss: 0.1768, Validation Loss: 0.1623
Epoch [202/250], Train Loss: 0.1529, Validation Loss: 0.1705
Epoch [203/250], Train Loss: 0.1714, Validation Loss: 0.1571
Epoch [204/250], Train Loss: 0.1687, Validation Loss: 0.1636
Epoch [205/250], Train Loss: 0.1656, Validation Loss: 0.1652
Epoch [206/250], Train Loss: 0.1730, Validation Loss: 0.1886
Epoch [207/250], Train Loss: 0.1904, Validation Loss: 0.2041
Epoch [208/250], Train Loss: 0.2150, Validation Loss: 0.1865
Epoch [209/250], Train Loss: 0.1826, Validation Loss: 0.1561
Epoch [210/250], Train Loss: 0.1731, Validation Loss: 0.1639
Epoch [211/250], Train Loss: 0.1695, Validation Loss: 0.1993
Epoch [212/250], Train Loss: 0.1851, Validation Loss: 0.1793
Epoch [213/250], Train Loss: 0.1974, Validation Loss: 0.1795
Epoch [214/250], Train Loss: 0.1680, Validation Loss: 0.1844
Epoch [215/250], Train Loss: 0.1955, Validation Loss: 0.1772
Epoch [216/250], Train Loss: 0.1638, Validation Loss: 0.1820
Epoch [217/250], Train Loss: 0.1729, Validation Loss: 0.1705
Epoch [218/250], Train Loss: 0.1493, Validation Loss: 0.1572
Epoch [219/250], Train Loss: 0.1719, Validation Loss: 0.1622
Epoch [220/250], Train Loss: 0.1646, Validation Loss: 0.1677
Epoch [221/250], Train Loss: 0.1611, Validation Loss: 0.1702
Epoch [222/250], Train Loss: 0.1638, Validation Loss: 0.1693
Epoch [223/250], Train Loss: 0.1768, Validation Loss: 0.1824
Epoch [224/250], Train Loss: 0.1888, Validation Loss: 0.1632
Epoch [225/250], Train Loss: 0.2097, Validation Loss: 0.2168
Epoch [226/250], Train Loss: 0.2034, Validation Loss: 0.2145
Epoch [227/250], Train Loss: 0.1772, Validation Loss: 0.2198
Epoch [228/250], Train Loss: 0.1930, Validation Loss: 0.1657
Epoch [229/250], Train Loss: 0.2047, Validation Loss: 0.1618
Epoch [230/250], Train Loss: 0.1769, Validation Loss: 0.1895
Epoch [231/250], Train Loss: 0.1726, Validation Loss: 0.1974
Epoch [232/250], Train Loss: 0.1831, Validation Loss: 0.1721
Epoch [233/250], Train Loss: 0.1915, Validation Loss: 0.1760
Epoch [234/250], Train Loss: 0.1839, Validation Loss: 0.1883
Epoch [235/250], Train Loss: 0.1864, Validation Loss: 0.1721
Epoch [236/250], Train Loss: 0.1758, Validation Loss: 0.1756
Epoch [237/250], Train Loss: 0.1737, Validation Loss: 0.1568
Epoch [238/250], Train Loss: 0.1685, Validation Loss: 0.1903
Epoch [239/250], Train Loss: 0.1821, Validation Loss: 0.1645
Epoch [240/250], Train Loss: 0.1582, Validation Loss: 0.1646
Epoch [241/250], Train Loss: 0.1967, Validation Loss: 0.1687
Epoch [242/250], Train Loss: 0.1681, Validation Loss: 0.1707
Epoch [243/250], Train Loss: 0.1759, Validation Loss: 0.1762
Epoch [244/250], Train Loss: 0.1651, Validation Loss: 0.1829
Epoch [245/250], Train Loss: 0.1591, Validation Loss: 0.1515
Epoch [246/250], Train Loss: 0.1860, Validation Loss: 0.1713
Epoch [247/250], Train Loss: 0.1719, Validation Loss: 0.1688
Epoch [248/250], Train Loss: 0.1965, Validation Loss: 0.1809
Epoch [249/250], Train Loss: 0.1666, Validation Loss: 0.1584
Epoch [250/250], Train Loss: 0.1744, Validation Loss: 0.1810

Finished Training in 81.6

Saving model parameters...
done
