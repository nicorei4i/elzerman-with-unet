GPU available:  True
cuda
(100, 8192)
(100, 8192)
20086
noise sigs:  [0.01   0.5075 1.005  1.5025 2.    ]
Noise Sigma:  0.01
Creating datasets...
Start training...
Epoch [1/250], Train Loss: 0.7129, Validation Loss: 0.7087
Epoch [2/250], Train Loss: 0.7060, Validation Loss: 0.7064
Epoch [3/250], Train Loss: 0.7045, Validation Loss: 0.7055
Epoch [4/250], Train Loss: 0.7035, Validation Loss: 0.7040
Epoch [5/250], Train Loss: 0.7017, Validation Loss: 0.7005
Epoch [6/250], Train Loss: 0.6973, Validation Loss: 0.6937
Epoch [7/250], Train Loss: 0.6899, Validation Loss: 0.6858
Epoch [8/250], Train Loss: 0.6818, Validation Loss: 0.6783
Epoch [9/250], Train Loss: 0.6742, Validation Loss: 0.6703
Epoch [10/250], Train Loss: 0.6658, Validation Loss: 0.6612
Epoch [11/250], Train Loss: 0.6563, Validation Loss: 0.6515
Epoch [12/250], Train Loss: 0.6467, Validation Loss: 0.6426
Epoch [13/250], Train Loss: 0.6381, Validation Loss: 0.6352
Epoch [14/250], Train Loss: 0.6308, Validation Loss: 0.6282
Epoch [15/250], Train Loss: 0.6239, Validation Loss: 0.6213
Epoch [16/250], Train Loss: 0.6170, Validation Loss: 0.6143
Epoch [17/250], Train Loss: 0.6099, Validation Loss: 0.6070
Epoch [18/250], Train Loss: 0.6025, Validation Loss: 0.5994
Epoch [19/250], Train Loss: 0.5948, Validation Loss: 0.5917
Epoch [20/250], Train Loss: 0.5867, Validation Loss: 0.5834
Epoch [21/250], Train Loss: 0.5784, Validation Loss: 0.5748
Epoch [22/250], Train Loss: 0.5696, Validation Loss: 0.5657
Epoch [23/250], Train Loss: 0.5604, Validation Loss: 0.5562
Epoch [24/250], Train Loss: 0.5506, Validation Loss: 0.5467
Epoch [25/250], Train Loss: 0.5408, Validation Loss: 0.5366
Epoch [26/250], Train Loss: 0.5309, Validation Loss: 0.5265
Epoch [27/250], Train Loss: 0.5204, Validation Loss: 0.5163
Epoch [28/250], Train Loss: 0.5101, Validation Loss: 0.5058
Epoch [29/250], Train Loss: 0.4995, Validation Loss: 0.4955
Epoch [30/250], Train Loss: 0.4891, Validation Loss: 0.4847
Epoch [31/250], Train Loss: 0.4780, Validation Loss: 0.4739
Epoch [32/250], Train Loss: 0.4672, Validation Loss: 0.4633
Epoch [33/250], Train Loss: 0.4566, Validation Loss: 0.4531
Epoch [34/250], Train Loss: 0.4461, Validation Loss: 0.4429
Epoch [35/250], Train Loss: 0.4360, Validation Loss: 0.4331
Epoch [36/250], Train Loss: 0.4262, Validation Loss: 0.4237
Epoch [37/250], Train Loss: 0.4170, Validation Loss: 0.4149
Epoch [38/250], Train Loss: 0.4078, Validation Loss: 0.4065
Epoch [39/250], Train Loss: 0.3997, Validation Loss: 0.3981
Epoch [40/250], Train Loss: 0.3914, Validation Loss: 0.3900
Epoch [41/250], Train Loss: 0.3828, Validation Loss: 0.3813
Epoch [42/250], Train Loss: 0.3740, Validation Loss: 0.3720
Epoch [43/250], Train Loss: 0.3643, Validation Loss: 0.3613
Epoch [44/250], Train Loss: 0.3530, Validation Loss: 0.3488
Epoch [45/250], Train Loss: 0.3397, Validation Loss: 0.3370
Epoch [46/250], Train Loss: 0.3298, Validation Loss: 0.3296
Epoch [47/250], Train Loss: 0.3229, Validation Loss: 0.3249
Epoch [48/250], Train Loss: 0.3185, Validation Loss: 0.3210
Epoch [49/250], Train Loss: 0.3148, Validation Loss: 0.3179
Epoch [50/250], Train Loss: 0.3118, Validation Loss: 0.3149
Epoch [51/250], Train Loss: 0.3090, Validation Loss: 0.3123
Epoch [52/250], Train Loss: 0.3063, Validation Loss: 0.3097
Epoch [53/250], Train Loss: 0.3039, Validation Loss: 0.3073
Epoch [54/250], Train Loss: 0.3015, Validation Loss: 0.3049
Epoch [55/250], Train Loss: 0.2992, Validation Loss: 0.3026
Epoch [56/250], Train Loss: 0.2970, Validation Loss: 0.3004
Epoch [57/250], Train Loss: 0.2948, Validation Loss: 0.2982
Epoch [58/250], Train Loss: 0.2927, Validation Loss: 0.2961
Epoch [59/250], Train Loss: 0.2907, Validation Loss: 0.2940
Epoch [60/250], Train Loss: 0.2886, Validation Loss: 0.2920
Epoch [61/250], Train Loss: 0.2867, Validation Loss: 0.2900
Epoch [62/250], Train Loss: 0.2847, Validation Loss: 0.2881
Epoch [63/250], Train Loss: 0.2828, Validation Loss: 0.2861
Epoch [64/250], Train Loss: 0.2808, Validation Loss: 0.2841
Epoch [65/250], Train Loss: 0.2789, Validation Loss: 0.2822
Epoch [66/250], Train Loss: 0.2771, Validation Loss: 0.2804
Epoch [67/250], Train Loss: 0.2752, Validation Loss: 0.2785
Epoch [68/250], Train Loss: 0.2734, Validation Loss: 0.2767
Epoch [69/250], Train Loss: 0.2717, Validation Loss: 0.2755
Epoch [70/250], Train Loss: 0.2707, Validation Loss: 0.2747
Epoch [71/250], Train Loss: 0.2700, Validation Loss: 0.2739
Epoch [72/250], Train Loss: 0.2691, Validation Loss: 0.2731
Epoch [73/250], Train Loss: 0.2684, Validation Loss: 0.2723
Epoch [74/250], Train Loss: 0.2676, Validation Loss: 0.2715
Epoch [75/250], Train Loss: 0.2669, Validation Loss: 0.2707
Epoch [76/250], Train Loss: 0.2661, Validation Loss: 0.2700
Epoch [77/250], Train Loss: 0.2653, Validation Loss: 0.2692
Epoch [78/250], Train Loss: 0.2645, Validation Loss: 0.2684
Epoch [79/250], Train Loss: 0.2638, Validation Loss: 0.2676
Epoch [80/250], Train Loss: 0.2630, Validation Loss: 0.2669
Epoch [81/250], Train Loss: 0.2623, Validation Loss: 0.2661
Epoch [82/250], Train Loss: 0.2615, Validation Loss: 0.2653
Epoch [83/250], Train Loss: 0.2607, Validation Loss: 0.2646
Epoch [84/250], Train Loss: 0.2600, Validation Loss: 0.2638
Epoch [85/250], Train Loss: 0.2593, Validation Loss: 0.2631
Epoch [86/250], Train Loss: 0.2585, Validation Loss: 0.2623
Epoch [87/250], Train Loss: 0.2578, Validation Loss: 0.2615
Epoch [88/250], Train Loss: 0.2570, Validation Loss: 0.2608
Epoch [89/250], Train Loss: 0.2563, Validation Loss: 0.2601
Epoch [90/250], Train Loss: 0.2556, Validation Loss: 0.2593
Epoch [91/250], Train Loss: 0.2548, Validation Loss: 0.2586
Epoch [92/250], Train Loss: 0.2541, Validation Loss: 0.2579
Epoch [93/250], Train Loss: 0.2534, Validation Loss: 0.2571
Epoch [94/250], Train Loss: 0.2527, Validation Loss: 0.2564
Epoch [95/250], Train Loss: 0.2520, Validation Loss: 0.2557
Epoch [96/250], Train Loss: 0.2512, Validation Loss: 0.2550
Epoch [97/250], Train Loss: 0.2505, Validation Loss: 0.2542
Epoch [98/250], Train Loss: 0.2498, Validation Loss: 0.2535
Epoch [99/250], Train Loss: 0.2491, Validation Loss: 0.2528
Epoch [100/250], Train Loss: 0.2484, Validation Loss: 0.2520
Epoch [101/250], Train Loss: 0.2477, Validation Loss: 0.2513
Epoch [102/250], Train Loss: 0.2470, Validation Loss: 0.2506
Epoch [103/250], Train Loss: 0.2463, Validation Loss: 0.2499
Epoch [104/250], Train Loss: 0.2456, Validation Loss: 0.2492
Epoch [105/250], Train Loss: 0.2449, Validation Loss: 0.2485
Epoch [106/250], Train Loss: 0.2442, Validation Loss: 0.2477
Epoch [107/250], Train Loss: 0.2434, Validation Loss: 0.2471
Epoch [108/250], Train Loss: 0.2427, Validation Loss: 0.2463
Epoch [109/250], Train Loss: 0.2421, Validation Loss: 0.2456
Epoch [110/250], Train Loss: 0.2414, Validation Loss: 0.2450
Epoch [111/250], Train Loss: 0.2407, Validation Loss: 0.2443
Epoch [112/250], Train Loss: 0.2401, Validation Loss: 0.2436
Epoch [113/250], Train Loss: 0.2394, Validation Loss: 0.2429
Epoch [114/250], Train Loss: 0.2387, Validation Loss: 0.2422
Epoch [115/250], Train Loss: 0.2381, Validation Loss: 0.2416
Epoch [116/250], Train Loss: 0.2374, Validation Loss: 0.2409
Epoch [117/250], Train Loss: 0.2367, Validation Loss: 0.2402
Epoch [118/250], Train Loss: 0.2361, Validation Loss: 0.2395
Epoch [119/250], Train Loss: 0.2354, Validation Loss: 0.2388
Epoch [120/250], Train Loss: 0.2347, Validation Loss: 0.2382
Epoch [121/250], Train Loss: 0.2340, Validation Loss: 0.2375
Epoch [122/250], Train Loss: 0.2334, Validation Loss: 0.2368
Epoch [123/250], Train Loss: 0.2327, Validation Loss: 0.2362
Epoch [124/250], Train Loss: 0.2321, Validation Loss: 0.2355
Epoch [125/250], Train Loss: 0.2314, Validation Loss: 0.2348
Epoch [126/250], Train Loss: 0.2308, Validation Loss: 0.2341
Epoch [127/250], Train Loss: 0.2301, Validation Loss: 0.2335
Epoch [128/250], Train Loss: 0.2294, Validation Loss: 0.2328
Epoch [129/250], Train Loss: 0.2288, Validation Loss: 0.2321
Epoch [130/250], Train Loss: 0.2281, Validation Loss: 0.2315
Epoch [131/250], Train Loss: 0.2275, Validation Loss: 0.2308
Epoch [132/250], Train Loss: 0.2269, Validation Loss: 0.2302
Epoch [133/250], Train Loss: 0.2262, Validation Loss: 0.2295
Epoch [134/250], Train Loss: 0.2256, Validation Loss: 0.2289
Epoch [135/250], Train Loss: 0.2249, Validation Loss: 0.2282
Epoch [136/250], Train Loss: 0.2243, Validation Loss: 0.2276
Epoch [137/250], Train Loss: 0.2236, Validation Loss: 0.2269
Epoch [138/250], Train Loss: 0.2230, Validation Loss: 0.2263
Epoch [139/250], Train Loss: 0.2224, Validation Loss: 0.2257
Epoch [140/250], Train Loss: 0.2218, Validation Loss: 0.2251
Epoch [141/250], Train Loss: 0.2212, Validation Loss: 0.2244
Epoch [142/250], Train Loss: 0.2205, Validation Loss: 0.2238
Epoch [143/250], Train Loss: 0.2199, Validation Loss: 0.2231
Epoch [144/250], Train Loss: 0.2193, Validation Loss: 0.2225
Epoch [145/250], Train Loss: 0.2187, Validation Loss: 0.2219
Epoch [146/250], Train Loss: 0.2181, Validation Loss: 0.2213
Epoch [147/250], Train Loss: 0.2175, Validation Loss: 0.2207
Epoch [148/250], Train Loss: 0.2169, Validation Loss: 0.2201
Epoch [149/250], Train Loss: 0.2163, Validation Loss: 0.2195
Epoch [150/250], Train Loss: 0.2157, Validation Loss: 0.2189
Epoch [151/250], Train Loss: 0.2151, Validation Loss: 0.2183
Epoch [152/250], Train Loss: 0.2145, Validation Loss: 0.2177
Epoch [153/250], Train Loss: 0.2139, Validation Loss: 0.2171
Epoch [154/250], Train Loss: 0.2133, Validation Loss: 0.2165
Epoch [155/250], Train Loss: 0.2127, Validation Loss: 0.2159
Epoch [156/250], Train Loss: 0.2122, Validation Loss: 0.2153
Epoch [157/250], Train Loss: 0.2116, Validation Loss: 0.2147
Epoch [158/250], Train Loss: 0.2110, Validation Loss: 0.2141
Epoch [159/250], Train Loss: 0.2104, Validation Loss: 0.2135
Epoch [160/250], Train Loss: 0.2098, Validation Loss: 0.2129
Epoch [161/250], Train Loss: 0.2092, Validation Loss: 0.2123
Epoch [162/250], Train Loss: 0.2086, Validation Loss: 0.2117
Epoch [163/250], Train Loss: 0.2080, Validation Loss: 0.2111
Epoch [164/250], Train Loss: 0.2075, Validation Loss: 0.2105
Epoch [165/250], Train Loss: 0.2069, Validation Loss: 0.2100
Epoch [166/250], Train Loss: 0.2063, Validation Loss: 0.2094
Epoch [167/250], Train Loss: 0.2058, Validation Loss: 0.2088
Epoch [168/250], Train Loss: 0.2052, Validation Loss: 0.2082
Epoch [169/250], Train Loss: 0.2046, Validation Loss: 0.2077
Epoch [170/250], Train Loss: 0.2041, Validation Loss: 0.2072
Epoch [171/250], Train Loss: 0.2035, Validation Loss: 0.2066
Epoch [172/250], Train Loss: 0.2030, Validation Loss: 0.2060
Epoch [173/250], Train Loss: 0.2024, Validation Loss: 0.2054
Epoch [174/250], Train Loss: 0.2019, Validation Loss: 0.2049
Epoch [175/250], Train Loss: 0.2013, Validation Loss: 0.2043
Epoch [176/250], Train Loss: 0.2008, Validation Loss: 0.2037
Epoch [177/250], Train Loss: 0.2002, Validation Loss: 0.2032
Epoch [178/250], Train Loss: 0.1997, Validation Loss: 0.2026
Epoch [179/250], Train Loss: 0.1991, Validation Loss: 0.2021
Epoch [180/250], Train Loss: 0.1986, Validation Loss: 0.2015
Epoch [181/250], Train Loss: 0.1980, Validation Loss: 0.2010
Epoch [182/250], Train Loss: 0.1975, Validation Loss: 0.2004
Epoch [183/250], Train Loss: 0.1970, Validation Loss: 0.1999
Epoch [184/250], Train Loss: 0.1965, Validation Loss: 0.1994
Epoch [185/250], Train Loss: 0.1959, Validation Loss: 0.1988
Epoch [186/250], Train Loss: 0.1954, Validation Loss: 0.1983
Epoch [187/250], Train Loss: 0.1949, Validation Loss: 0.1978
Epoch [188/250], Train Loss: 0.1944, Validation Loss: 0.1972
Epoch [189/250], Train Loss: 0.1938, Validation Loss: 0.1967
Epoch [190/250], Train Loss: 0.1933, Validation Loss: 0.1961
Epoch [191/250], Train Loss: 0.1928, Validation Loss: 0.1956
Epoch [192/250], Train Loss: 0.1922, Validation Loss: 0.1951
Epoch [193/250], Train Loss: 0.1917, Validation Loss: 0.1945
Epoch [194/250], Train Loss: 0.1912, Validation Loss: 0.1940
Epoch [195/250], Train Loss: 0.1907, Validation Loss: 0.1935
Epoch [196/250], Train Loss: 0.1902, Validation Loss: 0.1930
Epoch [197/250], Train Loss: 0.1897, Validation Loss: 0.1925
Epoch [198/250], Train Loss: 0.1892, Validation Loss: 0.1920
Epoch [199/250], Train Loss: 0.1886, Validation Loss: 0.1914
Epoch [200/250], Train Loss: 0.1882, Validation Loss: 0.1909
Epoch [201/250], Train Loss: 0.1876, Validation Loss: 0.1904
Epoch [202/250], Train Loss: 0.1871, Validation Loss: 0.1899
Epoch [203/250], Train Loss: 0.1867, Validation Loss: 0.1894
Epoch [204/250], Train Loss: 0.1861, Validation Loss: 0.1889
Epoch [205/250], Train Loss: 0.1856, Validation Loss: 0.1884
Epoch [206/250], Train Loss: 0.1851, Validation Loss: 0.1878
Epoch [207/250], Train Loss: 0.1846, Validation Loss: 0.1873
Epoch [208/250], Train Loss: 0.1841, Validation Loss: 0.1868
Epoch [209/250], Train Loss: 0.1836, Validation Loss: 0.1863
Epoch [210/250], Train Loss: 0.1831, Validation Loss: 0.1858
Epoch [211/250], Train Loss: 0.1826, Validation Loss: 0.1853
Epoch [212/250], Train Loss: 0.1821, Validation Loss: 0.1848
Epoch [213/250], Train Loss: 0.1816, Validation Loss: 0.1844
Epoch [214/250], Train Loss: 0.1811, Validation Loss: 0.1839
Epoch [215/250], Train Loss: 0.1807, Validation Loss: 0.1833
Epoch [216/250], Train Loss: 0.1802, Validation Loss: 0.1829
Epoch [217/250], Train Loss: 0.1797, Validation Loss: 0.1824
Epoch [218/250], Train Loss: 0.1792, Validation Loss: 0.1819
Epoch [219/250], Train Loss: 0.1788, Validation Loss: 0.1814
Epoch [220/250], Train Loss: 0.1783, Validation Loss: 0.1809
Epoch [221/250], Train Loss: 0.1778, Validation Loss: 0.1804
Epoch [222/250], Train Loss: 0.1773, Validation Loss: 0.1799
Epoch [223/250], Train Loss: 0.1768, Validation Loss: 0.1794
Epoch [224/250], Train Loss: 0.1764, Validation Loss: 0.1790
Epoch [225/250], Train Loss: 0.1759, Validation Loss: 0.1785
Epoch [226/250], Train Loss: 0.1754, Validation Loss: 0.1780
Epoch [227/250], Train Loss: 0.1750, Validation Loss: 0.1776
Epoch [228/250], Train Loss: 0.1745, Validation Loss: 0.1771
Epoch [229/250], Train Loss: 0.1740, Validation Loss: 0.1766
Epoch [230/250], Train Loss: 0.1736, Validation Loss: 0.1761
Epoch [231/250], Train Loss: 0.1731, Validation Loss: 0.1757
Epoch [232/250], Train Loss: 0.1727, Validation Loss: 0.1752
Epoch [233/250], Train Loss: 0.1722, Validation Loss: 0.1747
Epoch [234/250], Train Loss: 0.1717, Validation Loss: 0.1743
Epoch [235/250], Train Loss: 0.1712, Validation Loss: 0.1738
Epoch [236/250], Train Loss: 0.1708, Validation Loss: 0.1733
Epoch [237/250], Train Loss: 0.1703, Validation Loss: 0.1729
Epoch [238/250], Train Loss: 0.1699, Validation Loss: 0.1724
Epoch [239/250], Train Loss: 0.1695, Validation Loss: 0.1720
Epoch [240/250], Train Loss: 0.1690, Validation Loss: 0.1715
Epoch [241/250], Train Loss: 0.1686, Validation Loss: 0.1711
Epoch [242/250], Train Loss: 0.1681, Validation Loss: 0.1706
Epoch [243/250], Train Loss: 0.1677, Validation Loss: 0.1702
Epoch [244/250], Train Loss: 0.1672, Validation Loss: 0.1697
Epoch [245/250], Train Loss: 0.1668, Validation Loss: 0.1693
Epoch [246/250], Train Loss: 0.1664, Validation Loss: 0.1688
Epoch [247/250], Train Loss: 0.1659, Validation Loss: 0.1684
Epoch [248/250], Train Loss: 0.1655, Validation Loss: 0.1680
Epoch [249/250], Train Loss: 0.1651, Validation Loss: 0.1675
Epoch [250/250], Train Loss: 0.1646, Validation Loss: 0.1671

Finished Training in 81.8

Noise Sigma:  0.5075
Creating datasets...
Start training...
Epoch [1/250], Train Loss: 0.3740, Validation Loss: 0.3247
Epoch [2/250], Train Loss: 0.3151, Validation Loss: 0.3272
Epoch [3/250], Train Loss: 0.3437, Validation Loss: 0.3222
Epoch [4/250], Train Loss: 0.3156, Validation Loss: 0.3186
Epoch [5/250], Train Loss: 0.3142, Validation Loss: 0.3075
Epoch [6/250], Train Loss: 0.3117, Validation Loss: 0.3078
Epoch [7/250], Train Loss: 0.2995, Validation Loss: 0.3126
Epoch [8/250], Train Loss: 0.3027, Validation Loss: 0.3123
Epoch [9/250], Train Loss: 0.2962, Validation Loss: 0.2935
Epoch [10/250], Train Loss: 0.2904, Validation Loss: 0.2893
Epoch [11/250], Train Loss: 0.2774, Validation Loss: 0.2854
Epoch [12/250], Train Loss: 0.2901, Validation Loss: 0.2792
Epoch [13/250], Train Loss: 0.2691, Validation Loss: 0.2821
Epoch [14/250], Train Loss: 0.2787, Validation Loss: 0.2700
Epoch [15/250], Train Loss: 0.2663, Validation Loss: 0.2697
Epoch [16/250], Train Loss: 0.2540, Validation Loss: 0.2590
Epoch [17/250], Train Loss: 0.2483, Validation Loss: 0.2531
Epoch [18/250], Train Loss: 0.2552, Validation Loss: 0.2497
Epoch [19/250], Train Loss: 0.2406, Validation Loss: 0.2533
Epoch [20/250], Train Loss: 0.2325, Validation Loss: 0.2277
Epoch [21/250], Train Loss: 0.2314, Validation Loss: 0.2255
Epoch [22/250], Train Loss: 0.2246, Validation Loss: 0.2207
Epoch [23/250], Train Loss: 0.2195, Validation Loss: 0.2185
Epoch [24/250], Train Loss: 0.2196, Validation Loss: 0.2151
Epoch [25/250], Train Loss: 0.2185, Validation Loss: 0.2159
Epoch [26/250], Train Loss: 0.2139, Validation Loss: 0.2171
Epoch [27/250], Train Loss: 0.2198, Validation Loss: 0.2175
Epoch [28/250], Train Loss: 0.2094, Validation Loss: 0.2163
Epoch [29/250], Train Loss: 0.2152, Validation Loss: 0.2141
Epoch [30/250], Train Loss: 0.2157, Validation Loss: 0.2130
Epoch [31/250], Train Loss: 0.2048, Validation Loss: 0.2108
Epoch [32/250], Train Loss: 0.2154, Validation Loss: 0.2125
Epoch [33/250], Train Loss: 0.2060, Validation Loss: 0.2117
Epoch [34/250], Train Loss: 0.2071, Validation Loss: 0.2150
Epoch [35/250], Train Loss: 0.2099, Validation Loss: 0.2079
Epoch [36/250], Train Loss: 0.2044, Validation Loss: 0.2028
Epoch [37/250], Train Loss: 0.2186, Validation Loss: 0.2103
Epoch [38/250], Train Loss: 0.2007, Validation Loss: 0.2120
Epoch [39/250], Train Loss: 0.2124, Validation Loss: 0.2075
Epoch [40/250], Train Loss: 0.1968, Validation Loss: 0.2062
Epoch [41/250], Train Loss: 0.1989, Validation Loss: 0.1982
Epoch [42/250], Train Loss: 0.2026, Validation Loss: 0.2042
Epoch [43/250], Train Loss: 0.2058, Validation Loss: 0.1935
Epoch [44/250], Train Loss: 0.2045, Validation Loss: 0.2081
Epoch [45/250], Train Loss: 0.2044, Validation Loss: 0.2116
Epoch [46/250], Train Loss: 0.2219, Validation Loss: 0.2207
Epoch [47/250], Train Loss: 0.2071, Validation Loss: 0.2102
Epoch [48/250], Train Loss: 0.2052, Validation Loss: 0.2036
Epoch [49/250], Train Loss: 0.2037, Validation Loss: 0.2229
Epoch [50/250], Train Loss: 0.2218, Validation Loss: 0.2047
Epoch [51/250], Train Loss: 0.1993, Validation Loss: 0.2402
Epoch [52/250], Train Loss: 0.1999, Validation Loss: 0.2031
Epoch [53/250], Train Loss: 0.1985, Validation Loss: 0.2075
Epoch [54/250], Train Loss: 0.2054, Validation Loss: 0.2002
Epoch [55/250], Train Loss: 0.1984, Validation Loss: 0.1974
Epoch [56/250], Train Loss: 0.2062, Validation Loss: 0.1991
Epoch [57/250], Train Loss: 0.1979, Validation Loss: 0.1957
Epoch [58/250], Train Loss: 0.1970, Validation Loss: 0.1971
Epoch [59/250], Train Loss: 0.1911, Validation Loss: 0.2024
Epoch [60/250], Train Loss: 0.2054, Validation Loss: 0.1936
Epoch [61/250], Train Loss: 0.1965, Validation Loss: 0.1973
Epoch [62/250], Train Loss: 0.1886, Validation Loss: 0.1960
Epoch [63/250], Train Loss: 0.1994, Validation Loss: 0.1919
Epoch [64/250], Train Loss: 0.1975, Validation Loss: 0.1923
Epoch [65/250], Train Loss: 0.1999, Validation Loss: 0.1938
Epoch [66/250], Train Loss: 0.1950, Validation Loss: 0.1940
Epoch [67/250], Train Loss: 0.1893, Validation Loss: 0.1940
Epoch [68/250], Train Loss: 0.1862, Validation Loss: 0.1856
Epoch [69/250], Train Loss: 0.1823, Validation Loss: 0.1922
Epoch [70/250], Train Loss: 0.1949, Validation Loss: 0.1839
Epoch [71/250], Train Loss: 0.1833, Validation Loss: 0.1902
Epoch [72/250], Train Loss: 0.1858, Validation Loss: 0.1879
Epoch [73/250], Train Loss: 0.1946, Validation Loss: 0.1884
Epoch [74/250], Train Loss: 0.1919, Validation Loss: 0.1882
Epoch [75/250], Train Loss: 0.1989, Validation Loss: 0.1917
Epoch [76/250], Train Loss: 0.1930, Validation Loss: 0.1923
Epoch [77/250], Train Loss: 0.1863, Validation Loss: 0.1886
Epoch [78/250], Train Loss: 0.1803, Validation Loss: 0.1854
Epoch [79/250], Train Loss: 0.1807, Validation Loss: 0.1901
Epoch [80/250], Train Loss: 0.1848, Validation Loss: 0.1805
Epoch [81/250], Train Loss: 0.1898, Validation Loss: 0.1855
Epoch [82/250], Train Loss: 0.1758, Validation Loss: 0.1854
Epoch [83/250], Train Loss: 0.1840, Validation Loss: 0.1881
Epoch [84/250], Train Loss: 0.1789, Validation Loss: 0.1889
Epoch [85/250], Train Loss: 0.1984, Validation Loss: 0.1899
Epoch [86/250], Train Loss: 0.1811, Validation Loss: 0.1807
Epoch [87/250], Train Loss: 0.1853, Validation Loss: 0.1965
Epoch [88/250], Train Loss: 0.1852, Validation Loss: 0.1882
Epoch [89/250], Train Loss: 0.1923, Validation Loss: 0.1831
Epoch [90/250], Train Loss: 0.1819, Validation Loss: 0.1857
Epoch [91/250], Train Loss: 0.1764, Validation Loss: 0.1849
Epoch [92/250], Train Loss: 0.1875, Validation Loss: 0.1831
Epoch [93/250], Train Loss: 0.1792, Validation Loss: 0.1836
Epoch [94/250], Train Loss: 0.1844, Validation Loss: 0.1797
Epoch [95/250], Train Loss: 0.1835, Validation Loss: 0.1777
Epoch [96/250], Train Loss: 0.1745, Validation Loss: 0.1797
Epoch [97/250], Train Loss: 0.1782, Validation Loss: 0.1789
Epoch [98/250], Train Loss: 0.1754, Validation Loss: 0.1734
Epoch [99/250], Train Loss: 0.1715, Validation Loss: 0.1869
Epoch [100/250], Train Loss: 0.1753, Validation Loss: 0.1705
Epoch [101/250], Train Loss: 0.1761, Validation Loss: 0.1750
Epoch [102/250], Train Loss: 0.1792, Validation Loss: 0.1657
Epoch [103/250], Train Loss: 0.1689, Validation Loss: 0.1727
Epoch [104/250], Train Loss: 0.1670, Validation Loss: 0.1710
Epoch [105/250], Train Loss: 0.1767, Validation Loss: 0.1665
Epoch [106/250], Train Loss: 0.1655, Validation Loss: 0.1777
Epoch [107/250], Train Loss: 0.1682, Validation Loss: 0.1716
Epoch [108/250], Train Loss: 0.1745, Validation Loss: 0.1759
Epoch [109/250], Train Loss: 0.1786, Validation Loss: 0.1713
Epoch [110/250], Train Loss: 0.1812, Validation Loss: 0.1714
Epoch [111/250], Train Loss: 0.1701, Validation Loss: 0.1728
Epoch [112/250], Train Loss: 0.1678, Validation Loss: 0.1737
Epoch [113/250], Train Loss: 0.1708, Validation Loss: 0.1617
Epoch [114/250], Train Loss: 0.1636, Validation Loss: 0.1730
Epoch [115/250], Train Loss: 0.1614, Validation Loss: 0.1677
Epoch [116/250], Train Loss: 0.1651, Validation Loss: 0.1729
Epoch [117/250], Train Loss: 0.1680, Validation Loss: 0.1589
Epoch [118/250], Train Loss: 0.1603, Validation Loss: 0.1645
Epoch [119/250], Train Loss: 0.1577, Validation Loss: 0.1668
Epoch [120/250], Train Loss: 0.1671, Validation Loss: 0.1620
Epoch [121/250], Train Loss: 0.1628, Validation Loss: 0.1665
Epoch [122/250], Train Loss: 0.1652, Validation Loss: 0.1619
Epoch [123/250], Train Loss: 0.1563, Validation Loss: 0.1600
Epoch [124/250], Train Loss: 0.1612, Validation Loss: 0.1570
Epoch [125/250], Train Loss: 0.1641, Validation Loss: 0.1660
Epoch [126/250], Train Loss: 0.1599, Validation Loss: 0.1637
Epoch [127/250], Train Loss: 0.1541, Validation Loss: 0.1735
Epoch [128/250], Train Loss: 0.1748, Validation Loss: 0.1630
Epoch [129/250], Train Loss: 0.1615, Validation Loss: 0.1810
Epoch [130/250], Train Loss: 0.1667, Validation Loss: 0.1574
Epoch [131/250], Train Loss: 0.1588, Validation Loss: 0.1577
Epoch [132/250], Train Loss: 0.1591, Validation Loss: 0.1642
Epoch [133/250], Train Loss: 0.1570, Validation Loss: 0.1663
Epoch [134/250], Train Loss: 0.1576, Validation Loss: 0.1567
Epoch [135/250], Train Loss: 0.1556, Validation Loss: 0.1576
Epoch [136/250], Train Loss: 0.1541, Validation Loss: 0.1614
Epoch [137/250], Train Loss: 0.1644, Validation Loss: 0.1625
Epoch [138/250], Train Loss: 0.1521, Validation Loss: 0.1627
Epoch [139/250], Train Loss: 0.1482, Validation Loss: 0.1605
Epoch [140/250], Train Loss: 0.1520, Validation Loss: 0.1665
Epoch [141/250], Train Loss: 0.1537, Validation Loss: 0.1559
Epoch [142/250], Train Loss: 0.1562, Validation Loss: 0.1526
Epoch [143/250], Train Loss: 0.1540, Validation Loss: 0.1598
Epoch [144/250], Train Loss: 0.1564, Validation Loss: 0.1566
Epoch [145/250], Train Loss: 0.1534, Validation Loss: 0.1546
Epoch [146/250], Train Loss: 0.1606, Validation Loss: 0.1660
Epoch [147/250], Train Loss: 0.1475, Validation Loss: 0.1526
Epoch [148/250], Train Loss: 0.1518, Validation Loss: 0.1559
Epoch [149/250], Train Loss: 0.1507, Validation Loss: 0.1489
Epoch [150/250], Train Loss: 0.1587, Validation Loss: 0.1447
Epoch [151/250], Train Loss: 0.1543, Validation Loss: 0.1515
Epoch [152/250], Train Loss: 0.1504, Validation Loss: 0.1564
Epoch [153/250], Train Loss: 0.1612, Validation Loss: 0.1504
Epoch [154/250], Train Loss: 0.1470, Validation Loss: 0.1583
Epoch [155/250], Train Loss: 0.1495, Validation Loss: 0.1505
Epoch [156/250], Train Loss: 0.1537, Validation Loss: 0.1559
Epoch [157/250], Train Loss: 0.1457, Validation Loss: 0.1477
Epoch [158/250], Train Loss: 0.1512, Validation Loss: 0.1481
Epoch [159/250], Train Loss: 0.1523, Validation Loss: 0.1432
Epoch [160/250], Train Loss: 0.1474, Validation Loss: 0.1522
Epoch [161/250], Train Loss: 0.1522, Validation Loss: 0.1494
Epoch [162/250], Train Loss: 0.1452, Validation Loss: 0.1489
Epoch [163/250], Train Loss: 0.1495, Validation Loss: 0.1422
Epoch [164/250], Train Loss: 0.1454, Validation Loss: 0.1514
Epoch [165/250], Train Loss: 0.1426, Validation Loss: 0.1441
Epoch [166/250], Train Loss: 0.1448, Validation Loss: 0.1481
Epoch [167/250], Train Loss: 0.1464, Validation Loss: 0.1519
Epoch [168/250], Train Loss: 0.1380, Validation Loss: 0.1404
Epoch [169/250], Train Loss: 0.1384, Validation Loss: 0.1489
Epoch [170/250], Train Loss: 0.1388, Validation Loss: 0.1437
Epoch [171/250], Train Loss: 0.1464, Validation Loss: 0.1432
Epoch [172/250], Train Loss: 0.1405, Validation Loss: 0.1467
Epoch [173/250], Train Loss: 0.1400, Validation Loss: 0.1486
Epoch [174/250], Train Loss: 0.1463, Validation Loss: 0.1541
Epoch [175/250], Train Loss: 0.1496, Validation Loss: 0.1458
Epoch [176/250], Train Loss: 0.1463, Validation Loss: 0.1528
Epoch [177/250], Train Loss: 0.1387, Validation Loss: 0.1510
Epoch [178/250], Train Loss: 0.1402, Validation Loss: 0.1422
Epoch [179/250], Train Loss: 0.1422, Validation Loss: 0.1450
Epoch [180/250], Train Loss: 0.1425, Validation Loss: 0.1351
Epoch [181/250], Train Loss: 0.1384, Validation Loss: 0.1415
Epoch [182/250], Train Loss: 0.1413, Validation Loss: 0.1439
Epoch [183/250], Train Loss: 0.1351, Validation Loss: 0.1389
Epoch [184/250], Train Loss: 0.1449, Validation Loss: 0.1389
Epoch [185/250], Train Loss: 0.1367, Validation Loss: 0.1331
Epoch [186/250], Train Loss: 0.1340, Validation Loss: 0.1299
Epoch [187/250], Train Loss: 0.1334, Validation Loss: 0.1480
Epoch [188/250], Train Loss: 0.1406, Validation Loss: 0.1347
Epoch [189/250], Train Loss: 0.1340, Validation Loss: 0.1416
Epoch [190/250], Train Loss: 0.1407, Validation Loss: 0.1382
Epoch [191/250], Train Loss: 0.1281, Validation Loss: 0.1285
Epoch [192/250], Train Loss: 0.1341, Validation Loss: 0.1328
Epoch [193/250], Train Loss: 0.1303, Validation Loss: 0.1349
Epoch [194/250], Train Loss: 0.1340, Validation Loss: 0.1319
Epoch [195/250], Train Loss: 0.1314, Validation Loss: 0.1267
Epoch [196/250], Train Loss: 0.1270, Validation Loss: 0.1307
Epoch [197/250], Train Loss: 0.1337, Validation Loss: 0.1322
Epoch [198/250], Train Loss: 0.1342, Validation Loss: 0.1362
Epoch [199/250], Train Loss: 0.1282, Validation Loss: 0.1305
Epoch [200/250], Train Loss: 0.1273, Validation Loss: 0.1288
Epoch [201/250], Train Loss: 0.1237, Validation Loss: 0.1276
Epoch [202/250], Train Loss: 0.1272, Validation Loss: 0.1307
Epoch [203/250], Train Loss: 0.1232, Validation Loss: 0.1285
Epoch [204/250], Train Loss: 0.1300, Validation Loss: 0.1328
Epoch [205/250], Train Loss: 0.1257, Validation Loss: 0.1285
Epoch [206/250], Train Loss: 0.1265, Validation Loss: 0.1320
Epoch [207/250], Train Loss: 0.1244, Validation Loss: 0.1298
Epoch [208/250], Train Loss: 0.1313, Validation Loss: 0.1287
Epoch [209/250], Train Loss: 0.1351, Validation Loss: 0.1351
Epoch [210/250], Train Loss: 0.1231, Validation Loss: 0.1275
Epoch [211/250], Train Loss: 0.1269, Validation Loss: 0.1245
Epoch [212/250], Train Loss: 0.1269, Validation Loss: 0.1411
Epoch [213/250], Train Loss: 0.1353, Validation Loss: 0.1290
Epoch [214/250], Train Loss: 0.1282, Validation Loss: 0.1458
Epoch [215/250], Train Loss: 0.1376, Validation Loss: 0.1256
Epoch [216/250], Train Loss: 0.1243, Validation Loss: 0.1257
Epoch [217/250], Train Loss: 0.1207, Validation Loss: 0.1273
Epoch [218/250], Train Loss: 0.1223, Validation Loss: 0.1267
Epoch [219/250], Train Loss: 0.1200, Validation Loss: 0.1192
Epoch [220/250], Train Loss: 0.1183, Validation Loss: 0.1209
Epoch [221/250], Train Loss: 0.1175, Validation Loss: 0.1242
Epoch [222/250], Train Loss: 0.1196, Validation Loss: 0.1209
Epoch [223/250], Train Loss: 0.1142, Validation Loss: 0.1244
Epoch [224/250], Train Loss: 0.1158, Validation Loss: 0.1183
Epoch [225/250], Train Loss: 0.1167, Validation Loss: 0.1225
Epoch [226/250], Train Loss: 0.1148, Validation Loss: 0.1195
Epoch [227/250], Train Loss: 0.1137, Validation Loss: 0.1190
Epoch [228/250], Train Loss: 0.1154, Validation Loss: 0.1199
Epoch [229/250], Train Loss: 0.1120, Validation Loss: 0.1191
Epoch [230/250], Train Loss: 0.1159, Validation Loss: 0.1204
Epoch [231/250], Train Loss: 0.1115, Validation Loss: 0.1182
Epoch [232/250], Train Loss: 0.1162, Validation Loss: 0.1147
Epoch [233/250], Train Loss: 0.1142, Validation Loss: 0.1152
Epoch [234/250], Train Loss: 0.1148, Validation Loss: 0.1173
Epoch [235/250], Train Loss: 0.1152, Validation Loss: 0.1148
Epoch [236/250], Train Loss: 0.1142, Validation Loss: 0.1147
Epoch [237/250], Train Loss: 0.1128, Validation Loss: 0.1130
Epoch [238/250], Train Loss: 0.1149, Validation Loss: 0.1194
Epoch [239/250], Train Loss: 0.1098, Validation Loss: 0.1123
Epoch [240/250], Train Loss: 0.1103, Validation Loss: 0.1155
Epoch [241/250], Train Loss: 0.1138, Validation Loss: 0.1152
Epoch [242/250], Train Loss: 0.1142, Validation Loss: 0.1129
Epoch [243/250], Train Loss: 0.1098, Validation Loss: 0.1161
Epoch [244/250], Train Loss: 0.1128, Validation Loss: 0.1158
Epoch [245/250], Train Loss: 0.1108, Validation Loss: 0.1101
Epoch [246/250], Train Loss: 0.1114, Validation Loss: 0.1098
Epoch [247/250], Train Loss: 0.1093, Validation Loss: 0.1141
Epoch [248/250], Train Loss: 0.1082, Validation Loss: 0.1131
Epoch [249/250], Train Loss: 0.1101, Validation Loss: 0.1113
Epoch [250/250], Train Loss: 0.1070, Validation Loss: 0.1107

Finished Training in 81.2

Noise Sigma:  1.005
Creating datasets...
Start training...
Epoch [1/250], Train Loss: 0.3990, Validation Loss: 0.4184
Epoch [2/250], Train Loss: 0.4145, Validation Loss: 0.4109
Epoch [3/250], Train Loss: 0.3521, Validation Loss: 0.3315
Epoch [4/250], Train Loss: 0.2594, Validation Loss: 0.3703
Epoch [5/250], Train Loss: 0.3469, Validation Loss: 0.3687
Epoch [6/250], Train Loss: 0.2779, Validation Loss: 0.3334
Epoch [7/250], Train Loss: 0.2963, Validation Loss: 0.2860
Epoch [8/250], Train Loss: 0.2691, Validation Loss: 0.3040
Epoch [9/250], Train Loss: 0.2832, Validation Loss: 0.2944
Epoch [10/250], Train Loss: 0.2442, Validation Loss: 0.2696
Epoch [11/250], Train Loss: 0.2280, Validation Loss: 0.2798
Epoch [12/250], Train Loss: 0.2544, Validation Loss: 0.2468
Epoch [13/250], Train Loss: 0.2323, Validation Loss: 0.2307
Epoch [14/250], Train Loss: 0.2039, Validation Loss: 0.2602
Epoch [15/250], Train Loss: 0.2265, Validation Loss: 0.2243
Epoch [16/250], Train Loss: 0.2238, Validation Loss: 0.2390
Epoch [17/250], Train Loss: 0.2060, Validation Loss: 0.2108
Epoch [18/250], Train Loss: 0.2143, Validation Loss: 0.2243
Epoch [19/250], Train Loss: 0.2233, Validation Loss: 0.2283
Epoch [20/250], Train Loss: 0.1842, Validation Loss: 0.2385
Epoch [21/250], Train Loss: 0.1870, Validation Loss: 0.2157
Epoch [22/250], Train Loss: 0.1797, Validation Loss: 0.1947
Epoch [23/250], Train Loss: 0.1852, Validation Loss: 0.2271
Epoch [24/250], Train Loss: 0.1818, Validation Loss: 0.2116
Epoch [25/250], Train Loss: 0.1951, Validation Loss: 0.2018
Epoch [26/250], Train Loss: 0.1760, Validation Loss: 0.1908
Epoch [27/250], Train Loss: 0.1733, Validation Loss: 0.1934
Epoch [28/250], Train Loss: 0.1751, Validation Loss: 0.1917
Epoch [29/250], Train Loss: 0.1734, Validation Loss: 0.1848
Epoch [30/250], Train Loss: 0.1635, Validation Loss: 0.2013
Epoch [31/250], Train Loss: 0.1619, Validation Loss: 0.1815
Epoch [32/250], Train Loss: 0.1544, Validation Loss: 0.1659
Epoch [33/250], Train Loss: 0.1630, Validation Loss: 0.1865
Epoch [34/250], Train Loss: 0.1787, Validation Loss: 0.2119
Epoch [35/250], Train Loss: 0.1545, Validation Loss: 0.2099
Epoch [36/250], Train Loss: 0.1557, Validation Loss: 0.1956
Epoch [37/250], Train Loss: 0.1589, Validation Loss: 0.1656
Epoch [38/250], Train Loss: 0.1572, Validation Loss: 0.1879
Epoch [39/250], Train Loss: 0.1669, Validation Loss: 0.1856
Epoch [40/250], Train Loss: 0.1580, Validation Loss: 0.1814
Epoch [41/250], Train Loss: 0.1674, Validation Loss: 0.1768
Epoch [42/250], Train Loss: 0.1497, Validation Loss: 0.1886
Epoch [43/250], Train Loss: 0.1652, Validation Loss: 0.1775
Epoch [44/250], Train Loss: 0.1503, Validation Loss: 0.1779
Epoch [45/250], Train Loss: 0.1649, Validation Loss: 0.1928
Epoch [46/250], Train Loss: 0.1458, Validation Loss: 0.1808
Epoch [47/250], Train Loss: 0.1613, Validation Loss: 0.1850
Epoch [48/250], Train Loss: 0.1447, Validation Loss: 0.2047
Epoch [49/250], Train Loss: 0.1565, Validation Loss: 0.1556
Epoch [50/250], Train Loss: 0.1566, Validation Loss: 0.1781
Epoch [51/250], Train Loss: 0.1521, Validation Loss: 0.1764
Epoch [52/250], Train Loss: 0.1462, Validation Loss: 0.1998
Epoch [53/250], Train Loss: 0.1608, Validation Loss: 0.2148
Epoch [54/250], Train Loss: 0.1515, Validation Loss: 0.1876
Epoch [55/250], Train Loss: 0.1602, Validation Loss: 0.1883
Epoch [56/250], Train Loss: 0.1407, Validation Loss: 0.1980
Epoch [57/250], Train Loss: 0.1479, Validation Loss: 0.1746
Epoch [58/250], Train Loss: 0.1438, Validation Loss: 0.1765
Epoch [59/250], Train Loss: 0.1325, Validation Loss: 0.1843
Epoch [60/250], Train Loss: 0.1364, Validation Loss: 0.1584
Epoch [61/250], Train Loss: 0.1418, Validation Loss: 0.1765
Epoch [62/250], Train Loss: 0.1490, Validation Loss: 0.1619
Epoch [63/250], Train Loss: 0.1376, Validation Loss: 0.1659
Epoch [64/250], Train Loss: 0.1298, Validation Loss: 0.1733
Epoch [65/250], Train Loss: 0.1293, Validation Loss: 0.1644
Epoch [66/250], Train Loss: 0.1299, Validation Loss: 0.1700
Epoch [67/250], Train Loss: 0.1296, Validation Loss: 0.1720
Epoch [68/250], Train Loss: 0.1402, Validation Loss: 0.1619
Epoch [69/250], Train Loss: 0.1374, Validation Loss: 0.1964
Epoch [70/250], Train Loss: 0.1358, Validation Loss: 0.1696
Epoch [71/250], Train Loss: 0.1269, Validation Loss: 0.1696
Epoch [72/250], Train Loss: 0.1277, Validation Loss: 0.1619
Epoch [73/250], Train Loss: 0.1294, Validation Loss: 0.1569
Epoch [74/250], Train Loss: 0.1377, Validation Loss: 0.1711
Epoch [75/250], Train Loss: 0.1404, Validation Loss: 0.1663
Epoch [76/250], Train Loss: 0.1293, Validation Loss: 0.1539
Epoch [77/250], Train Loss: 0.1314, Validation Loss: 0.1795
Epoch [78/250], Train Loss: 0.1600, Validation Loss: 0.2245
Epoch [79/250], Train Loss: 0.1508, Validation Loss: 0.1690
Epoch [80/250], Train Loss: 0.1477, Validation Loss: 0.1602
Epoch [81/250], Train Loss: 0.1279, Validation Loss: 0.1624
Epoch [82/250], Train Loss: 0.1458, Validation Loss: 0.1412
Epoch [83/250], Train Loss: 0.1249, Validation Loss: 0.1760
Epoch [84/250], Train Loss: 0.1323, Validation Loss: 0.1660
Epoch [85/250], Train Loss: 0.1306, Validation Loss: 0.1460
Epoch [86/250], Train Loss: 0.1195, Validation Loss: 0.1751
Epoch [87/250], Train Loss: 0.1215, Validation Loss: 0.1539
Epoch [88/250], Train Loss: 0.1249, Validation Loss: 0.1447
Epoch [89/250], Train Loss: 0.1392, Validation Loss: 0.1693
Epoch [90/250], Train Loss: 0.1217, Validation Loss: 0.1431
Epoch [91/250], Train Loss: 0.1190, Validation Loss: 0.1554
Epoch [92/250], Train Loss: 0.1234, Validation Loss: 0.1555
Epoch [93/250], Train Loss: 0.1306, Validation Loss: 0.1630
Epoch [94/250], Train Loss: 0.1188, Validation Loss: 0.1432
Epoch [95/250], Train Loss: 0.1234, Validation Loss: 0.1471
Epoch [96/250], Train Loss: 0.1246, Validation Loss: 0.1458
Epoch [97/250], Train Loss: 0.1140, Validation Loss: 0.1442
Epoch [98/250], Train Loss: 0.1164, Validation Loss: 0.1572
Epoch [99/250], Train Loss: 0.1096, Validation Loss: 0.1412
Epoch [100/250], Train Loss: 0.1151, Validation Loss: 0.1412
Epoch [101/250], Train Loss: 0.1206, Validation Loss: 0.1538
Epoch [102/250], Train Loss: 0.1105, Validation Loss: 0.1432
Epoch [103/250], Train Loss: 0.1024, Validation Loss: 0.1390
Epoch [104/250], Train Loss: 0.1145, Validation Loss: 0.1505
Epoch [105/250], Train Loss: 0.1133, Validation Loss: 0.1278
Epoch [106/250], Train Loss: 0.1336, Validation Loss: 0.1662
Epoch [107/250], Train Loss: 0.1344, Validation Loss: 0.1662
Epoch [108/250], Train Loss: 0.1260, Validation Loss: 0.1383
Epoch [109/250], Train Loss: 0.1282, Validation Loss: 0.1737
Epoch [110/250], Train Loss: 0.1291, Validation Loss: 0.1506
Epoch [111/250], Train Loss: 0.1150, Validation Loss: 0.1445
Epoch [112/250], Train Loss: 0.1223, Validation Loss: 0.1732
Epoch [113/250], Train Loss: 0.1119, Validation Loss: 0.1434
Epoch [114/250], Train Loss: 0.1352, Validation Loss: 0.1457
Epoch [115/250], Train Loss: 0.1265, Validation Loss: 0.2428
Epoch [116/250], Train Loss: 0.1664, Validation Loss: 0.1341
Epoch [117/250], Train Loss: 0.1314, Validation Loss: 0.1402
Epoch [118/250], Train Loss: 0.1460, Validation Loss: 0.1352
Epoch [119/250], Train Loss: 0.1212, Validation Loss: 0.1514
Epoch [120/250], Train Loss: 0.1230, Validation Loss: 0.1544
Epoch [121/250], Train Loss: 0.1248, Validation Loss: 0.1536
Epoch [122/250], Train Loss: 0.1155, Validation Loss: 0.1412
Epoch [123/250], Train Loss: 0.1164, Validation Loss: 0.1359
Epoch [124/250], Train Loss: 0.1140, Validation Loss: 0.1265
Epoch [125/250], Train Loss: 0.1239, Validation Loss: 0.1362
Epoch [126/250], Train Loss: 0.1175, Validation Loss: 0.1239
Epoch [127/250], Train Loss: 0.1072, Validation Loss: 0.1354
Epoch [128/250], Train Loss: 0.1080, Validation Loss: 0.1357
Epoch [129/250], Train Loss: 0.1073, Validation Loss: 0.1109
Epoch [130/250], Train Loss: 0.1119, Validation Loss: 0.1303
Epoch [131/250], Train Loss: 0.0977, Validation Loss: 0.1328
Epoch [132/250], Train Loss: 0.1069, Validation Loss: 0.1211
Epoch [133/250], Train Loss: 0.1072, Validation Loss: 0.1326
Epoch [134/250], Train Loss: 0.1126, Validation Loss: 0.1290
Epoch [135/250], Train Loss: 0.1118, Validation Loss: 0.1243
Epoch [136/250], Train Loss: 0.1150, Validation Loss: 0.1196
Epoch [137/250], Train Loss: 0.1056, Validation Loss: 0.1398
Epoch [138/250], Train Loss: 0.0966, Validation Loss: 0.1290
Epoch [139/250], Train Loss: 0.1118, Validation Loss: 0.1254
Epoch [140/250], Train Loss: 0.1010, Validation Loss: 0.1365
Epoch [141/250], Train Loss: 0.1000, Validation Loss: 0.1311
Epoch [142/250], Train Loss: 0.1077, Validation Loss: 0.1279
Epoch [143/250], Train Loss: 0.1074, Validation Loss: 0.1164
Epoch [144/250], Train Loss: 0.1037, Validation Loss: 0.1214
Epoch [145/250], Train Loss: 0.0975, Validation Loss: 0.1268
Epoch [146/250], Train Loss: 0.1103, Validation Loss: 0.1255
Epoch [147/250], Train Loss: 0.0983, Validation Loss: 0.1490
Epoch [148/250], Train Loss: 0.0982, Validation Loss: 0.1325
Epoch [149/250], Train Loss: 0.1012, Validation Loss: 0.1394
Epoch [150/250], Train Loss: 0.0937, Validation Loss: 0.1159
Epoch [151/250], Train Loss: 0.1039, Validation Loss: 0.1267
Epoch [152/250], Train Loss: 0.0989, Validation Loss: 0.1213
Epoch [153/250], Train Loss: 0.1017, Validation Loss: 0.1179
Epoch [154/250], Train Loss: 0.1000, Validation Loss: 0.1290
Epoch [155/250], Train Loss: 0.1032, Validation Loss: 0.1223
Epoch [156/250], Train Loss: 0.1012, Validation Loss: 0.1262
Epoch [157/250], Train Loss: 0.0904, Validation Loss: 0.1143
Epoch [158/250], Train Loss: 0.0953, Validation Loss: 0.1132
Epoch [159/250], Train Loss: 0.0970, Validation Loss: 0.1255
Epoch [160/250], Train Loss: 0.0997, Validation Loss: 0.1233
Epoch [161/250], Train Loss: 0.0949, Validation Loss: 0.1119
Epoch [162/250], Train Loss: 0.0989, Validation Loss: 0.1187
Epoch [163/250], Train Loss: 0.1039, Validation Loss: 0.1309
Epoch [164/250], Train Loss: 0.0926, Validation Loss: 0.1342
Epoch [165/250], Train Loss: 0.1014, Validation Loss: 0.1277
Epoch [166/250], Train Loss: 0.0913, Validation Loss: 0.1313
Epoch [167/250], Train Loss: 0.0942, Validation Loss: 0.1300
Epoch [168/250], Train Loss: 0.0954, Validation Loss: 0.1048
Epoch [169/250], Train Loss: 0.0919, Validation Loss: 0.1110
Epoch [170/250], Train Loss: 0.0881, Validation Loss: 0.1102
Epoch [171/250], Train Loss: 0.0859, Validation Loss: 0.1097
Epoch [172/250], Train Loss: 0.0873, Validation Loss: 0.1156
Epoch [173/250], Train Loss: 0.0875, Validation Loss: 0.1359
Epoch [174/250], Train Loss: 0.0992, Validation Loss: 0.1054
Epoch [175/250], Train Loss: 0.0873, Validation Loss: 0.1172
Epoch [176/250], Train Loss: 0.0877, Validation Loss: 0.1048
Epoch [177/250], Train Loss: 0.0878, Validation Loss: 0.1062
Epoch [178/250], Train Loss: 0.0913, Validation Loss: 0.1241
Epoch [179/250], Train Loss: 0.0946, Validation Loss: 0.1057
Epoch [180/250], Train Loss: 0.0868, Validation Loss: 0.1021
Epoch [181/250], Train Loss: 0.0969, Validation Loss: 0.1078
Epoch [182/250], Train Loss: 0.0940, Validation Loss: 0.1273
Epoch [183/250], Train Loss: 0.0865, Validation Loss: 0.1137
Epoch [184/250], Train Loss: 0.0888, Validation Loss: 0.1059
Epoch [185/250], Train Loss: 0.0857, Validation Loss: 0.1217
Epoch [186/250], Train Loss: 0.0807, Validation Loss: 0.1161
Epoch [187/250], Train Loss: 0.0851, Validation Loss: 0.1085
Epoch [188/250], Train Loss: 0.0831, Validation Loss: 0.1215
Epoch [189/250], Train Loss: 0.0996, Validation Loss: 0.1232
Epoch [190/250], Train Loss: 0.1002, Validation Loss: 0.1270
Epoch [191/250], Train Loss: 0.0929, Validation Loss: 0.1245
Epoch [192/250], Train Loss: 0.0875, Validation Loss: 0.0996
Epoch [193/250], Train Loss: 0.1005, Validation Loss: 0.1153
Epoch [194/250], Train Loss: 0.1430, Validation Loss: 0.1027
Epoch [195/250], Train Loss: 0.0955, Validation Loss: 0.1534
Epoch [196/250], Train Loss: 0.0917, Validation Loss: 0.1265
Epoch [197/250], Train Loss: 0.0913, Validation Loss: 0.1074
Epoch [198/250], Train Loss: 0.0789, Validation Loss: 0.1376
Epoch [199/250], Train Loss: 0.0934, Validation Loss: 0.1095
Epoch [200/250], Train Loss: 0.0935, Validation Loss: 0.1061
Epoch [201/250], Train Loss: 0.0814, Validation Loss: 0.1264
Epoch [202/250], Train Loss: 0.0879, Validation Loss: 0.1187
Epoch [203/250], Train Loss: 0.0859, Validation Loss: 0.1094
Epoch [204/250], Train Loss: 0.0824, Validation Loss: 0.0856
Epoch [205/250], Train Loss: 0.0868, Validation Loss: 0.1123
Epoch [206/250], Train Loss: 0.0819, Validation Loss: 0.1138
Epoch [207/250], Train Loss: 0.0944, Validation Loss: 0.1090
Epoch [208/250], Train Loss: 0.0885, Validation Loss: 0.1096
Epoch [209/250], Train Loss: 0.0872, Validation Loss: 0.1076
Epoch [210/250], Train Loss: 0.0848, Validation Loss: 0.0995
Epoch [211/250], Train Loss: 0.0787, Validation Loss: 0.1062
Epoch [212/250], Train Loss: 0.0807, Validation Loss: 0.1077
Epoch [213/250], Train Loss: 0.0849, Validation Loss: 0.1006
Epoch [214/250], Train Loss: 0.0891, Validation Loss: 0.0953
Epoch [215/250], Train Loss: 0.0844, Validation Loss: 0.1031
Epoch [216/250], Train Loss: 0.0786, Validation Loss: 0.1020
Epoch [217/250], Train Loss: 0.0827, Validation Loss: 0.0985
Epoch [218/250], Train Loss: 0.0802, Validation Loss: 0.1005
Epoch [219/250], Train Loss: 0.0782, Validation Loss: 0.1087
Epoch [220/250], Train Loss: 0.0797, Validation Loss: 0.1010
Epoch [221/250], Train Loss: 0.0849, Validation Loss: 0.0886
Epoch [222/250], Train Loss: 0.0761, Validation Loss: 0.0988
Epoch [223/250], Train Loss: 0.0747, Validation Loss: 0.1003
Epoch [224/250], Train Loss: 0.0818, Validation Loss: 0.1027
Epoch [225/250], Train Loss: 0.0755, Validation Loss: 0.0907
Epoch [226/250], Train Loss: 0.0812, Validation Loss: 0.0994
Epoch [227/250], Train Loss: 0.0727, Validation Loss: 0.0891
Epoch [228/250], Train Loss: 0.0742, Validation Loss: 0.0955
Epoch [229/250], Train Loss: 0.0715, Validation Loss: 0.0973
Epoch [230/250], Train Loss: 0.0758, Validation Loss: 0.0887
Epoch [231/250], Train Loss: 0.0783, Validation Loss: 0.1013
Epoch [232/250], Train Loss: 0.0797, Validation Loss: 0.0857
Epoch [233/250], Train Loss: 0.0775, Validation Loss: 0.0876
Epoch [234/250], Train Loss: 0.0737, Validation Loss: 0.0887
Epoch [235/250], Train Loss: 0.0723, Validation Loss: 0.0930
Epoch [236/250], Train Loss: 0.0798, Validation Loss: 0.0890
Epoch [237/250], Train Loss: 0.0689, Validation Loss: 0.0829
Epoch [238/250], Train Loss: 0.0745, Validation Loss: 0.0879
Epoch [239/250], Train Loss: 0.0740, Validation Loss: 0.0919
Epoch [240/250], Train Loss: 0.0723, Validation Loss: 0.0866
Epoch [241/250], Train Loss: 0.0749, Validation Loss: 0.0982
Epoch [242/250], Train Loss: 0.0682, Validation Loss: 0.1013
Epoch [243/250], Train Loss: 0.0824, Validation Loss: 0.0885
Epoch [244/250], Train Loss: 0.0752, Validation Loss: 0.0891
Epoch [245/250], Train Loss: 0.0743, Validation Loss: 0.0950
Epoch [246/250], Train Loss: 0.0705, Validation Loss: 0.0912
Epoch [247/250], Train Loss: 0.0801, Validation Loss: 0.0921
Epoch [248/250], Train Loss: 0.0703, Validation Loss: 0.0867
Epoch [249/250], Train Loss: 0.0660, Validation Loss: 0.0927
Epoch [250/250], Train Loss: 0.0696, Validation Loss: 0.0838

Finished Training in 81.0

Noise Sigma:  1.5025
Creating datasets...
Start training...
Epoch [1/250], Train Loss: 0.5190, Validation Loss: 0.3457
Epoch [2/250], Train Loss: 0.3304, Validation Loss: 0.3261
Epoch [3/250], Train Loss: 0.3133, Validation Loss: 0.3025
Epoch [4/250], Train Loss: 0.2671, Validation Loss: 0.2883
Epoch [5/250], Train Loss: 0.2702, Validation Loss: 0.3160
Epoch [6/250], Train Loss: 0.2639, Validation Loss: 0.3021
Epoch [7/250], Train Loss: 0.2490, Validation Loss: 0.2322
Epoch [8/250], Train Loss: 0.2359, Validation Loss: 0.2485
Epoch [9/250], Train Loss: 0.2276, Validation Loss: 0.2358
Epoch [10/250], Train Loss: 0.2284, Validation Loss: 0.2450
Epoch [11/250], Train Loss: 0.2206, Validation Loss: 0.2587
Epoch [12/250], Train Loss: 0.1797, Validation Loss: 0.2330
Epoch [13/250], Train Loss: 0.1969, Validation Loss: 0.2181
Epoch [14/250], Train Loss: 0.1840, Validation Loss: 0.2356
Epoch [15/250], Train Loss: 0.1762, Validation Loss: 0.2203
Epoch [16/250], Train Loss: 0.1785, Validation Loss: 0.2346
Epoch [17/250], Train Loss: 0.1593, Validation Loss: 0.2023
Epoch [18/250], Train Loss: 0.1839, Validation Loss: 0.1813
Epoch [19/250], Train Loss: 0.1727, Validation Loss: 0.2242
Epoch [20/250], Train Loss: 0.1970, Validation Loss: 0.1986
Epoch [21/250], Train Loss: 0.1597, Validation Loss: 0.1796
Epoch [22/250], Train Loss: 0.1642, Validation Loss: 0.1881
Epoch [23/250], Train Loss: 0.1572, Validation Loss: 0.1860
Epoch [24/250], Train Loss: 0.1578, Validation Loss: 0.2054
Epoch [25/250], Train Loss: 0.1611, Validation Loss: 0.1917
Epoch [26/250], Train Loss: 0.1570, Validation Loss: 0.1982
Epoch [27/250], Train Loss: 0.1594, Validation Loss: 0.1827
Epoch [28/250], Train Loss: 0.1580, Validation Loss: 0.2234
Epoch [29/250], Train Loss: 0.1578, Validation Loss: 0.1979
Epoch [30/250], Train Loss: 0.1352, Validation Loss: 0.2068
Epoch [31/250], Train Loss: 0.1539, Validation Loss: 0.1948
Epoch [32/250], Train Loss: 0.1476, Validation Loss: 0.2213
Epoch [33/250], Train Loss: 0.1552, Validation Loss: 0.1814
Epoch [34/250], Train Loss: 0.1367, Validation Loss: 0.1803
Epoch [35/250], Train Loss: 0.1382, Validation Loss: 0.1617
Epoch [36/250], Train Loss: 0.1345, Validation Loss: 0.2061
Epoch [37/250], Train Loss: 0.1351, Validation Loss: 0.1774
Epoch [38/250], Train Loss: 0.1299, Validation Loss: 0.2072
Epoch [39/250], Train Loss: 0.1561, Validation Loss: 0.1817
Epoch [40/250], Train Loss: 0.1375, Validation Loss: 0.1841
Epoch [41/250], Train Loss: 0.1461, Validation Loss: 0.1900
Epoch [42/250], Train Loss: 0.1497, Validation Loss: 0.1788
Epoch [43/250], Train Loss: 0.1357, Validation Loss: 0.1866
Epoch [44/250], Train Loss: 0.1197, Validation Loss: 0.2098
Epoch [45/250], Train Loss: 0.1231, Validation Loss: 0.1836
Epoch [46/250], Train Loss: 0.1491, Validation Loss: 0.1869
Epoch [47/250], Train Loss: 0.1166, Validation Loss: 0.1397
Epoch [48/250], Train Loss: 0.1342, Validation Loss: 0.1694
Epoch [49/250], Train Loss: 0.1279, Validation Loss: 0.1666
Epoch [50/250], Train Loss: 0.1318, Validation Loss: 0.1601
Epoch [51/250], Train Loss: 0.1302, Validation Loss: 0.1604
Epoch [52/250], Train Loss: 0.1137, Validation Loss: 0.1520
Epoch [53/250], Train Loss: 0.1177, Validation Loss: 0.1877
Epoch [54/250], Train Loss: 0.1245, Validation Loss: 0.1689
Epoch [55/250], Train Loss: 0.1155, Validation Loss: 0.1587
Epoch [56/250], Train Loss: 0.1242, Validation Loss: 0.1585
Epoch [57/250], Train Loss: 0.1178, Validation Loss: 0.1817
Epoch [58/250], Train Loss: 0.1136, Validation Loss: 0.1528
Epoch [59/250], Train Loss: 0.1313, Validation Loss: 0.1742
Epoch [60/250], Train Loss: 0.1366, Validation Loss: 0.1868
Epoch [61/250], Train Loss: 0.1338, Validation Loss: 0.2054
Epoch [62/250], Train Loss: 0.1394, Validation Loss: 0.1861
Epoch [63/250], Train Loss: 0.1190, Validation Loss: 0.1917
Epoch [64/250], Train Loss: 0.1042, Validation Loss: 0.1692
Epoch [65/250], Train Loss: 0.1191, Validation Loss: 0.1794
Epoch [66/250], Train Loss: 0.1245, Validation Loss: 0.1682
Epoch [67/250], Train Loss: 0.1235, Validation Loss: 0.1542
Epoch [68/250], Train Loss: 0.1257, Validation Loss: 0.2015
Epoch [69/250], Train Loss: 0.1235, Validation Loss: 0.1685
Epoch [70/250], Train Loss: 0.1328, Validation Loss: 0.1665
Epoch [71/250], Train Loss: 0.1262, Validation Loss: 0.1310
Epoch [72/250], Train Loss: 0.1149, Validation Loss: 0.1455
Epoch [73/250], Train Loss: 0.1180, Validation Loss: 0.1707
Epoch [74/250], Train Loss: 0.1140, Validation Loss: 0.1521
Epoch [75/250], Train Loss: 0.1181, Validation Loss: 0.1623
Epoch [76/250], Train Loss: 0.1212, Validation Loss: 0.1586
Epoch [77/250], Train Loss: 0.1058, Validation Loss: 0.1537
Epoch [78/250], Train Loss: 0.1221, Validation Loss: 0.1545
Epoch [79/250], Train Loss: 0.0938, Validation Loss: 0.1898
Epoch [80/250], Train Loss: 0.1223, Validation Loss: 0.1379
Epoch [81/250], Train Loss: 0.1028, Validation Loss: 0.1252
Epoch [82/250], Train Loss: 0.1152, Validation Loss: 0.1718
Epoch [83/250], Train Loss: 0.1159, Validation Loss: 0.1661
Epoch [84/250], Train Loss: 0.1226, Validation Loss: 0.1462
Epoch [85/250], Train Loss: 0.1181, Validation Loss: 0.1399
Epoch [86/250], Train Loss: 0.1133, Validation Loss: 0.1563
Epoch [87/250], Train Loss: 0.1009, Validation Loss: 0.1606
Epoch [88/250], Train Loss: 0.0977, Validation Loss: 0.1645
Epoch [89/250], Train Loss: 0.1233, Validation Loss: 0.1961
Epoch [90/250], Train Loss: 0.1104, Validation Loss: 0.1398
Epoch [91/250], Train Loss: 0.1049, Validation Loss: 0.1676
Epoch [92/250], Train Loss: 0.1062, Validation Loss: 0.1659
Epoch [93/250], Train Loss: 0.0994, Validation Loss: 0.1311
Epoch [94/250], Train Loss: 0.1116, Validation Loss: 0.1368
Epoch [95/250], Train Loss: 0.0998, Validation Loss: 0.1503
Epoch [96/250], Train Loss: 0.1112, Validation Loss: 0.1471
Epoch [97/250], Train Loss: 0.1096, Validation Loss: 0.1379
Epoch [98/250], Train Loss: 0.1048, Validation Loss: 0.1441
Epoch [99/250], Train Loss: 0.1087, Validation Loss: 0.1304
Epoch [100/250], Train Loss: 0.1009, Validation Loss: 0.1321
Epoch [101/250], Train Loss: 0.1022, Validation Loss: 0.1386
Epoch [102/250], Train Loss: 0.1023, Validation Loss: 0.1693
Epoch [103/250], Train Loss: 0.1176, Validation Loss: 0.1575
Epoch [104/250], Train Loss: 0.1108, Validation Loss: 0.1711
Epoch [105/250], Train Loss: 0.1094, Validation Loss: 0.2138
Epoch [106/250], Train Loss: 0.1027, Validation Loss: 0.1656
Epoch [107/250], Train Loss: 0.1005, Validation Loss: 0.1500
Epoch [108/250], Train Loss: 0.0977, Validation Loss: 0.1526
Epoch [109/250], Train Loss: 0.1016, Validation Loss: 0.1536
Epoch [110/250], Train Loss: 0.0947, Validation Loss: 0.1439
Epoch [111/250], Train Loss: 0.1080, Validation Loss: 0.1413
Epoch [112/250], Train Loss: 0.1060, Validation Loss: 0.1431
Epoch [113/250], Train Loss: 0.0946, Validation Loss: 0.1203
Epoch [114/250], Train Loss: 0.0985, Validation Loss: 0.1404
Epoch [115/250], Train Loss: 0.0904, Validation Loss: 0.1395
Epoch [116/250], Train Loss: 0.0989, Validation Loss: 0.1610
Epoch [117/250], Train Loss: 0.0999, Validation Loss: 0.1514
Epoch [118/250], Train Loss: 0.0968, Validation Loss: 0.1325
Epoch [119/250], Train Loss: 0.0890, Validation Loss: 0.1465
Epoch [120/250], Train Loss: 0.0944, Validation Loss: 0.1709
Epoch [121/250], Train Loss: 0.1112, Validation Loss: 0.1402
Epoch [122/250], Train Loss: 0.0919, Validation Loss: 0.1138
Epoch [123/250], Train Loss: 0.0983, Validation Loss: 0.1493
Epoch [124/250], Train Loss: 0.1093, Validation Loss: 0.1364
Epoch [125/250], Train Loss: 0.0940, Validation Loss: 0.1495
Epoch [126/250], Train Loss: 0.1119, Validation Loss: 0.1930
Epoch [127/250], Train Loss: 0.1104, Validation Loss: 0.1610
Epoch [128/250], Train Loss: 0.0957, Validation Loss: 0.1336
Epoch [129/250], Train Loss: 0.1056, Validation Loss: 0.1461
Epoch [130/250], Train Loss: 0.1006, Validation Loss: 0.1411
Epoch [131/250], Train Loss: 0.1009, Validation Loss: 0.1470
Epoch [132/250], Train Loss: 0.0980, Validation Loss: 0.1366
Epoch [133/250], Train Loss: 0.1009, Validation Loss: 0.1023
Epoch [134/250], Train Loss: 0.0915, Validation Loss: 0.1418
Epoch [135/250], Train Loss: 0.0826, Validation Loss: 0.1208
Epoch [136/250], Train Loss: 0.0835, Validation Loss: 0.1275
Epoch [137/250], Train Loss: 0.0842, Validation Loss: 0.1379
Epoch [138/250], Train Loss: 0.0850, Validation Loss: 0.1204
Epoch [139/250], Train Loss: 0.0893, Validation Loss: 0.1472
Epoch [140/250], Train Loss: 0.1031, Validation Loss: 0.1260
Epoch [141/250], Train Loss: 0.0986, Validation Loss: 0.1541
Epoch [142/250], Train Loss: 0.1012, Validation Loss: 0.1648
Epoch [143/250], Train Loss: 0.1008, Validation Loss: 0.1610
Epoch [144/250], Train Loss: 0.0922, Validation Loss: 0.1895
Epoch [145/250], Train Loss: 0.0992, Validation Loss: 0.1839
Epoch [146/250], Train Loss: 0.1009, Validation Loss: 0.1625
Epoch [147/250], Train Loss: 0.1007, Validation Loss: 0.1400
Epoch [148/250], Train Loss: 0.0920, Validation Loss: 0.1148
Epoch [149/250], Train Loss: 0.0843, Validation Loss: 0.1164
Epoch [150/250], Train Loss: 0.0830, Validation Loss: 0.1313
Epoch [151/250], Train Loss: 0.0766, Validation Loss: 0.1358
Epoch [152/250], Train Loss: 0.0965, Validation Loss: 0.1335
Epoch [153/250], Train Loss: 0.0816, Validation Loss: 0.1207
Epoch [154/250], Train Loss: 0.0866, Validation Loss: 0.1559
Epoch [155/250], Train Loss: 0.0838, Validation Loss: 0.1327
Epoch [156/250], Train Loss: 0.0763, Validation Loss: 0.1277
Epoch [157/250], Train Loss: 0.0887, Validation Loss: 0.1140
Epoch [158/250], Train Loss: 0.0786, Validation Loss: 0.1631
Epoch [159/250], Train Loss: 0.0931, Validation Loss: 0.1247
Epoch [160/250], Train Loss: 0.0991, Validation Loss: 0.1412
Epoch [161/250], Train Loss: 0.0717, Validation Loss: 0.1415
Epoch [162/250], Train Loss: 0.0796, Validation Loss: 0.1439
Epoch [163/250], Train Loss: 0.0899, Validation Loss: 0.1160
Epoch [164/250], Train Loss: 0.0856, Validation Loss: 0.1564
Epoch [165/250], Train Loss: 0.0978, Validation Loss: 0.1320
Epoch [166/250], Train Loss: 0.0918, Validation Loss: 0.1121
Epoch [167/250], Train Loss: 0.0859, Validation Loss: 0.1108
Epoch [168/250], Train Loss: 0.0781, Validation Loss: 0.0997
Epoch [169/250], Train Loss: 0.0988, Validation Loss: 0.1127
Epoch [170/250], Train Loss: 0.0725, Validation Loss: 0.1221
Epoch [171/250], Train Loss: 0.0755, Validation Loss: 0.1275
Epoch [172/250], Train Loss: 0.0983, Validation Loss: 0.1150
Epoch [173/250], Train Loss: 0.0869, Validation Loss: 0.1230
Epoch [174/250], Train Loss: 0.0887, Validation Loss: 0.1336
Epoch [175/250], Train Loss: 0.0870, Validation Loss: 0.1435
Epoch [176/250], Train Loss: 0.0767, Validation Loss: 0.1051
Epoch [177/250], Train Loss: 0.0739, Validation Loss: 0.1320
Epoch [178/250], Train Loss: 0.0903, Validation Loss: 0.1348
Epoch [179/250], Train Loss: 0.0870, Validation Loss: 0.1954
Epoch [180/250], Train Loss: 0.0829, Validation Loss: 0.1440
Epoch [181/250], Train Loss: 0.0877, Validation Loss: 0.1468
Epoch [182/250], Train Loss: 0.0747, Validation Loss: 0.1187
Epoch [183/250], Train Loss: 0.0676, Validation Loss: 0.1185
Epoch [184/250], Train Loss: 0.0746, Validation Loss: 0.1098
Epoch [185/250], Train Loss: 0.0782, Validation Loss: 0.1174
Epoch [186/250], Train Loss: 0.0670, Validation Loss: 0.1666
Epoch [187/250], Train Loss: 0.0711, Validation Loss: 0.1501
Epoch [188/250], Train Loss: 0.0922, Validation Loss: 0.1583
Epoch [189/250], Train Loss: 0.0882, Validation Loss: 0.1561
Epoch [190/250], Train Loss: 0.0733, Validation Loss: 0.1407
Epoch [191/250], Train Loss: 0.0903, Validation Loss: 0.1120
Epoch [192/250], Train Loss: 0.0847, Validation Loss: 0.1699
Epoch [193/250], Train Loss: 0.0887, Validation Loss: 0.1066
Epoch [194/250], Train Loss: 0.0769, Validation Loss: 0.1124
Epoch [195/250], Train Loss: 0.0925, Validation Loss: 0.1035
Epoch [196/250], Train Loss: 0.0827, Validation Loss: 0.1031
Epoch [197/250], Train Loss: 0.0789, Validation Loss: 0.1280
Epoch [198/250], Train Loss: 0.0809, Validation Loss: 0.1191
Epoch [199/250], Train Loss: 0.0759, Validation Loss: 0.1001
Epoch [200/250], Train Loss: 0.0766, Validation Loss: 0.1278
Epoch [201/250], Train Loss: 0.0662, Validation Loss: 0.1470
Epoch [202/250], Train Loss: 0.0762, Validation Loss: 0.1491
Epoch [203/250], Train Loss: 0.0697, Validation Loss: 0.1344
Epoch [204/250], Train Loss: 0.0685, Validation Loss: 0.1304
Epoch [205/250], Train Loss: 0.0735, Validation Loss: 0.1734
Epoch [206/250], Train Loss: 0.0821, Validation Loss: 0.1375
Epoch [207/250], Train Loss: 0.0793, Validation Loss: 0.1760
Epoch [208/250], Train Loss: 0.0789, Validation Loss: 0.1403
Epoch [209/250], Train Loss: 0.0750, Validation Loss: 0.1086
Epoch [210/250], Train Loss: 0.0672, Validation Loss: 0.1270
Epoch [211/250], Train Loss: 0.0622, Validation Loss: 0.1308
Epoch [212/250], Train Loss: 0.0709, Validation Loss: 0.1381
Epoch [213/250], Train Loss: 0.0716, Validation Loss: 0.1341
Epoch [214/250], Train Loss: 0.0664, Validation Loss: 0.1369
Epoch [215/250], Train Loss: 0.0683, Validation Loss: 0.1404
Epoch [216/250], Train Loss: 0.0671, Validation Loss: 0.1203
Epoch [217/250], Train Loss: 0.0739, Validation Loss: 0.1076
Epoch [218/250], Train Loss: 0.0689, Validation Loss: 0.1293
Epoch [219/250], Train Loss: 0.0664, Validation Loss: 0.1215
Epoch [220/250], Train Loss: 0.0696, Validation Loss: 0.1040
Epoch [221/250], Train Loss: 0.0597, Validation Loss: 0.1366
Epoch [222/250], Train Loss: 0.0697, Validation Loss: 0.1015
Epoch [223/250], Train Loss: 0.0675, Validation Loss: 0.1209
Epoch [224/250], Train Loss: 0.0654, Validation Loss: 0.1118
Epoch [225/250], Train Loss: 0.0697, Validation Loss: 0.1432
Epoch [226/250], Train Loss: 0.0704, Validation Loss: 0.1620
Epoch [227/250], Train Loss: 0.0690, Validation Loss: 0.1484
Epoch [228/250], Train Loss: 0.0713, Validation Loss: 0.1793
Epoch [229/250], Train Loss: 0.0790, Validation Loss: 0.1222
Epoch [230/250], Train Loss: 0.0607, Validation Loss: 0.1005
Epoch [231/250], Train Loss: 0.0596, Validation Loss: 0.1005
Epoch [232/250], Train Loss: 0.0650, Validation Loss: 0.1064
Epoch [233/250], Train Loss: 0.0619, Validation Loss: 0.1161
Epoch [234/250], Train Loss: 0.0910, Validation Loss: 0.1360
Epoch [235/250], Train Loss: 0.0807, Validation Loss: 0.1553
Epoch [236/250], Train Loss: 0.0773, Validation Loss: 0.0831
Epoch [237/250], Train Loss: 0.0781, Validation Loss: 0.1291
Epoch [238/250], Train Loss: 0.0953, Validation Loss: 0.1264
Epoch [239/250], Train Loss: 0.0590, Validation Loss: 0.1613
Epoch [240/250], Train Loss: 0.0778, Validation Loss: 0.1746
Epoch [241/250], Train Loss: 0.0786, Validation Loss: 0.1968
Epoch [242/250], Train Loss: 0.0678, Validation Loss: 0.1294
Epoch [243/250], Train Loss: 0.0715, Validation Loss: 0.1280
Epoch [244/250], Train Loss: 0.0723, Validation Loss: 0.1872
Epoch [245/250], Train Loss: 0.0948, Validation Loss: 0.2381
Epoch [246/250], Train Loss: 0.0781, Validation Loss: 0.1232
Epoch [247/250], Train Loss: 0.0754, Validation Loss: 0.1006
Epoch [248/250], Train Loss: 0.0678, Validation Loss: 0.1017
Epoch [249/250], Train Loss: 0.0792, Validation Loss: 0.1116
Epoch [250/250], Train Loss: 0.0743, Validation Loss: 0.1151

Finished Training in 81.4

Noise Sigma:  2.0
Creating datasets...
Start training...
Epoch [1/250], Train Loss: 0.1756, Validation Loss: 0.2448
Epoch [2/250], Train Loss: 0.1321, Validation Loss: 0.2942
Epoch [3/250], Train Loss: 0.1407, Validation Loss: 0.2416
Epoch [4/250], Train Loss: 0.1246, Validation Loss: 0.2192
Epoch [5/250], Train Loss: 0.1619, Validation Loss: 0.1645
Epoch [6/250], Train Loss: 0.1136, Validation Loss: 0.1636
Epoch [7/250], Train Loss: 0.1088, Validation Loss: 0.1409
Epoch [8/250], Train Loss: 0.1070, Validation Loss: 0.1619
Epoch [9/250], Train Loss: 0.0965, Validation Loss: 0.1876
Epoch [10/250], Train Loss: 0.1002, Validation Loss: 0.2216
Epoch [11/250], Train Loss: 0.1325, Validation Loss: 0.2334
Epoch [12/250], Train Loss: 0.1195, Validation Loss: 0.2066
Epoch [13/250], Train Loss: 0.1047, Validation Loss: 0.1520
Epoch [14/250], Train Loss: 0.1056, Validation Loss: 0.2016
Epoch [15/250], Train Loss: 0.1042, Validation Loss: 0.1799
Epoch [16/250], Train Loss: 0.1089, Validation Loss: 0.1952
Epoch [17/250], Train Loss: 0.1128, Validation Loss: 0.2082
Epoch [18/250], Train Loss: 0.1140, Validation Loss: 0.1622
Epoch [19/250], Train Loss: 0.0880, Validation Loss: 0.2173
Epoch [20/250], Train Loss: 0.1014, Validation Loss: 0.1369
Epoch [21/250], Train Loss: 0.0986, Validation Loss: 0.1459
Epoch [22/250], Train Loss: 0.0773, Validation Loss: 0.1590
Epoch [23/250], Train Loss: 0.0922, Validation Loss: 0.1733
Epoch [24/250], Train Loss: 0.0980, Validation Loss: 0.1894
Epoch [25/250], Train Loss: 0.0841, Validation Loss: 0.1891
Epoch [26/250], Train Loss: 0.0824, Validation Loss: 0.1756
Epoch [27/250], Train Loss: 0.0897, Validation Loss: 0.2033
Epoch [28/250], Train Loss: 0.0686, Validation Loss: 0.2260
Epoch [29/250], Train Loss: 0.0759, Validation Loss: 0.2037
Epoch [30/250], Train Loss: 0.0897, Validation Loss: 0.1778
Epoch [31/250], Train Loss: 0.0755, Validation Loss: 0.1642
Epoch [32/250], Train Loss: 0.0830, Validation Loss: 0.1571
Epoch [33/250], Train Loss: 0.0779, Validation Loss: 0.1793
Epoch [34/250], Train Loss: 0.0816, Validation Loss: 0.1802
Epoch [35/250], Train Loss: 0.0602, Validation Loss: 0.1653
Epoch [36/250], Train Loss: 0.0738, Validation Loss: 0.1849
Epoch [37/250], Train Loss: 0.0909, Validation Loss: 0.1721
Epoch [38/250], Train Loss: 0.0839, Validation Loss: 0.1801
Epoch [39/250], Train Loss: 0.0909, Validation Loss: 0.1913
Epoch [40/250], Train Loss: 0.1202, Validation Loss: 0.2309
Epoch [41/250], Train Loss: 0.1127, Validation Loss: 0.1667
Epoch [42/250], Train Loss: 0.0797, Validation Loss: 0.1373
Epoch [43/250], Train Loss: 0.0886, Validation Loss: 0.1239
Epoch [44/250], Train Loss: 0.0766, Validation Loss: 0.1526
Epoch [45/250], Train Loss: 0.0918, Validation Loss: 0.1383
Epoch [46/250], Train Loss: 0.0848, Validation Loss: 0.1358
Epoch [47/250], Train Loss: 0.0819, Validation Loss: 0.2016
Epoch [48/250], Train Loss: 0.0743, Validation Loss: 0.1890
Epoch [49/250], Train Loss: 0.0918, Validation Loss: 0.1889
Epoch [50/250], Train Loss: 0.0792, Validation Loss: 0.1909
Epoch [51/250], Train Loss: 0.0800, Validation Loss: 0.2041
Epoch [52/250], Train Loss: 0.0845, Validation Loss: 0.1927
Epoch [53/250], Train Loss: 0.0843, Validation Loss: 0.1693
Epoch [54/250], Train Loss: 0.0940, Validation Loss: 0.2208
Epoch [55/250], Train Loss: 0.0712, Validation Loss: 0.1732
Epoch [56/250], Train Loss: 0.0948, Validation Loss: 0.1844
Epoch [57/250], Train Loss: 0.0876, Validation Loss: 0.1785
Epoch [58/250], Train Loss: 0.1161, Validation Loss: 0.1590
Epoch [59/250], Train Loss: 0.0824, Validation Loss: 0.2202
Epoch [60/250], Train Loss: 0.1135, Validation Loss: 0.1738
Epoch [61/250], Train Loss: 0.0652, Validation Loss: 0.1898
Epoch [62/250], Train Loss: 0.0949, Validation Loss: 0.1870
Epoch [63/250], Train Loss: 0.0930, Validation Loss: 0.1856
Epoch [64/250], Train Loss: 0.0840, Validation Loss: 0.1580
Epoch [65/250], Train Loss: 0.1090, Validation Loss: 0.1347
Epoch [66/250], Train Loss: 0.0876, Validation Loss: 0.1429
Epoch [67/250], Train Loss: 0.0909, Validation Loss: 0.1696
Epoch [68/250], Train Loss: 0.0857, Validation Loss: 0.2219
Epoch [69/250], Train Loss: 0.0734, Validation Loss: 0.1962
Epoch [70/250], Train Loss: 0.0894, Validation Loss: 0.1844
Epoch [71/250], Train Loss: 0.0749, Validation Loss: 0.1614
Epoch [72/250], Train Loss: 0.0924, Validation Loss: 0.1929
Epoch [73/250], Train Loss: 0.0844, Validation Loss: 0.1517
Epoch [74/250], Train Loss: 0.0716, Validation Loss: 0.1652
Epoch [75/250], Train Loss: 0.0677, Validation Loss: 0.1765
Epoch [76/250], Train Loss: 0.0771, Validation Loss: 0.1797
Epoch [77/250], Train Loss: 0.0581, Validation Loss: 0.1675
Epoch [78/250], Train Loss: 0.0770, Validation Loss: 0.1849
Epoch [79/250], Train Loss: 0.0772, Validation Loss: 0.2007
Epoch [80/250], Train Loss: 0.0771, Validation Loss: 0.1458
Epoch [81/250], Train Loss: 0.0667, Validation Loss: 0.1229
Epoch [82/250], Train Loss: 0.0647, Validation Loss: 0.1476
Epoch [83/250], Train Loss: 0.0815, Validation Loss: 0.1816
Epoch [84/250], Train Loss: 0.0851, Validation Loss: 0.2317
Epoch [85/250], Train Loss: 0.0696, Validation Loss: 0.2045
Epoch [86/250], Train Loss: 0.0636, Validation Loss: 0.1666
Epoch [87/250], Train Loss: 0.0607, Validation Loss: 0.1754
Epoch [88/250], Train Loss: 0.0720, Validation Loss: 0.1690
Epoch [89/250], Train Loss: 0.0735, Validation Loss: 0.1906
Epoch [90/250], Train Loss: 0.0752, Validation Loss: 0.1981
Epoch [91/250], Train Loss: 0.0827, Validation Loss: 0.1814
Epoch [92/250], Train Loss: 0.0596, Validation Loss: 0.2250
Epoch [93/250], Train Loss: 0.0789, Validation Loss: 0.2275
Epoch [94/250], Train Loss: 0.0765, Validation Loss: 0.2057
Epoch [95/250], Train Loss: 0.0841, Validation Loss: 0.2856
Epoch [96/250], Train Loss: 0.0855, Validation Loss: 0.2598
Epoch [97/250], Train Loss: 0.0867, Validation Loss: 0.2395
Epoch [98/250], Train Loss: 0.0785, Validation Loss: 0.3037
Epoch [99/250], Train Loss: 0.1063, Validation Loss: 0.1904
Epoch [100/250], Train Loss: 0.0815, Validation Loss: 0.1238
Epoch [101/250], Train Loss: 0.0729, Validation Loss: 0.1992
Epoch [102/250], Train Loss: 0.0831, Validation Loss: 0.1870
Epoch [103/250], Train Loss: 0.0930, Validation Loss: 0.1409
Epoch [104/250], Train Loss: 0.0655, Validation Loss: 0.1422
Epoch [105/250], Train Loss: 0.0643, Validation Loss: 0.1476
Epoch [106/250], Train Loss: 0.0694, Validation Loss: 0.1809
Epoch [107/250], Train Loss: 0.0613, Validation Loss: 0.1915
Epoch [108/250], Train Loss: 0.0782, Validation Loss: 0.2005
Epoch [109/250], Train Loss: 0.0699, Validation Loss: 0.1924
Epoch [110/250], Train Loss: 0.0668, Validation Loss: 0.2025
Epoch [111/250], Train Loss: 0.0638, Validation Loss: 0.1967
Epoch [112/250], Train Loss: 0.0586, Validation Loss: 0.2065
Epoch [113/250], Train Loss: 0.0608, Validation Loss: 0.1651
Epoch [114/250], Train Loss: 0.0597, Validation Loss: 0.1704
Epoch [115/250], Train Loss: 0.0560, Validation Loss: 0.1552
Epoch [116/250], Train Loss: 0.0615, Validation Loss: 0.1550
Epoch [117/250], Train Loss: 0.0701, Validation Loss: 0.1618
Epoch [118/250], Train Loss: 0.0713, Validation Loss: 0.1839
Epoch [119/250], Train Loss: 0.0715, Validation Loss: 0.1881
Epoch [120/250], Train Loss: 0.0664, Validation Loss: 0.1710
Epoch [121/250], Train Loss: 0.0730, Validation Loss: 0.1967
Epoch [122/250], Train Loss: 0.0660, Validation Loss: 0.1787
Epoch [123/250], Train Loss: 0.0646, Validation Loss: 0.1791
Epoch [124/250], Train Loss: 0.0685, Validation Loss: 0.1974
Epoch [125/250], Train Loss: 0.0649, Validation Loss: 0.1998
Epoch [126/250], Train Loss: 0.0597, Validation Loss: 0.1682
Epoch [127/250], Train Loss: 0.0831, Validation Loss: 0.2349
Epoch [128/250], Train Loss: 0.0962, Validation Loss: 0.3130
Epoch [129/250], Train Loss: 0.1259, Validation Loss: 0.2869
Epoch [130/250], Train Loss: 0.1082, Validation Loss: 0.1939
Epoch [131/250], Train Loss: 0.0810, Validation Loss: 0.1620
Epoch [132/250], Train Loss: 0.1048, Validation Loss: 0.2033
Epoch [133/250], Train Loss: 0.0870, Validation Loss: 0.1689
Epoch [134/250], Train Loss: 0.0864, Validation Loss: 0.1880
Epoch [135/250], Train Loss: 0.0826, Validation Loss: 0.2231
Epoch [136/250], Train Loss: 0.0794, Validation Loss: 0.1230
Epoch [137/250], Train Loss: 0.0650, Validation Loss: 0.1341
Epoch [138/250], Train Loss: 0.0693, Validation Loss: 0.1684
Epoch [139/250], Train Loss: 0.0812, Validation Loss: 0.1367
Epoch [140/250], Train Loss: 0.0741, Validation Loss: 0.1725
Epoch [141/250], Train Loss: 0.0576, Validation Loss: 0.1851
Epoch [142/250], Train Loss: 0.0872, Validation Loss: 0.1838
Epoch [143/250], Train Loss: 0.0644, Validation Loss: 0.2028
Epoch [144/250], Train Loss: 0.0701, Validation Loss: 0.1588
Epoch [145/250], Train Loss: 0.0658, Validation Loss: 0.1442
Epoch [146/250], Train Loss: 0.0748, Validation Loss: 0.1191
Epoch [147/250], Train Loss: 0.0675, Validation Loss: 0.1350
Epoch [148/250], Train Loss: 0.0576, Validation Loss: 0.1590
Epoch [149/250], Train Loss: 0.0628, Validation Loss: 0.1420
Epoch [150/250], Train Loss: 0.0719, Validation Loss: 0.1339
Epoch [151/250], Train Loss: 0.0538, Validation Loss: 0.1192
Epoch [152/250], Train Loss: 0.0683, Validation Loss: 0.1354
Epoch [153/250], Train Loss: 0.0661, Validation Loss: 0.1695
Epoch [154/250], Train Loss: 0.0639, Validation Loss: 0.1465
Epoch [155/250], Train Loss: 0.0498, Validation Loss: 0.1349
Epoch [156/250], Train Loss: 0.0604, Validation Loss: 0.1314
Epoch [157/250], Train Loss: 0.0604, Validation Loss: 0.1689
Epoch [158/250], Train Loss: 0.0820, Validation Loss: 0.1715
Epoch [159/250], Train Loss: 0.0570, Validation Loss: 0.1320
Epoch [160/250], Train Loss: 0.0529, Validation Loss: 0.1466
Epoch [161/250], Train Loss: 0.0657, Validation Loss: 0.1799
Epoch [162/250], Train Loss: 0.0647, Validation Loss: 0.1665
Epoch [163/250], Train Loss: 0.0513, Validation Loss: 0.1842
Epoch [164/250], Train Loss: 0.0667, Validation Loss: 0.2169
Epoch [165/250], Train Loss: 0.0599, Validation Loss: 0.1971
Epoch [166/250], Train Loss: 0.0572, Validation Loss: 0.2034
Epoch [167/250], Train Loss: 0.0690, Validation Loss: 0.1375
Epoch [168/250], Train Loss: 0.0518, Validation Loss: 0.1346
Epoch [169/250], Train Loss: 0.0618, Validation Loss: 0.1391
Epoch [170/250], Train Loss: 0.0625, Validation Loss: 0.1662
Epoch [171/250], Train Loss: 0.0659, Validation Loss: 0.1617
Epoch [172/250], Train Loss: 0.0607, Validation Loss: 0.2079
Epoch [173/250], Train Loss: 0.0664, Validation Loss: 0.2056
Epoch [174/250], Train Loss: 0.0682, Validation Loss: 0.2180
Epoch [175/250], Train Loss: 0.0528, Validation Loss: 0.1716
Epoch [176/250], Train Loss: 0.0585, Validation Loss: 0.1620
Epoch [177/250], Train Loss: 0.0692, Validation Loss: 0.1481
Epoch [178/250], Train Loss: 0.0735, Validation Loss: 0.1940
Epoch [179/250], Train Loss: 0.0758, Validation Loss: 0.1510
Epoch [180/250], Train Loss: 0.0591, Validation Loss: 0.1788
Epoch [181/250], Train Loss: 0.0615, Validation Loss: 0.2295
Epoch [182/250], Train Loss: 0.0723, Validation Loss: 0.1837
Epoch [183/250], Train Loss: 0.0634, Validation Loss: 0.1523
Epoch [184/250], Train Loss: 0.0595, Validation Loss: 0.1281
Epoch [185/250], Train Loss: 0.0660, Validation Loss: 0.1320
Epoch [186/250], Train Loss: 0.0636, Validation Loss: 0.1255
Epoch [187/250], Train Loss: 0.0533, Validation Loss: 0.1260
Epoch [188/250], Train Loss: 0.0511, Validation Loss: 0.1192
Epoch [189/250], Train Loss: 0.0501, Validation Loss: 0.1559
Epoch [190/250], Train Loss: 0.0517, Validation Loss: 0.1276
Epoch [191/250], Train Loss: 0.0494, Validation Loss: 0.1532
Epoch [192/250], Train Loss: 0.0501, Validation Loss: 0.1640
Epoch [193/250], Train Loss: 0.0569, Validation Loss: 0.1940
Epoch [194/250], Train Loss: 0.0491, Validation Loss: 0.2078
Epoch [195/250], Train Loss: 0.0527, Validation Loss: 0.1410
Epoch [196/250], Train Loss: 0.0677, Validation Loss: 0.1392
Epoch [197/250], Train Loss: 0.0485, Validation Loss: 0.1559
Epoch [198/250], Train Loss: 0.0447, Validation Loss: 0.1319
Epoch [199/250], Train Loss: 0.0517, Validation Loss: 0.1106
Epoch [200/250], Train Loss: 0.0601, Validation Loss: 0.1246
Epoch [201/250], Train Loss: 0.0428, Validation Loss: 0.2042
Epoch [202/250], Train Loss: 0.0473, Validation Loss: 0.1394
Epoch [203/250], Train Loss: 0.0490, Validation Loss: 0.1260
Epoch [204/250], Train Loss: 0.0440, Validation Loss: 0.1393
Epoch [205/250], Train Loss: 0.0569, Validation Loss: 0.1345
Epoch [206/250], Train Loss: 0.0474, Validation Loss: 0.1462
Epoch [207/250], Train Loss: 0.0557, Validation Loss: 0.1274
Epoch [208/250], Train Loss: 0.0399, Validation Loss: 0.1252
Epoch [209/250], Train Loss: 0.0550, Validation Loss: 0.1334
Epoch [210/250], Train Loss: 0.0525, Validation Loss: 0.1192
Epoch [211/250], Train Loss: 0.0524, Validation Loss: 0.1299
Epoch [212/250], Train Loss: 0.0459, Validation Loss: 0.1238
Epoch [213/250], Train Loss: 0.0478, Validation Loss: 0.1720
Epoch [214/250], Train Loss: 0.0518, Validation Loss: 0.1891
Epoch [215/250], Train Loss: 0.0477, Validation Loss: 0.1565
Epoch [216/250], Train Loss: 0.0508, Validation Loss: 0.1645
Epoch [217/250], Train Loss: 0.0516, Validation Loss: 0.1379
Epoch [218/250], Train Loss: 0.0560, Validation Loss: 0.1648
Epoch [219/250], Train Loss: 0.0486, Validation Loss: 0.1750
Epoch [220/250], Train Loss: 0.0458, Validation Loss: 0.1871
Epoch [221/250], Train Loss: 0.0441, Validation Loss: 0.2150
Epoch [222/250], Train Loss: 0.0571, Validation Loss: 0.1845
Epoch [223/250], Train Loss: 0.0503, Validation Loss: 0.2120
Epoch [224/250], Train Loss: 0.0494, Validation Loss: 0.1818
Epoch [225/250], Train Loss: 0.0511, Validation Loss: 0.1635
Epoch [226/250], Train Loss: 0.0456, Validation Loss: 0.1753
Epoch [227/250], Train Loss: 0.0419, Validation Loss: 0.1864
Epoch [228/250], Train Loss: 0.0492, Validation Loss: 0.1821
Epoch [229/250], Train Loss: 0.0473, Validation Loss: 0.1491
Epoch [230/250], Train Loss: 0.0440, Validation Loss: 0.1549
Epoch [231/250], Train Loss: 0.0442, Validation Loss: 0.1415
Epoch [232/250], Train Loss: 0.0514, Validation Loss: 0.1618
Epoch [233/250], Train Loss: 0.0489, Validation Loss: 0.1351
Epoch [234/250], Train Loss: 0.0450, Validation Loss: 0.1074
Epoch [235/250], Train Loss: 0.0516, Validation Loss: 0.1191
Epoch [236/250], Train Loss: 0.0433, Validation Loss: 0.1315
Epoch [237/250], Train Loss: 0.0473, Validation Loss: 0.1382
Epoch [238/250], Train Loss: 0.0475, Validation Loss: 0.1247
Epoch [239/250], Train Loss: 0.0460, Validation Loss: 0.1511
Epoch [240/250], Train Loss: 0.0441, Validation Loss: 0.1591
Epoch [241/250], Train Loss: 0.0437, Validation Loss: 0.1522
Epoch [242/250], Train Loss: 0.0402, Validation Loss: 0.1347
Epoch [243/250], Train Loss: 0.0487, Validation Loss: 0.1478
Epoch [244/250], Train Loss: 0.0513, Validation Loss: 0.1482
Epoch [245/250], Train Loss: 0.0542, Validation Loss: 0.1924
Epoch [246/250], Train Loss: 0.0495, Validation Loss: 0.2391
Epoch [247/250], Train Loss: 0.0445, Validation Loss: 0.1714
Epoch [248/250], Train Loss: 0.0450, Validation Loss: 0.1181
Epoch [249/250], Train Loss: 0.0369, Validation Loss: 0.1277
Epoch [250/250], Train Loss: 0.0545, Validation Loss: 0.1297

Finished Training in 81.7

Saving model parameters...
done
