GPU available:  True
cuda
(100, 8192)
(100, 8192)
20086
noise sigs:  [0.01   0.5075 1.005  1.5025 2.    ]
Noise Sigma:  0.01
Creating datasets...
Start training...
Epoch [1/250], Train Loss: 0.7185, Validation Loss: 0.7198
Epoch [2/250], Train Loss: 0.7164, Validation Loss: 0.7176
Epoch [3/250], Train Loss: 0.7145, Validation Loss: 0.7155
Epoch [4/250], Train Loss: 0.7125, Validation Loss: 0.7134
Epoch [5/250], Train Loss: 0.7105, Validation Loss: 0.7109
Epoch [6/250], Train Loss: 0.7081, Validation Loss: 0.7082
Epoch [7/250], Train Loss: 0.7057, Validation Loss: 0.7053
Epoch [8/250], Train Loss: 0.7028, Validation Loss: 0.7023
Epoch [9/250], Train Loss: 0.6998, Validation Loss: 0.6990
Epoch [10/250], Train Loss: 0.6967, Validation Loss: 0.6953
Epoch [11/250], Train Loss: 0.6932, Validation Loss: 0.6911
Epoch [12/250], Train Loss: 0.6891, Validation Loss: 0.6864
Epoch [13/250], Train Loss: 0.6847, Validation Loss: 0.6814
Epoch [14/250], Train Loss: 0.6794, Validation Loss: 0.6755
Epoch [15/250], Train Loss: 0.6738, Validation Loss: 0.6687
Epoch [16/250], Train Loss: 0.6668, Validation Loss: 0.6609
Epoch [17/250], Train Loss: 0.6589, Validation Loss: 0.6518
Epoch [18/250], Train Loss: 0.6500, Validation Loss: 0.6445
Epoch [19/250], Train Loss: 0.6438, Validation Loss: 0.6374
Epoch [20/250], Train Loss: 0.6358, Validation Loss: 0.6278
Epoch [21/250], Train Loss: 0.6257, Validation Loss: 0.6177
Epoch [22/250], Train Loss: 0.6162, Validation Loss: 0.6088
Epoch [23/250], Train Loss: 0.6067, Validation Loss: 0.5984
Epoch [24/250], Train Loss: 0.5964, Validation Loss: 0.5894
Epoch [25/250], Train Loss: 0.5881, Validation Loss: 0.5815
Epoch [26/250], Train Loss: 0.5801, Validation Loss: 0.5729
Epoch [27/250], Train Loss: 0.5714, Validation Loss: 0.5637
Epoch [28/250], Train Loss: 0.5621, Validation Loss: 0.5540
Epoch [29/250], Train Loss: 0.5523, Validation Loss: 0.5436
Epoch [30/250], Train Loss: 0.5417, Validation Loss: 0.5325
Epoch [31/250], Train Loss: 0.5306, Validation Loss: 0.5207
Epoch [32/250], Train Loss: 0.5189, Validation Loss: 0.5083
Epoch [33/250], Train Loss: 0.5063, Validation Loss: 0.4951
Epoch [34/250], Train Loss: 0.4930, Validation Loss: 0.4812
Epoch [35/250], Train Loss: 0.4790, Validation Loss: 0.4668
Epoch [36/250], Train Loss: 0.4645, Validation Loss: 0.4517
Epoch [37/250], Train Loss: 0.4496, Validation Loss: 0.4363
Epoch [38/250], Train Loss: 0.4342, Validation Loss: 0.4206
Epoch [39/250], Train Loss: 0.4187, Validation Loss: 0.4048
Epoch [40/250], Train Loss: 0.4031, Validation Loss: 0.3890
Epoch [41/250], Train Loss: 0.3873, Validation Loss: 0.3732
Epoch [42/250], Train Loss: 0.3719, Validation Loss: 0.3575
Epoch [43/250], Train Loss: 0.3564, Validation Loss: 0.3424
Epoch [44/250], Train Loss: 0.3416, Validation Loss: 0.3279
Epoch [45/250], Train Loss: 0.3275, Validation Loss: 0.3143
Epoch [46/250], Train Loss: 0.3141, Validation Loss: 0.3016
Epoch [47/250], Train Loss: 0.3019, Validation Loss: 0.2899
Epoch [48/250], Train Loss: 0.2905, Validation Loss: 0.2791
Epoch [49/250], Train Loss: 0.2799, Validation Loss: 0.2692
Epoch [50/250], Train Loss: 0.2704, Validation Loss: 0.2602
Epoch [51/250], Train Loss: 0.2618, Validation Loss: 0.2530
Epoch [52/250], Train Loss: 0.2551, Validation Loss: 0.2469
Epoch [53/250], Train Loss: 0.2491, Validation Loss: 0.2415
Epoch [54/250], Train Loss: 0.2442, Validation Loss: 0.2376
Epoch [55/250], Train Loss: 0.2405, Validation Loss: 0.2343
Epoch [56/250], Train Loss: 0.2373, Validation Loss: 0.2313
Epoch [57/250], Train Loss: 0.2344, Validation Loss: 0.2286
Epoch [58/250], Train Loss: 0.2318, Validation Loss: 0.2263
Epoch [59/250], Train Loss: 0.2296, Validation Loss: 0.2242
Epoch [60/250], Train Loss: 0.2276, Validation Loss: 0.2223
Epoch [61/250], Train Loss: 0.2257, Validation Loss: 0.2206
Epoch [62/250], Train Loss: 0.2240, Validation Loss: 0.2190
Epoch [63/250], Train Loss: 0.2225, Validation Loss: 0.2175
Epoch [64/250], Train Loss: 0.2211, Validation Loss: 0.2162
Epoch [65/250], Train Loss: 0.2198, Validation Loss: 0.2150
Epoch [66/250], Train Loss: 0.2186, Validation Loss: 0.2138
Epoch [67/250], Train Loss: 0.2174, Validation Loss: 0.2127
Epoch [68/250], Train Loss: 0.2163, Validation Loss: 0.2116
Epoch [69/250], Train Loss: 0.2152, Validation Loss: 0.2106
Epoch [70/250], Train Loss: 0.2142, Validation Loss: 0.2096
Epoch [71/250], Train Loss: 0.2132, Validation Loss: 0.2087
Epoch [72/250], Train Loss: 0.2123, Validation Loss: 0.2077
Epoch [73/250], Train Loss: 0.2114, Validation Loss: 0.2069
Epoch [74/250], Train Loss: 0.2105, Validation Loss: 0.2060
Epoch [75/250], Train Loss: 0.2096, Validation Loss: 0.2052
Epoch [76/250], Train Loss: 0.2088, Validation Loss: 0.2043
Epoch [77/250], Train Loss: 0.2080, Validation Loss: 0.2035
Epoch [78/250], Train Loss: 0.2072, Validation Loss: 0.2028
Epoch [79/250], Train Loss: 0.2064, Validation Loss: 0.2020
Epoch [80/250], Train Loss: 0.2056, Validation Loss: 0.2012
Epoch [81/250], Train Loss: 0.2048, Validation Loss: 0.2005
Epoch [82/250], Train Loss: 0.2041, Validation Loss: 0.1998
Epoch [83/250], Train Loss: 0.2034, Validation Loss: 0.1991
Epoch [84/250], Train Loss: 0.2026, Validation Loss: 0.1984
Epoch [85/250], Train Loss: 0.2019, Validation Loss: 0.1976
Epoch [86/250], Train Loss: 0.2012, Validation Loss: 0.1969
Epoch [87/250], Train Loss: 0.2005, Validation Loss: 0.1963
Epoch [88/250], Train Loss: 0.1998, Validation Loss: 0.1956
Epoch [89/250], Train Loss: 0.1992, Validation Loss: 0.1949
Epoch [90/250], Train Loss: 0.1985, Validation Loss: 0.1943
Epoch [91/250], Train Loss: 0.1978, Validation Loss: 0.1937
Epoch [92/250], Train Loss: 0.1972, Validation Loss: 0.1930
Epoch [93/250], Train Loss: 0.1965, Validation Loss: 0.1924
Epoch [94/250], Train Loss: 0.1959, Validation Loss: 0.1918
Epoch [95/250], Train Loss: 0.1953, Validation Loss: 0.1912
Epoch [96/250], Train Loss: 0.1947, Validation Loss: 0.1906
Epoch [97/250], Train Loss: 0.1940, Validation Loss: 0.1900
Epoch [98/250], Train Loss: 0.1934, Validation Loss: 0.1894
Epoch [99/250], Train Loss: 0.1928, Validation Loss: 0.1887
Epoch [100/250], Train Loss: 0.1922, Validation Loss: 0.1881
Epoch [101/250], Train Loss: 0.1916, Validation Loss: 0.1875
Epoch [102/250], Train Loss: 0.1909, Validation Loss: 0.1869
Epoch [103/250], Train Loss: 0.1903, Validation Loss: 0.1863
Epoch [104/250], Train Loss: 0.1897, Validation Loss: 0.1857
Epoch [105/250], Train Loss: 0.1891, Validation Loss: 0.1851
Epoch [106/250], Train Loss: 0.1885, Validation Loss: 0.1845
Epoch [107/250], Train Loss: 0.1879, Validation Loss: 0.1840
Epoch [108/250], Train Loss: 0.1874, Validation Loss: 0.1834
Epoch [109/250], Train Loss: 0.1868, Validation Loss: 0.1828
Epoch [110/250], Train Loss: 0.1862, Validation Loss: 0.1823
Epoch [111/250], Train Loss: 0.1856, Validation Loss: 0.1817
Epoch [112/250], Train Loss: 0.1851, Validation Loss: 0.1811
Epoch [113/250], Train Loss: 0.1845, Validation Loss: 0.1806
Epoch [114/250], Train Loss: 0.1839, Validation Loss: 0.1800
Epoch [115/250], Train Loss: 0.1834, Validation Loss: 0.1795
Epoch [116/250], Train Loss: 0.1828, Validation Loss: 0.1789
Epoch [117/250], Train Loss: 0.1822, Validation Loss: 0.1784
Epoch [118/250], Train Loss: 0.1817, Validation Loss: 0.1778
Epoch [119/250], Train Loss: 0.1811, Validation Loss: 0.1773
Epoch [120/250], Train Loss: 0.1806, Validation Loss: 0.1768
Epoch [121/250], Train Loss: 0.1800, Validation Loss: 0.1762
Epoch [122/250], Train Loss: 0.1795, Validation Loss: 0.1757
Epoch [123/250], Train Loss: 0.1790, Validation Loss: 0.1752
Epoch [124/250], Train Loss: 0.1784, Validation Loss: 0.1747
Epoch [125/250], Train Loss: 0.1779, Validation Loss: 0.1741
Epoch [126/250], Train Loss: 0.1774, Validation Loss: 0.1736
Epoch [127/250], Train Loss: 0.1768, Validation Loss: 0.1731
Epoch [128/250], Train Loss: 0.1763, Validation Loss: 0.1726
Epoch [129/250], Train Loss: 0.1758, Validation Loss: 0.1721
Epoch [130/250], Train Loss: 0.1753, Validation Loss: 0.1716
Epoch [131/250], Train Loss: 0.1748, Validation Loss: 0.1711
Epoch [132/250], Train Loss: 0.1743, Validation Loss: 0.1706
Epoch [133/250], Train Loss: 0.1738, Validation Loss: 0.1701
Epoch [134/250], Train Loss: 0.1733, Validation Loss: 0.1696
Epoch [135/250], Train Loss: 0.1728, Validation Loss: 0.1691
Epoch [136/250], Train Loss: 0.1722, Validation Loss: 0.1686
Epoch [137/250], Train Loss: 0.1717, Validation Loss: 0.1681
Epoch [138/250], Train Loss: 0.1712, Validation Loss: 0.1676
Epoch [139/250], Train Loss: 0.1707, Validation Loss: 0.1671
Epoch [140/250], Train Loss: 0.1702, Validation Loss: 0.1666
Epoch [141/250], Train Loss: 0.1697, Validation Loss: 0.1661
Epoch [142/250], Train Loss: 0.1692, Validation Loss: 0.1656
Epoch [143/250], Train Loss: 0.1687, Validation Loss: 0.1651
Epoch [144/250], Train Loss: 0.1682, Validation Loss: 0.1646
Epoch [145/250], Train Loss: 0.1677, Validation Loss: 0.1641
Epoch [146/250], Train Loss: 0.1672, Validation Loss: 0.1636
Epoch [147/250], Train Loss: 0.1667, Validation Loss: 0.1632
Epoch [148/250], Train Loss: 0.1662, Validation Loss: 0.1627
Epoch [149/250], Train Loss: 0.1657, Validation Loss: 0.1622
Epoch [150/250], Train Loss: 0.1652, Validation Loss: 0.1617
Epoch [151/250], Train Loss: 0.1647, Validation Loss: 0.1613
Epoch [152/250], Train Loss: 0.1643, Validation Loss: 0.1608
Epoch [153/250], Train Loss: 0.1638, Validation Loss: 0.1603
Epoch [154/250], Train Loss: 0.1633, Validation Loss: 0.1599
Epoch [155/250], Train Loss: 0.1628, Validation Loss: 0.1594
Epoch [156/250], Train Loss: 0.1624, Validation Loss: 0.1589
Epoch [157/250], Train Loss: 0.1619, Validation Loss: 0.1585
Epoch [158/250], Train Loss: 0.1614, Validation Loss: 0.1580
Epoch [159/250], Train Loss: 0.1609, Validation Loss: 0.1575
Epoch [160/250], Train Loss: 0.1605, Validation Loss: 0.1571
Epoch [161/250], Train Loss: 0.1600, Validation Loss: 0.1566
Epoch [162/250], Train Loss: 0.1596, Validation Loss: 0.1562
Epoch [163/250], Train Loss: 0.1591, Validation Loss: 0.1557
Epoch [164/250], Train Loss: 0.1586, Validation Loss: 0.1553
Epoch [165/250], Train Loss: 0.1582, Validation Loss: 0.1548
Epoch [166/250], Train Loss: 0.1577, Validation Loss: 0.1543
Epoch [167/250], Train Loss: 0.1572, Validation Loss: 0.1539
Epoch [168/250], Train Loss: 0.1568, Validation Loss: 0.1535
Epoch [169/250], Train Loss: 0.1563, Validation Loss: 0.1530
Epoch [170/250], Train Loss: 0.1559, Validation Loss: 0.1526
Epoch [171/250], Train Loss: 0.1554, Validation Loss: 0.1521
Epoch [172/250], Train Loss: 0.1550, Validation Loss: 0.1517
Epoch [173/250], Train Loss: 0.1545, Validation Loss: 0.1513
Epoch [174/250], Train Loss: 0.1541, Validation Loss: 0.1508
Epoch [175/250], Train Loss: 0.1536, Validation Loss: 0.1504
Epoch [176/250], Train Loss: 0.1532, Validation Loss: 0.1500
Epoch [177/250], Train Loss: 0.1528, Validation Loss: 0.1495
Epoch [178/250], Train Loss: 0.1523, Validation Loss: 0.1491
Epoch [179/250], Train Loss: 0.1519, Validation Loss: 0.1487
Epoch [180/250], Train Loss: 0.1515, Validation Loss: 0.1482
Epoch [181/250], Train Loss: 0.1510, Validation Loss: 0.1478
Epoch [182/250], Train Loss: 0.1506, Validation Loss: 0.1474
Epoch [183/250], Train Loss: 0.1502, Validation Loss: 0.1470
Epoch [184/250], Train Loss: 0.1497, Validation Loss: 0.1466
Epoch [185/250], Train Loss: 0.1493, Validation Loss: 0.1462
Epoch [186/250], Train Loss: 0.1489, Validation Loss: 0.1458
Epoch [187/250], Train Loss: 0.1485, Validation Loss: 0.1454
Epoch [188/250], Train Loss: 0.1481, Validation Loss: 0.1449
Epoch [189/250], Train Loss: 0.1477, Validation Loss: 0.1445
Epoch [190/250], Train Loss: 0.1472, Validation Loss: 0.1441
Epoch [191/250], Train Loss: 0.1468, Validation Loss: 0.1437
Epoch [192/250], Train Loss: 0.1464, Validation Loss: 0.1433
Epoch [193/250], Train Loss: 0.1460, Validation Loss: 0.1429
Epoch [194/250], Train Loss: 0.1456, Validation Loss: 0.1425
Epoch [195/250], Train Loss: 0.1452, Validation Loss: 0.1421
Epoch [196/250], Train Loss: 0.1448, Validation Loss: 0.1417
Epoch [197/250], Train Loss: 0.1444, Validation Loss: 0.1413
Epoch [198/250], Train Loss: 0.1440, Validation Loss: 0.1409
Epoch [199/250], Train Loss: 0.1435, Validation Loss: 0.1405
Epoch [200/250], Train Loss: 0.1431, Validation Loss: 0.1401
Epoch [201/250], Train Loss: 0.1427, Validation Loss: 0.1397
Epoch [202/250], Train Loss: 0.1423, Validation Loss: 0.1393
Epoch [203/250], Train Loss: 0.1419, Validation Loss: 0.1389
Epoch [204/250], Train Loss: 0.1415, Validation Loss: 0.1385
Epoch [205/250], Train Loss: 0.1411, Validation Loss: 0.1382
Epoch [206/250], Train Loss: 0.1407, Validation Loss: 0.1378
Epoch [207/250], Train Loss: 0.1404, Validation Loss: 0.1374
Epoch [208/250], Train Loss: 0.1400, Validation Loss: 0.1370
Epoch [209/250], Train Loss: 0.1396, Validation Loss: 0.1366
Epoch [210/250], Train Loss: 0.1392, Validation Loss: 0.1363
Epoch [211/250], Train Loss: 0.1388, Validation Loss: 0.1359
Epoch [212/250], Train Loss: 0.1384, Validation Loss: 0.1355
Epoch [213/250], Train Loss: 0.1380, Validation Loss: 0.1351
Epoch [214/250], Train Loss: 0.1377, Validation Loss: 0.1347
Epoch [215/250], Train Loss: 0.1373, Validation Loss: 0.1344
Epoch [216/250], Train Loss: 0.1369, Validation Loss: 0.1340
Epoch [217/250], Train Loss: 0.1365, Validation Loss: 0.1336
Epoch [218/250], Train Loss: 0.1361, Validation Loss: 0.1332
Epoch [219/250], Train Loss: 0.1357, Validation Loss: 0.1329
Epoch [220/250], Train Loss: 0.1354, Validation Loss: 0.1325
Epoch [221/250], Train Loss: 0.1350, Validation Loss: 0.1321
Epoch [222/250], Train Loss: 0.1346, Validation Loss: 0.1318
Epoch [223/250], Train Loss: 0.1342, Validation Loss: 0.1314
Epoch [224/250], Train Loss: 0.1339, Validation Loss: 0.1310
Epoch [225/250], Train Loss: 0.1335, Validation Loss: 0.1307
Epoch [226/250], Train Loss: 0.1331, Validation Loss: 0.1303
Epoch [227/250], Train Loss: 0.1328, Validation Loss: 0.1300
Epoch [228/250], Train Loss: 0.1324, Validation Loss: 0.1296
Epoch [229/250], Train Loss: 0.1321, Validation Loss: 0.1293
Epoch [230/250], Train Loss: 0.1317, Validation Loss: 0.1289
Epoch [231/250], Train Loss: 0.1313, Validation Loss: 0.1286
Epoch [232/250], Train Loss: 0.1310, Validation Loss: 0.1282
Epoch [233/250], Train Loss: 0.1306, Validation Loss: 0.1279
Epoch [234/250], Train Loss: 0.1303, Validation Loss: 0.1275
Epoch [235/250], Train Loss: 0.1299, Validation Loss: 0.1272
Epoch [236/250], Train Loss: 0.1296, Validation Loss: 0.1268
Epoch [237/250], Train Loss: 0.1292, Validation Loss: 0.1265
Epoch [238/250], Train Loss: 0.1289, Validation Loss: 0.1262
Epoch [239/250], Train Loss: 0.1285, Validation Loss: 0.1258
Epoch [240/250], Train Loss: 0.1282, Validation Loss: 0.1255
Epoch [241/250], Train Loss: 0.1278, Validation Loss: 0.1252
Epoch [242/250], Train Loss: 0.1275, Validation Loss: 0.1248
Epoch [243/250], Train Loss: 0.1272, Validation Loss: 0.1245
Epoch [244/250], Train Loss: 0.1268, Validation Loss: 0.1242
Epoch [245/250], Train Loss: 0.1265, Validation Loss: 0.1238
Epoch [246/250], Train Loss: 0.1262, Validation Loss: 0.1235
Epoch [247/250], Train Loss: 0.1258, Validation Loss: 0.1232
Epoch [248/250], Train Loss: 0.1255, Validation Loss: 0.1228
Epoch [249/250], Train Loss: 0.1251, Validation Loss: 0.1225
Epoch [250/250], Train Loss: 0.1248, Validation Loss: 0.1222

Finished Training in 77.5

Noise Sigma:  0.5075
Creating datasets...
Start training...
Epoch [1/250], Train Loss: 0.4842, Validation Loss: 0.4064
Epoch [2/250], Train Loss: 0.3937, Validation Loss: 0.3563
Epoch [3/250], Train Loss: 0.3567, Validation Loss: 0.3570
Epoch [4/250], Train Loss: 0.3525, Validation Loss: 0.3598
Epoch [5/250], Train Loss: 0.3644, Validation Loss: 0.3609
Epoch [6/250], Train Loss: 0.3466, Validation Loss: 0.3579
Epoch [7/250], Train Loss: 0.3451, Validation Loss: 0.3412
Epoch [8/250], Train Loss: 0.3379, Validation Loss: 0.3467
Epoch [9/250], Train Loss: 0.3198, Validation Loss: 0.3384
Epoch [10/250], Train Loss: 0.3421, Validation Loss: 0.3551
Epoch [11/250], Train Loss: 0.3474, Validation Loss: 0.3422
Epoch [12/250], Train Loss: 0.3451, Validation Loss: 0.3309
Epoch [13/250], Train Loss: 0.3384, Validation Loss: 0.3373
Epoch [14/250], Train Loss: 0.3359, Validation Loss: 0.3474
Epoch [15/250], Train Loss: 0.3255, Validation Loss: 0.3455
Epoch [16/250], Train Loss: 0.3193, Validation Loss: 0.3464
Epoch [17/250], Train Loss: 0.3172, Validation Loss: 0.3177
Epoch [18/250], Train Loss: 0.2938, Validation Loss: 0.3002
Epoch [19/250], Train Loss: 0.3074, Validation Loss: 0.2942
Epoch [20/250], Train Loss: 0.2886, Validation Loss: 0.2857
Epoch [21/250], Train Loss: 0.2686, Validation Loss: 0.2749
Epoch [22/250], Train Loss: 0.2694, Validation Loss: 0.2542
Epoch [23/250], Train Loss: 0.2469, Validation Loss: 0.2359
Epoch [24/250], Train Loss: 0.2263, Validation Loss: 0.2193
Epoch [25/250], Train Loss: 0.2201, Validation Loss: 0.2066
Epoch [26/250], Train Loss: 0.2091, Validation Loss: 0.2093
Epoch [27/250], Train Loss: 0.2013, Validation Loss: 0.2187
Epoch [28/250], Train Loss: 0.2137, Validation Loss: 0.1973
Epoch [29/250], Train Loss: 0.2008, Validation Loss: 0.2343
Epoch [30/250], Train Loss: 0.2102, Validation Loss: 0.1844
Epoch [31/250], Train Loss: 0.2079, Validation Loss: 0.1738
Epoch [32/250], Train Loss: 0.1729, Validation Loss: 0.1323
Epoch [33/250], Train Loss: 0.1254, Validation Loss: 0.1103
Epoch [34/250], Train Loss: 0.0952, Validation Loss: 0.1720
Epoch [35/250], Train Loss: 0.0955, Validation Loss: 0.0963
Epoch [36/250], Train Loss: 0.1015, Validation Loss: 0.1125
Epoch [37/250], Train Loss: 0.0881, Validation Loss: 0.0922
Epoch [38/250], Train Loss: 0.0795, Validation Loss: 0.1009
Epoch [39/250], Train Loss: 0.0876, Validation Loss: 0.1152
Epoch [40/250], Train Loss: 0.0925, Validation Loss: 0.0859
Epoch [41/250], Train Loss: 0.0912, Validation Loss: 0.0823
Epoch [42/250], Train Loss: 0.0778, Validation Loss: 0.0861
Epoch [43/250], Train Loss: 0.0822, Validation Loss: 0.0760
Epoch [44/250], Train Loss: 0.0878, Validation Loss: 0.0808
Epoch [45/250], Train Loss: 0.0741, Validation Loss: 0.0872
Epoch [46/250], Train Loss: 0.0683, Validation Loss: 0.0710
Epoch [47/250], Train Loss: 0.0713, Validation Loss: 0.0813
Epoch [48/250], Train Loss: 0.0713, Validation Loss: 0.0715
Epoch [49/250], Train Loss: 0.0660, Validation Loss: 0.0673
Epoch [50/250], Train Loss: 0.0698, Validation Loss: 0.0739
Epoch [51/250], Train Loss: 0.0643, Validation Loss: 0.0864
Epoch [52/250], Train Loss: 0.0607, Validation Loss: 0.0708
Epoch [53/250], Train Loss: 0.0517, Validation Loss: 0.0855
Epoch [54/250], Train Loss: 0.0671, Validation Loss: 0.0796
Epoch [55/250], Train Loss: 0.0750, Validation Loss: 0.0770
Epoch [56/250], Train Loss: 0.0719, Validation Loss: 0.0877
Epoch [57/250], Train Loss: 0.0695, Validation Loss: 0.0626
Epoch [58/250], Train Loss: 0.0631, Validation Loss: 0.0583
Epoch [59/250], Train Loss: 0.0589, Validation Loss: 0.0629
Epoch [60/250], Train Loss: 0.0531, Validation Loss: 0.0643
Epoch [61/250], Train Loss: 0.0550, Validation Loss: 0.0561
Epoch [62/250], Train Loss: 0.0581, Validation Loss: 0.0571
Epoch [63/250], Train Loss: 0.0707, Validation Loss: 0.0674
Epoch [64/250], Train Loss: 0.0488, Validation Loss: 0.0774
Epoch [65/250], Train Loss: 0.0539, Validation Loss: 0.0609
Epoch [66/250], Train Loss: 0.0491, Validation Loss: 0.0680
Epoch [67/250], Train Loss: 0.0570, Validation Loss: 0.0554
Epoch [68/250], Train Loss: 0.0522, Validation Loss: 0.0587
Epoch [69/250], Train Loss: 0.0495, Validation Loss: 0.0551
Epoch [70/250], Train Loss: 0.0432, Validation Loss: 0.0486
Epoch [71/250], Train Loss: 0.0423, Validation Loss: 0.0829
Epoch [72/250], Train Loss: 0.0542, Validation Loss: 0.0561
Epoch [73/250], Train Loss: 0.0353, Validation Loss: 0.0455
Epoch [74/250], Train Loss: 0.0335, Validation Loss: 0.0426
Epoch [75/250], Train Loss: 0.0407, Validation Loss: 0.0580
Epoch [76/250], Train Loss: 0.0358, Validation Loss: 0.0495
Epoch [77/250], Train Loss: 0.0457, Validation Loss: 0.0468
Epoch [78/250], Train Loss: 0.0282, Validation Loss: 0.0418
Epoch [79/250], Train Loss: 0.0375, Validation Loss: 0.0541
Epoch [80/250], Train Loss: 0.0271, Validation Loss: 0.0413
Epoch [81/250], Train Loss: 0.0355, Validation Loss: 0.0509
Epoch [82/250], Train Loss: 0.0348, Validation Loss: 0.0357
Epoch [83/250], Train Loss: 0.0272, Validation Loss: 0.0412
Epoch [84/250], Train Loss: 0.0311, Validation Loss: 0.0456
Epoch [85/250], Train Loss: 0.0295, Validation Loss: 0.0417
Epoch [86/250], Train Loss: 0.0211, Validation Loss: 0.0339
Epoch [87/250], Train Loss: 0.0253, Validation Loss: 0.0321
Epoch [88/250], Train Loss: 0.0215, Validation Loss: 0.0341
Epoch [89/250], Train Loss: 0.0267, Validation Loss: 0.0334
Epoch [90/250], Train Loss: 0.0260, Validation Loss: 0.0470
Epoch [91/250], Train Loss: 0.0334, Validation Loss: 0.0477
Epoch [92/250], Train Loss: 0.0317, Validation Loss: 0.0326
Epoch [93/250], Train Loss: 0.0242, Validation Loss: 0.0480
Epoch [94/250], Train Loss: 0.0282, Validation Loss: 0.0348
Epoch [95/250], Train Loss: 0.0201, Validation Loss: 0.0326
Epoch [96/250], Train Loss: 0.0234, Validation Loss: 0.0274
Epoch [97/250], Train Loss: 0.0232, Validation Loss: 0.0320
Epoch [98/250], Train Loss: 0.0202, Validation Loss: 0.0326
Epoch [99/250], Train Loss: 0.0224, Validation Loss: 0.0516
Epoch [100/250], Train Loss: 0.0255, Validation Loss: 0.0357
Epoch [101/250], Train Loss: 0.0219, Validation Loss: 0.0325
Epoch [102/250], Train Loss: 0.0212, Validation Loss: 0.0337
Epoch [103/250], Train Loss: 0.0193, Validation Loss: 0.0369
Epoch [104/250], Train Loss: 0.0249, Validation Loss: 0.0257
Epoch [105/250], Train Loss: 0.0175, Validation Loss: 0.0289
Epoch [106/250], Train Loss: 0.0212, Validation Loss: 0.0305
Epoch [107/250], Train Loss: 0.0191, Validation Loss: 0.0304
Epoch [108/250], Train Loss: 0.0172, Validation Loss: 0.0291
Epoch [109/250], Train Loss: 0.0165, Validation Loss: 0.0230
Epoch [110/250], Train Loss: 0.0143, Validation Loss: 0.0289
Epoch [111/250], Train Loss: 0.0164, Validation Loss: 0.0378
Epoch [112/250], Train Loss: 0.0173, Validation Loss: 0.0293
Epoch [113/250], Train Loss: 0.0177, Validation Loss: 0.0284
Epoch [114/250], Train Loss: 0.0116, Validation Loss: 0.0325
Epoch [115/250], Train Loss: 0.0142, Validation Loss: 0.0315
Epoch [116/250], Train Loss: 0.0143, Validation Loss: 0.0247
Epoch [117/250], Train Loss: 0.0140, Validation Loss: 0.0382
Epoch [118/250], Train Loss: 0.0150, Validation Loss: 0.0328
Epoch [119/250], Train Loss: 0.0133, Validation Loss: 0.0210
Epoch [120/250], Train Loss: 0.0221, Validation Loss: 0.0275
Epoch [121/250], Train Loss: 0.0204, Validation Loss: 0.0221
Epoch [122/250], Train Loss: 0.0189, Validation Loss: 0.0389
Epoch [123/250], Train Loss: 0.0204, Validation Loss: 0.0260
Epoch [124/250], Train Loss: 0.0300, Validation Loss: 0.0709
Epoch [125/250], Train Loss: 0.0313, Validation Loss: 0.0278
Epoch [126/250], Train Loss: 0.0255, Validation Loss: 0.0621
Epoch [127/250], Train Loss: 0.0289, Validation Loss: 0.0312
Epoch [128/250], Train Loss: 0.0201, Validation Loss: 0.0230
Epoch [129/250], Train Loss: 0.0161, Validation Loss: 0.0221
Epoch [130/250], Train Loss: 0.0150, Validation Loss: 0.0189
Epoch [131/250], Train Loss: 0.0196, Validation Loss: 0.0406
Epoch [132/250], Train Loss: 0.0140, Validation Loss: 0.0223
Epoch [133/250], Train Loss: 0.0154, Validation Loss: 0.0229
Epoch [134/250], Train Loss: 0.0211, Validation Loss: 0.0245
Epoch [135/250], Train Loss: 0.0176, Validation Loss: 0.0213
Epoch [136/250], Train Loss: 0.0177, Validation Loss: 0.0326
Epoch [137/250], Train Loss: 0.0115, Validation Loss: 0.0292
Epoch [138/250], Train Loss: 0.0153, Validation Loss: 0.0315
Epoch [139/250], Train Loss: 0.0135, Validation Loss: 0.0272
Epoch [140/250], Train Loss: 0.0129, Validation Loss: 0.0342
Epoch [141/250], Train Loss: 0.0146, Validation Loss: 0.0209
Epoch [142/250], Train Loss: 0.0128, Validation Loss: 0.0258
Epoch [143/250], Train Loss: 0.0098, Validation Loss: 0.0289
Epoch [144/250], Train Loss: 0.0122, Validation Loss: 0.0223
Epoch [145/250], Train Loss: 0.0095, Validation Loss: 0.0227
Epoch [146/250], Train Loss: 0.0143, Validation Loss: 0.0236
Epoch [147/250], Train Loss: 0.0134, Validation Loss: 0.0229
Epoch [148/250], Train Loss: 0.0131, Validation Loss: 0.0229
Epoch [149/250], Train Loss: 0.0127, Validation Loss: 0.0454
Epoch [150/250], Train Loss: 0.0216, Validation Loss: 0.0351
Epoch [151/250], Train Loss: 0.0199, Validation Loss: 0.0305
Epoch [152/250], Train Loss: 0.0155, Validation Loss: 0.0330
Epoch [153/250], Train Loss: 0.0161, Validation Loss: 0.0213
Epoch [154/250], Train Loss: 0.0101, Validation Loss: 0.0367
Epoch [155/250], Train Loss: 0.0193, Validation Loss: 0.0302
Epoch [156/250], Train Loss: 0.0158, Validation Loss: 0.0330
Epoch [157/250], Train Loss: 0.0103, Validation Loss: 0.0401
Epoch [158/250], Train Loss: 0.0103, Validation Loss: 0.0474
Epoch [159/250], Train Loss: 0.0103, Validation Loss: 0.0391
Epoch [160/250], Train Loss: 0.0096, Validation Loss: 0.0259
Epoch [161/250], Train Loss: 0.0111, Validation Loss: 0.0248
Epoch [162/250], Train Loss: 0.0106, Validation Loss: 0.0220
Epoch [163/250], Train Loss: 0.0143, Validation Loss: 0.0357
Epoch [164/250], Train Loss: 0.0111, Validation Loss: 0.0426
Epoch [165/250], Train Loss: 0.0124, Validation Loss: 0.0401
Epoch [166/250], Train Loss: 0.0112, Validation Loss: 0.0323
Epoch [167/250], Train Loss: 0.0116, Validation Loss: 0.0266
Epoch [168/250], Train Loss: 0.0098, Validation Loss: 0.0198
Epoch [169/250], Train Loss: 0.0101, Validation Loss: 0.0349
Epoch [170/250], Train Loss: 0.0094, Validation Loss: 0.0220
Epoch [171/250], Train Loss: 0.0138, Validation Loss: 0.0185
Epoch [172/250], Train Loss: 0.0108, Validation Loss: 0.0307
Epoch [173/250], Train Loss: 0.0144, Validation Loss: 0.0281
Epoch [174/250], Train Loss: 0.0097, Validation Loss: 0.0257
Epoch [175/250], Train Loss: 0.0081, Validation Loss: 0.0187
Epoch [176/250], Train Loss: 0.0102, Validation Loss: 0.0248
Epoch [177/250], Train Loss: 0.0094, Validation Loss: 0.0192
Epoch [178/250], Train Loss: 0.0100, Validation Loss: 0.0187
Epoch [179/250], Train Loss: 0.0096, Validation Loss: 0.0235
Epoch [180/250], Train Loss: 0.0089, Validation Loss: 0.0150
Epoch [181/250], Train Loss: 0.0070, Validation Loss: 0.0203
Epoch [182/250], Train Loss: 0.0093, Validation Loss: 0.0331
Epoch [183/250], Train Loss: 0.0075, Validation Loss: 0.0281
Epoch [184/250], Train Loss: 0.0072, Validation Loss: 0.0287
Epoch [185/250], Train Loss: 0.0112, Validation Loss: 0.0226
Epoch [186/250], Train Loss: 0.0079, Validation Loss: 0.0196
Epoch [187/250], Train Loss: 0.0116, Validation Loss: 0.0170
Epoch [188/250], Train Loss: 0.0063, Validation Loss: 0.0329
Epoch [189/250], Train Loss: 0.0096, Validation Loss: 0.0151
Epoch [190/250], Train Loss: 0.0073, Validation Loss: 0.0144
Epoch [191/250], Train Loss: 0.0077, Validation Loss: 0.0247
Epoch [192/250], Train Loss: 0.0076, Validation Loss: 0.0313
Epoch [193/250], Train Loss: 0.0082, Validation Loss: 0.0180
Epoch [194/250], Train Loss: 0.0076, Validation Loss: 0.0219
Epoch [195/250], Train Loss: 0.0081, Validation Loss: 0.0217
Epoch [196/250], Train Loss: 0.0203, Validation Loss: 0.0210
Epoch [197/250], Train Loss: 0.0082, Validation Loss: 0.0182
Epoch [198/250], Train Loss: 0.0108, Validation Loss: 0.0238
Epoch [199/250], Train Loss: 0.0064, Validation Loss: 0.0258
Epoch [200/250], Train Loss: 0.0079, Validation Loss: 0.0307
Epoch [201/250], Train Loss: 0.0105, Validation Loss: 0.0188
Epoch [202/250], Train Loss: 0.0060, Validation Loss: 0.0239
Epoch [203/250], Train Loss: 0.0060, Validation Loss: 0.0140
Epoch [204/250], Train Loss: 0.0075, Validation Loss: 0.0149
Epoch [205/250], Train Loss: 0.0077, Validation Loss: 0.0277
Epoch [206/250], Train Loss: 0.0069, Validation Loss: 0.0189
Epoch [207/250], Train Loss: 0.0098, Validation Loss: 0.0235
Epoch [208/250], Train Loss: 0.0100, Validation Loss: 0.0180
Epoch [209/250], Train Loss: 0.0055, Validation Loss: 0.0230
Epoch [210/250], Train Loss: 0.0078, Validation Loss: 0.0098
Epoch [211/250], Train Loss: 0.0092, Validation Loss: 0.0276
Epoch [212/250], Train Loss: 0.0100, Validation Loss: 0.0240
Epoch [213/250], Train Loss: 0.0058, Validation Loss: 0.0191
Epoch [214/250], Train Loss: 0.0075, Validation Loss: 0.0328
Epoch [215/250], Train Loss: 0.0081, Validation Loss: 0.0272
Epoch [216/250], Train Loss: 0.0079, Validation Loss: 0.0333
Epoch [217/250], Train Loss: 0.0059, Validation Loss: 0.0463
Epoch [218/250], Train Loss: 0.0091, Validation Loss: 0.0224
Epoch [219/250], Train Loss: 0.0084, Validation Loss: 0.0192
Epoch [220/250], Train Loss: 0.0066, Validation Loss: 0.0215
Epoch [221/250], Train Loss: 0.0067, Validation Loss: 0.0306
Epoch [222/250], Train Loss: 0.0102, Validation Loss: 0.0387
Epoch [223/250], Train Loss: 0.0063, Validation Loss: 0.0223
Epoch [224/250], Train Loss: 0.0084, Validation Loss: 0.0249
Epoch [225/250], Train Loss: 0.0052, Validation Loss: 0.0203
Epoch [226/250], Train Loss: 0.0058, Validation Loss: 0.0215
Epoch [227/250], Train Loss: 0.0088, Validation Loss: 0.0309
Epoch [228/250], Train Loss: 0.0053, Validation Loss: 0.0667
Epoch [229/250], Train Loss: 0.0134, Validation Loss: 0.0248
Epoch [230/250], Train Loss: 0.0054, Validation Loss: 0.0221
Epoch [231/250], Train Loss: 0.0059, Validation Loss: 0.0145
Epoch [232/250], Train Loss: 0.0094, Validation Loss: 0.0197
Epoch [233/250], Train Loss: 0.0059, Validation Loss: 0.0222
Epoch [234/250], Train Loss: 0.0114, Validation Loss: 0.0237
Epoch [235/250], Train Loss: 0.0064, Validation Loss: 0.0137
Epoch [236/250], Train Loss: 0.0069, Validation Loss: 0.0256
Epoch [237/250], Train Loss: 0.0082, Validation Loss: 0.0249
Epoch [238/250], Train Loss: 0.0148, Validation Loss: 0.0259
Epoch [239/250], Train Loss: 0.0083, Validation Loss: 0.0214
Epoch [240/250], Train Loss: 0.0068, Validation Loss: 0.0285
Epoch [241/250], Train Loss: 0.0093, Validation Loss: 0.0205
Epoch [242/250], Train Loss: 0.0085, Validation Loss: 0.0213
Epoch [243/250], Train Loss: 0.0079, Validation Loss: 0.0170
Epoch [244/250], Train Loss: 0.0086, Validation Loss: 0.0247
Epoch [245/250], Train Loss: 0.0065, Validation Loss: 0.0242
Epoch [246/250], Train Loss: 0.0061, Validation Loss: 0.0164
Epoch [247/250], Train Loss: 0.0063, Validation Loss: 0.0233
Epoch [248/250], Train Loss: 0.0058, Validation Loss: 0.0167
Epoch [249/250], Train Loss: 0.0067, Validation Loss: 0.0163
Epoch [250/250], Train Loss: 0.0078, Validation Loss: 0.0140

Finished Training in 77.0

Noise Sigma:  1.005
Creating datasets...
Start training...
Epoch [1/250], Train Loss: 0.6792, Validation Loss: 0.5314
Epoch [2/250], Train Loss: 0.4629, Validation Loss: 0.4940
Epoch [3/250], Train Loss: 0.4804, Validation Loss: 0.4766
Epoch [4/250], Train Loss: 0.4002, Validation Loss: 0.3253
Epoch [5/250], Train Loss: 0.2891, Validation Loss: 0.3659
Epoch [6/250], Train Loss: 0.3124, Validation Loss: 0.3020
Epoch [7/250], Train Loss: 0.3270, Validation Loss: 0.2674
Epoch [8/250], Train Loss: 0.2889, Validation Loss: 0.3070
Epoch [9/250], Train Loss: 0.2475, Validation Loss: 0.2504
Epoch [10/250], Train Loss: 0.2472, Validation Loss: 0.2712
Epoch [11/250], Train Loss: 0.2466, Validation Loss: 0.2287
Epoch [12/250], Train Loss: 0.2775, Validation Loss: 0.2147
Epoch [13/250], Train Loss: 0.2654, Validation Loss: 0.2806
Epoch [14/250], Train Loss: 0.2293, Validation Loss: 0.3114
Epoch [15/250], Train Loss: 0.2370, Validation Loss: 0.2208
Epoch [16/250], Train Loss: 0.2344, Validation Loss: 0.2605
Epoch [17/250], Train Loss: 0.2350, Validation Loss: 0.2043
Epoch [18/250], Train Loss: 0.1834, Validation Loss: 0.2097
Epoch [19/250], Train Loss: 0.2103, Validation Loss: 0.2091
Epoch [20/250], Train Loss: 0.1932, Validation Loss: 0.2154
Epoch [21/250], Train Loss: 0.1948, Validation Loss: 0.2104
Epoch [22/250], Train Loss: 0.2135, Validation Loss: 0.1996
Epoch [23/250], Train Loss: 0.1705, Validation Loss: 0.1824
Epoch [24/250], Train Loss: 0.1918, Validation Loss: 0.1715
Epoch [25/250], Train Loss: 0.1955, Validation Loss: 0.2047
Epoch [26/250], Train Loss: 0.1876, Validation Loss: 0.2080
Epoch [27/250], Train Loss: 0.1874, Validation Loss: 0.1816
Epoch [28/250], Train Loss: 0.1977, Validation Loss: 0.1765
Epoch [29/250], Train Loss: 0.1994, Validation Loss: 0.2004
Epoch [30/250], Train Loss: 0.1920, Validation Loss: 0.1637
Epoch [31/250], Train Loss: 0.1678, Validation Loss: 0.2112
Epoch [32/250], Train Loss: 0.1759, Validation Loss: 0.1944
Epoch [33/250], Train Loss: 0.1575, Validation Loss: 0.1663
Epoch [34/250], Train Loss: 0.1817, Validation Loss: 0.1761
Epoch [35/250], Train Loss: 0.1577, Validation Loss: 0.1708
Epoch [36/250], Train Loss: 0.1753, Validation Loss: 0.1439
Epoch [37/250], Train Loss: 0.1914, Validation Loss: 0.1862
Epoch [38/250], Train Loss: 0.1859, Validation Loss: 0.1832
Epoch [39/250], Train Loss: 0.1694, Validation Loss: 0.1844
Epoch [40/250], Train Loss: 0.1660, Validation Loss: 0.1927
Epoch [41/250], Train Loss: 0.2038, Validation Loss: 0.1548
Epoch [42/250], Train Loss: 0.1830, Validation Loss: 0.1610
Epoch [43/250], Train Loss: 0.1631, Validation Loss: 0.1703
Epoch [44/250], Train Loss: 0.1460, Validation Loss: 0.1552
Epoch [45/250], Train Loss: 0.1571, Validation Loss: 0.1608
Epoch [46/250], Train Loss: 0.2046, Validation Loss: 0.1941
Epoch [47/250], Train Loss: 0.1616, Validation Loss: 0.2065
Epoch [48/250], Train Loss: 0.1637, Validation Loss: 0.1927
Epoch [49/250], Train Loss: 0.2074, Validation Loss: 0.2202
Epoch [50/250], Train Loss: 0.1590, Validation Loss: 0.1555
Epoch [51/250], Train Loss: 0.1473, Validation Loss: 0.1435
Epoch [52/250], Train Loss: 0.1454, Validation Loss: 0.1628
Epoch [53/250], Train Loss: 0.1629, Validation Loss: 0.1401
Epoch [54/250], Train Loss: 0.1338, Validation Loss: 0.1979
Epoch [55/250], Train Loss: 0.1903, Validation Loss: 0.1640
Epoch [56/250], Train Loss: 0.1568, Validation Loss: 0.1893
Epoch [57/250], Train Loss: 0.1644, Validation Loss: 0.1593
Epoch [58/250], Train Loss: 0.1271, Validation Loss: 0.1396
Epoch [59/250], Train Loss: 0.1279, Validation Loss: 0.1539
Epoch [60/250], Train Loss: 0.1490, Validation Loss: 0.1313
Epoch [61/250], Train Loss: 0.1289, Validation Loss: 0.1407
Epoch [62/250], Train Loss: 0.1297, Validation Loss: 0.1498
Epoch [63/250], Train Loss: 0.1495, Validation Loss: 0.1551
Epoch [64/250], Train Loss: 0.1465, Validation Loss: 0.1666
Epoch [65/250], Train Loss: 0.1329, Validation Loss: 0.1791
Epoch [66/250], Train Loss: 0.1618, Validation Loss: 0.1556
Epoch [67/250], Train Loss: 0.1290, Validation Loss: 0.1403
Epoch [68/250], Train Loss: 0.1371, Validation Loss: 0.1588
Epoch [69/250], Train Loss: 0.1508, Validation Loss: 0.1639
Epoch [70/250], Train Loss: 0.1635, Validation Loss: 0.1469
Epoch [71/250], Train Loss: 0.1368, Validation Loss: 0.1518
Epoch [72/250], Train Loss: 0.1516, Validation Loss: 0.1327
Epoch [73/250], Train Loss: 0.1276, Validation Loss: 0.1520
Epoch [74/250], Train Loss: 0.1296, Validation Loss: 0.1550
Epoch [75/250], Train Loss: 0.1406, Validation Loss: 0.1537
Epoch [76/250], Train Loss: 0.1144, Validation Loss: 0.1638
Epoch [77/250], Train Loss: 0.1339, Validation Loss: 0.1458
Epoch [78/250], Train Loss: 0.1224, Validation Loss: 0.1591
Epoch [79/250], Train Loss: 0.1355, Validation Loss: 0.1844
Epoch [80/250], Train Loss: 0.1797, Validation Loss: 0.1347
Epoch [81/250], Train Loss: 0.1669, Validation Loss: 0.1725
Epoch [82/250], Train Loss: 0.1474, Validation Loss: 0.1462
Epoch [83/250], Train Loss: 0.1390, Validation Loss: 0.1308
Epoch [84/250], Train Loss: 0.1305, Validation Loss: 0.1379
Epoch [85/250], Train Loss: 0.1227, Validation Loss: 0.1128
Epoch [86/250], Train Loss: 0.1336, Validation Loss: 0.1212
Epoch [87/250], Train Loss: 0.1086, Validation Loss: 0.1650
Epoch [88/250], Train Loss: 0.1284, Validation Loss: 0.1247
Epoch [89/250], Train Loss: 0.1295, Validation Loss: 0.1642
Epoch [90/250], Train Loss: 0.1333, Validation Loss: 0.1470
Epoch [91/250], Train Loss: 0.1144, Validation Loss: 0.1112
Epoch [92/250], Train Loss: 0.1366, Validation Loss: 0.1194
Epoch [93/250], Train Loss: 0.1050, Validation Loss: 0.1591
Epoch [94/250], Train Loss: 0.1221, Validation Loss: 0.1424
Epoch [95/250], Train Loss: 0.1284, Validation Loss: 0.1277
Epoch [96/250], Train Loss: 0.1472, Validation Loss: 0.1285
Epoch [97/250], Train Loss: 0.1210, Validation Loss: 0.2091
Epoch [98/250], Train Loss: 0.1680, Validation Loss: 0.1226
Epoch [99/250], Train Loss: 0.1633, Validation Loss: 0.1633
Epoch [100/250], Train Loss: 0.1406, Validation Loss: 0.1534
Epoch [101/250], Train Loss: 0.1501, Validation Loss: 0.1690
Epoch [102/250], Train Loss: 0.1250, Validation Loss: 0.1503
Epoch [103/250], Train Loss: 0.1146, Validation Loss: 0.1137
Epoch [104/250], Train Loss: 0.1080, Validation Loss: 0.1232
Epoch [105/250], Train Loss: 0.1172, Validation Loss: 0.1447
Epoch [106/250], Train Loss: 0.1300, Validation Loss: 0.1134
Epoch [107/250], Train Loss: 0.1109, Validation Loss: 0.1232
Epoch [108/250], Train Loss: 0.1172, Validation Loss: 0.1129
Epoch [109/250], Train Loss: 0.1122, Validation Loss: 0.1337
Epoch [110/250], Train Loss: 0.0986, Validation Loss: 0.1419
Epoch [111/250], Train Loss: 0.1066, Validation Loss: 0.1172
Epoch [112/250], Train Loss: 0.1248, Validation Loss: 0.1707
Epoch [113/250], Train Loss: 0.1371, Validation Loss: 0.1539
Epoch [114/250], Train Loss: 0.1548, Validation Loss: 0.1332
Epoch [115/250], Train Loss: 0.1448, Validation Loss: 0.1093
Epoch [116/250], Train Loss: 0.0963, Validation Loss: 0.1579
Epoch [117/250], Train Loss: 0.1110, Validation Loss: 0.1193
Epoch [118/250], Train Loss: 0.1235, Validation Loss: 0.1234
Epoch [119/250], Train Loss: 0.1150, Validation Loss: 0.1398
Epoch [120/250], Train Loss: 0.1030, Validation Loss: 0.1436
Epoch [121/250], Train Loss: 0.1053, Validation Loss: 0.1109
Epoch [122/250], Train Loss: 0.1063, Validation Loss: 0.1268
Epoch [123/250], Train Loss: 0.1094, Validation Loss: 0.1186
Epoch [124/250], Train Loss: 0.1108, Validation Loss: 0.1121
Epoch [125/250], Train Loss: 0.0960, Validation Loss: 0.1227
Epoch [126/250], Train Loss: 0.1021, Validation Loss: 0.1465
Epoch [127/250], Train Loss: 0.1434, Validation Loss: 0.1542
Epoch [128/250], Train Loss: 0.1191, Validation Loss: 0.1560
Epoch [129/250], Train Loss: 0.1088, Validation Loss: 0.1221
Epoch [130/250], Train Loss: 0.1331, Validation Loss: 0.1233
Epoch [131/250], Train Loss: 0.1007, Validation Loss: 0.1291
Epoch [132/250], Train Loss: 0.1008, Validation Loss: 0.1220
Epoch [133/250], Train Loss: 0.1151, Validation Loss: 0.1202
Epoch [134/250], Train Loss: 0.1221, Validation Loss: 0.1492
Epoch [135/250], Train Loss: 0.0968, Validation Loss: 0.1021
Epoch [136/250], Train Loss: 0.0985, Validation Loss: 0.1254
Epoch [137/250], Train Loss: 0.1052, Validation Loss: 0.1064
Epoch [138/250], Train Loss: 0.0728, Validation Loss: 0.1267
Epoch [139/250], Train Loss: 0.1300, Validation Loss: 0.1137
Epoch [140/250], Train Loss: 0.1122, Validation Loss: 0.2107
Epoch [141/250], Train Loss: 0.1831, Validation Loss: 0.1581
Epoch [142/250], Train Loss: 0.1312, Validation Loss: 0.1493
Epoch [143/250], Train Loss: 0.1280, Validation Loss: 0.1306
Epoch [144/250], Train Loss: 0.1413, Validation Loss: 0.1258
Epoch [145/250], Train Loss: 0.1459, Validation Loss: 0.1286
Epoch [146/250], Train Loss: 0.1113, Validation Loss: 0.1073
Epoch [147/250], Train Loss: 0.0982, Validation Loss: 0.1228
Epoch [148/250], Train Loss: 0.0991, Validation Loss: 0.1389
Epoch [149/250], Train Loss: 0.1104, Validation Loss: 0.1229
Epoch [150/250], Train Loss: 0.1129, Validation Loss: 0.1693
Epoch [151/250], Train Loss: 0.1097, Validation Loss: 0.1130
Epoch [152/250], Train Loss: 0.1024, Validation Loss: 0.1387
Epoch [153/250], Train Loss: 0.1128, Validation Loss: 0.1123
Epoch [154/250], Train Loss: 0.1129, Validation Loss: 0.1129
Epoch [155/250], Train Loss: 0.1112, Validation Loss: 0.1181
Epoch [156/250], Train Loss: 0.1233, Validation Loss: 0.1014
Epoch [157/250], Train Loss: 0.0965, Validation Loss: 0.1109
Epoch [158/250], Train Loss: 0.0978, Validation Loss: 0.1151
Epoch [159/250], Train Loss: 0.1148, Validation Loss: 0.1460
Epoch [160/250], Train Loss: 0.1143, Validation Loss: 0.1400
Epoch [161/250], Train Loss: 0.1268, Validation Loss: 0.1305
Epoch [162/250], Train Loss: 0.1095, Validation Loss: 0.1488
Epoch [163/250], Train Loss: 0.1410, Validation Loss: 0.1112
Epoch [164/250], Train Loss: 0.1250, Validation Loss: 0.1164
Epoch [165/250], Train Loss: 0.1042, Validation Loss: 0.1200
Epoch [166/250], Train Loss: 0.1264, Validation Loss: 0.1027
Epoch [167/250], Train Loss: 0.0976, Validation Loss: 0.1198
Epoch [168/250], Train Loss: 0.0950, Validation Loss: 0.1221
Epoch [169/250], Train Loss: 0.1067, Validation Loss: 0.1113
Epoch [170/250], Train Loss: 0.0956, Validation Loss: 0.1112
Epoch [171/250], Train Loss: 0.0828, Validation Loss: 0.0909
Epoch [172/250], Train Loss: 0.0763, Validation Loss: 0.1021
Epoch [173/250], Train Loss: 0.1134, Validation Loss: 0.1203
Epoch [174/250], Train Loss: 0.0778, Validation Loss: 0.1312
Epoch [175/250], Train Loss: 0.1121, Validation Loss: 0.1116
Epoch [176/250], Train Loss: 0.0871, Validation Loss: 0.1198
Epoch [177/250], Train Loss: 0.0954, Validation Loss: 0.0866
Epoch [178/250], Train Loss: 0.0898, Validation Loss: 0.1164
Epoch [179/250], Train Loss: 0.0982, Validation Loss: 0.1363
Epoch [180/250], Train Loss: 0.1018, Validation Loss: 0.0987
Epoch [181/250], Train Loss: 0.0934, Validation Loss: 0.1255
Epoch [182/250], Train Loss: 0.1265, Validation Loss: 0.1057
Epoch [183/250], Train Loss: 0.0874, Validation Loss: 0.1990
Epoch [184/250], Train Loss: 0.1802, Validation Loss: 0.1288
Epoch [185/250], Train Loss: 0.1182, Validation Loss: 0.1350
Epoch [186/250], Train Loss: 0.1170, Validation Loss: 0.1163
Epoch [187/250], Train Loss: 0.0983, Validation Loss: 0.1111
Epoch [188/250], Train Loss: 0.1201, Validation Loss: 0.1832
Epoch [189/250], Train Loss: 0.1386, Validation Loss: 0.1220
Epoch [190/250], Train Loss: 0.1098, Validation Loss: 0.1584
Epoch [191/250], Train Loss: 0.1343, Validation Loss: 0.1217
Epoch [192/250], Train Loss: 0.1041, Validation Loss: 0.1133
Epoch [193/250], Train Loss: 0.0944, Validation Loss: 0.1215
Epoch [194/250], Train Loss: 0.1126, Validation Loss: 0.1381
Epoch [195/250], Train Loss: 0.0915, Validation Loss: 0.1156
Epoch [196/250], Train Loss: 0.0915, Validation Loss: 0.1046
Epoch [197/250], Train Loss: 0.0812, Validation Loss: 0.1195
Epoch [198/250], Train Loss: 0.1196, Validation Loss: 0.1013
Epoch [199/250], Train Loss: 0.1013, Validation Loss: 0.1203
Epoch [200/250], Train Loss: 0.0847, Validation Loss: 0.0953
Epoch [201/250], Train Loss: 0.0850, Validation Loss: 0.1165
Epoch [202/250], Train Loss: 0.0758, Validation Loss: 0.1212
Epoch [203/250], Train Loss: 0.0689, Validation Loss: 0.1173
Epoch [204/250], Train Loss: 0.0770, Validation Loss: 0.1083
Epoch [205/250], Train Loss: 0.1068, Validation Loss: 0.1400
Epoch [206/250], Train Loss: 0.0919, Validation Loss: 0.1094
Epoch [207/250], Train Loss: 0.0880, Validation Loss: 0.1169
Epoch [208/250], Train Loss: 0.0939, Validation Loss: 0.1458
Epoch [209/250], Train Loss: 0.0806, Validation Loss: 0.1075
Epoch [210/250], Train Loss: 0.0816, Validation Loss: 0.1139
Epoch [211/250], Train Loss: 0.0832, Validation Loss: 0.1472
Epoch [212/250], Train Loss: 0.1003, Validation Loss: 0.0975
Epoch [213/250], Train Loss: 0.0944, Validation Loss: 0.1105
Epoch [214/250], Train Loss: 0.0852, Validation Loss: 0.1124
Epoch [215/250], Train Loss: 0.0849, Validation Loss: 0.1163
Epoch [216/250], Train Loss: 0.0859, Validation Loss: 0.1008
Epoch [217/250], Train Loss: 0.0956, Validation Loss: 0.0991
Epoch [218/250], Train Loss: 0.0796, Validation Loss: 0.1135
Epoch [219/250], Train Loss: 0.0723, Validation Loss: 0.0916
Epoch [220/250], Train Loss: 0.0754, Validation Loss: 0.0928
Epoch [221/250], Train Loss: 0.0900, Validation Loss: 0.0957
Epoch [222/250], Train Loss: 0.0739, Validation Loss: 0.1088
Epoch [223/250], Train Loss: 0.0962, Validation Loss: 0.1140
Epoch [224/250], Train Loss: 0.0937, Validation Loss: 0.0991
Epoch [225/250], Train Loss: 0.0749, Validation Loss: 0.1125
Epoch [226/250], Train Loss: 0.0976, Validation Loss: 0.1048
Epoch [227/250], Train Loss: 0.0625, Validation Loss: 0.0947
Epoch [228/250], Train Loss: 0.0847, Validation Loss: 0.1057
Epoch [229/250], Train Loss: 0.0946, Validation Loss: 0.0839
Epoch [230/250], Train Loss: 0.0799, Validation Loss: 0.0940
Epoch [231/250], Train Loss: 0.0767, Validation Loss: 0.0887
Epoch [232/250], Train Loss: 0.0760, Validation Loss: 0.0765
Epoch [233/250], Train Loss: 0.0696, Validation Loss: 0.0921
Epoch [234/250], Train Loss: 0.0826, Validation Loss: 0.1029
Epoch [235/250], Train Loss: 0.0691, Validation Loss: 0.0829
Epoch [236/250], Train Loss: 0.0710, Validation Loss: 0.0919
Epoch [237/250], Train Loss: 0.0932, Validation Loss: 0.0752
Epoch [238/250], Train Loss: 0.0887, Validation Loss: 0.0772
Epoch [239/250], Train Loss: 0.0813, Validation Loss: 0.0939
Epoch [240/250], Train Loss: 0.1011, Validation Loss: 0.1043
Epoch [241/250], Train Loss: 0.0744, Validation Loss: 0.1009
Epoch [242/250], Train Loss: 0.0935, Validation Loss: 0.0929
Epoch [243/250], Train Loss: 0.0838, Validation Loss: 0.1265
Epoch [244/250], Train Loss: 0.0978, Validation Loss: 0.1054
Epoch [245/250], Train Loss: 0.0816, Validation Loss: 0.1175
Epoch [246/250], Train Loss: 0.0786, Validation Loss: 0.1166
Epoch [247/250], Train Loss: 0.0796, Validation Loss: 0.1406
Epoch [248/250], Train Loss: 0.1089, Validation Loss: 0.1161
Epoch [249/250], Train Loss: 0.0722, Validation Loss: 0.1340
Epoch [250/250], Train Loss: 0.0916, Validation Loss: 0.0888

Finished Training in 76.8

Noise Sigma:  1.5025
Creating datasets...
Start training...
Epoch [1/250], Train Loss: 0.3556, Validation Loss: 0.3693
Epoch [2/250], Train Loss: 0.3364, Validation Loss: 0.3141
Epoch [3/250], Train Loss: 0.2669, Validation Loss: 0.3161
Epoch [4/250], Train Loss: 0.2914, Validation Loss: 0.3036
Epoch [5/250], Train Loss: 0.2661, Validation Loss: 0.2669
Epoch [6/250], Train Loss: 0.2662, Validation Loss: 0.2590
Epoch [7/250], Train Loss: 0.2660, Validation Loss: 0.3039
Epoch [8/250], Train Loss: 0.2601, Validation Loss: 0.2438
Epoch [9/250], Train Loss: 0.2642, Validation Loss: 0.2598
Epoch [10/250], Train Loss: 0.2467, Validation Loss: 0.2411
Epoch [11/250], Train Loss: 0.2310, Validation Loss: 0.2296
Epoch [12/250], Train Loss: 0.2392, Validation Loss: 0.2375
Epoch [13/250], Train Loss: 0.2509, Validation Loss: 0.2467
Epoch [14/250], Train Loss: 0.2561, Validation Loss: 0.2486
Epoch [15/250], Train Loss: 0.2518, Validation Loss: 0.2484
Epoch [16/250], Train Loss: 0.2477, Validation Loss: 0.2516
Epoch [17/250], Train Loss: 0.2345, Validation Loss: 0.2230
Epoch [18/250], Train Loss: 0.2213, Validation Loss: 0.2644
Epoch [19/250], Train Loss: 0.2511, Validation Loss: 0.2351
Epoch [20/250], Train Loss: 0.2348, Validation Loss: 0.2579
Epoch [21/250], Train Loss: 0.2420, Validation Loss: 0.2344
Epoch [22/250], Train Loss: 0.2434, Validation Loss: 0.2461
Epoch [23/250], Train Loss: 0.2301, Validation Loss: 0.2486
Epoch [24/250], Train Loss: 0.2033, Validation Loss: 0.2178
Epoch [25/250], Train Loss: 0.2154, Validation Loss: 0.2385
Epoch [26/250], Train Loss: 0.2146, Validation Loss: 0.2385
Epoch [27/250], Train Loss: 0.1961, Validation Loss: 0.2332
Epoch [28/250], Train Loss: 0.1957, Validation Loss: 0.2542
Epoch [29/250], Train Loss: 0.2375, Validation Loss: 0.2308
Epoch [30/250], Train Loss: 0.2172, Validation Loss: 0.2459
Epoch [31/250], Train Loss: 0.2483, Validation Loss: 0.2516
Epoch [32/250], Train Loss: 0.2071, Validation Loss: 0.2195
Epoch [33/250], Train Loss: 0.2281, Validation Loss: 0.2602
Epoch [34/250], Train Loss: 0.1890, Validation Loss: 0.2101
Epoch [35/250], Train Loss: 0.2098, Validation Loss: 0.2263
Epoch [36/250], Train Loss: 0.2102, Validation Loss: 0.2422
Epoch [37/250], Train Loss: 0.2171, Validation Loss: 0.2205
Epoch [38/250], Train Loss: 0.2087, Validation Loss: 0.2340
Epoch [39/250], Train Loss: 0.1845, Validation Loss: 0.2127
Epoch [40/250], Train Loss: 0.2252, Validation Loss: 0.1876
Epoch [41/250], Train Loss: 0.2131, Validation Loss: 0.2195
Epoch [42/250], Train Loss: 0.1910, Validation Loss: 0.2185
Epoch [43/250], Train Loss: 0.2470, Validation Loss: 0.2047
Epoch [44/250], Train Loss: 0.2086, Validation Loss: 0.2031
Epoch [45/250], Train Loss: 0.2008, Validation Loss: 0.2131
Epoch [46/250], Train Loss: 0.1717, Validation Loss: 0.2194
Epoch [47/250], Train Loss: 0.2189, Validation Loss: 0.2105
Epoch [48/250], Train Loss: 0.1785, Validation Loss: 0.2011
Epoch [49/250], Train Loss: 0.1783, Validation Loss: 0.2015
Epoch [50/250], Train Loss: 0.2142, Validation Loss: 0.2243
Epoch [51/250], Train Loss: 0.2105, Validation Loss: 0.2198
Epoch [52/250], Train Loss: 0.2140, Validation Loss: 0.2310
Epoch [53/250], Train Loss: 0.2115, Validation Loss: 0.2009
Epoch [54/250], Train Loss: 0.1797, Validation Loss: 0.2236
Epoch [55/250], Train Loss: 0.1946, Validation Loss: 0.1831
Epoch [56/250], Train Loss: 0.2185, Validation Loss: 0.2132
Epoch [57/250], Train Loss: 0.1857, Validation Loss: 0.2237
Epoch [58/250], Train Loss: 0.1741, Validation Loss: 0.2319
Epoch [59/250], Train Loss: 0.1930, Validation Loss: 0.2042
Epoch [60/250], Train Loss: 0.1848, Validation Loss: 0.2245
Epoch [61/250], Train Loss: 0.2251, Validation Loss: 0.2093
Epoch [62/250], Train Loss: 0.2097, Validation Loss: 0.2026
Epoch [63/250], Train Loss: 0.1946, Validation Loss: 0.1865
Epoch [64/250], Train Loss: 0.2181, Validation Loss: 0.2134
Epoch [65/250], Train Loss: 0.1882, Validation Loss: 0.1949
Epoch [66/250], Train Loss: 0.2022, Validation Loss: 0.1748
Epoch [67/250], Train Loss: 0.1851, Validation Loss: 0.1750
Epoch [68/250], Train Loss: 0.1726, Validation Loss: 0.1889
Epoch [69/250], Train Loss: 0.1827, Validation Loss: 0.1840
Epoch [70/250], Train Loss: 0.1717, Validation Loss: 0.1891
Epoch [71/250], Train Loss: 0.1956, Validation Loss: 0.2115
Epoch [72/250], Train Loss: 0.1906, Validation Loss: 0.1879
Epoch [73/250], Train Loss: 0.2044, Validation Loss: 0.1841
Epoch [74/250], Train Loss: 0.1627, Validation Loss: 0.1852
Epoch [75/250], Train Loss: 0.1705, Validation Loss: 0.1918
Epoch [76/250], Train Loss: 0.1634, Validation Loss: 0.1854
Epoch [77/250], Train Loss: 0.1745, Validation Loss: 0.1882
Epoch [78/250], Train Loss: 0.1814, Validation Loss: 0.1886
Epoch [79/250], Train Loss: 0.1529, Validation Loss: 0.1913
Epoch [80/250], Train Loss: 0.1732, Validation Loss: 0.1891
Epoch [81/250], Train Loss: 0.1631, Validation Loss: 0.1967
Epoch [82/250], Train Loss: 0.1971, Validation Loss: 0.1979
Epoch [83/250], Train Loss: 0.1591, Validation Loss: 0.1613
Epoch [84/250], Train Loss: 0.1616, Validation Loss: 0.1675
Epoch [85/250], Train Loss: 0.1673, Validation Loss: 0.1618
Epoch [86/250], Train Loss: 0.1548, Validation Loss: 0.1842
Epoch [87/250], Train Loss: 0.1645, Validation Loss: 0.1585
Epoch [88/250], Train Loss: 0.1635, Validation Loss: 0.1695
Epoch [89/250], Train Loss: 0.1609, Validation Loss: 0.1819
Epoch [90/250], Train Loss: 0.1831, Validation Loss: 0.1756
Epoch [91/250], Train Loss: 0.1642, Validation Loss: 0.2125
Epoch [92/250], Train Loss: 0.1786, Validation Loss: 0.1902
Epoch [93/250], Train Loss: 0.1798, Validation Loss: 0.1907
Epoch [94/250], Train Loss: 0.1750, Validation Loss: 0.1886
Epoch [95/250], Train Loss: 0.1766, Validation Loss: 0.1712
Epoch [96/250], Train Loss: 0.1631, Validation Loss: 0.2116
Epoch [97/250], Train Loss: 0.1842, Validation Loss: 0.1695
Epoch [98/250], Train Loss: 0.1538, Validation Loss: 0.1609
Epoch [99/250], Train Loss: 0.1540, Validation Loss: 0.1713
Epoch [100/250], Train Loss: 0.1861, Validation Loss: 0.1715
Epoch [101/250], Train Loss: 0.1611, Validation Loss: 0.1789
Epoch [102/250], Train Loss: 0.1809, Validation Loss: 0.1581
Epoch [103/250], Train Loss: 0.1748, Validation Loss: 0.1686
Epoch [104/250], Train Loss: 0.1657, Validation Loss: 0.1569
Epoch [105/250], Train Loss: 0.1867, Validation Loss: 0.1750
Epoch [106/250], Train Loss: 0.1341, Validation Loss: 0.1633
Epoch [107/250], Train Loss: 0.1734, Validation Loss: 0.1502
Epoch [108/250], Train Loss: 0.1307, Validation Loss: 0.1515
Epoch [109/250], Train Loss: 0.1579, Validation Loss: 0.1703
Epoch [110/250], Train Loss: 0.1655, Validation Loss: 0.1623
Epoch [111/250], Train Loss: 0.1529, Validation Loss: 0.1454
Epoch [112/250], Train Loss: 0.1696, Validation Loss: 0.1587
Epoch [113/250], Train Loss: 0.1527, Validation Loss: 0.1465
Epoch [114/250], Train Loss: 0.1375, Validation Loss: 0.1531
Epoch [115/250], Train Loss: 0.1393, Validation Loss: 0.1566
Epoch [116/250], Train Loss: 0.1538, Validation Loss: 0.1724
Epoch [117/250], Train Loss: 0.1398, Validation Loss: 0.1597
Epoch [118/250], Train Loss: 0.1863, Validation Loss: 0.1620
Epoch [119/250], Train Loss: 0.1865, Validation Loss: 0.1974
Epoch [120/250], Train Loss: 0.1604, Validation Loss: 0.1719
Epoch [121/250], Train Loss: 0.1743, Validation Loss: 0.1516
Epoch [122/250], Train Loss: 0.1715, Validation Loss: 0.1830
Epoch [123/250], Train Loss: 0.1597, Validation Loss: 0.1561
Epoch [124/250], Train Loss: 0.1651, Validation Loss: 0.2436
Epoch [125/250], Train Loss: 0.1933, Validation Loss: 0.1797
Epoch [126/250], Train Loss: 0.1806, Validation Loss: 0.1793
Epoch [127/250], Train Loss: 0.1706, Validation Loss: 0.1716
Epoch [128/250], Train Loss: 0.1624, Validation Loss: 0.1543
Epoch [129/250], Train Loss: 0.1597, Validation Loss: 0.1582
Epoch [130/250], Train Loss: 0.1510, Validation Loss: 0.1544
Epoch [131/250], Train Loss: 0.1394, Validation Loss: 0.1615
Epoch [132/250], Train Loss: 0.1514, Validation Loss: 0.1574
Epoch [133/250], Train Loss: 0.1564, Validation Loss: 0.1389
Epoch [134/250], Train Loss: 0.1617, Validation Loss: 0.1522
Epoch [135/250], Train Loss: 0.1599, Validation Loss: 0.1546
Epoch [136/250], Train Loss: 0.1311, Validation Loss: 0.1335
Epoch [137/250], Train Loss: 0.1365, Validation Loss: 0.1367
Epoch [138/250], Train Loss: 0.1471, Validation Loss: 0.1404
Epoch [139/250], Train Loss: 0.1567, Validation Loss: 0.1419
Epoch [140/250], Train Loss: 0.1422, Validation Loss: 0.1300
Epoch [141/250], Train Loss: 0.1412, Validation Loss: 0.1161
Epoch [142/250], Train Loss: 0.1407, Validation Loss: 0.1709
Epoch [143/250], Train Loss: 0.1491, Validation Loss: 0.1503
Epoch [144/250], Train Loss: 0.1471, Validation Loss: 0.1676
Epoch [145/250], Train Loss: 0.1471, Validation Loss: 0.1412
Epoch [146/250], Train Loss: 0.1485, Validation Loss: 0.1498
Epoch [147/250], Train Loss: 0.1296, Validation Loss: 0.1427
Epoch [148/250], Train Loss: 0.1436, Validation Loss: 0.1675
Epoch [149/250], Train Loss: 0.1581, Validation Loss: 0.1451
Epoch [150/250], Train Loss: 0.1046, Validation Loss: 0.1643
Epoch [151/250], Train Loss: 0.1312, Validation Loss: 0.1444
Epoch [152/250], Train Loss: 0.1279, Validation Loss: 0.1702
Epoch [153/250], Train Loss: 0.1562, Validation Loss: 0.1448
Epoch [154/250], Train Loss: 0.1464, Validation Loss: 0.1387
Epoch [155/250], Train Loss: 0.1312, Validation Loss: 0.1477
Epoch [156/250], Train Loss: 0.1167, Validation Loss: 0.1399
Epoch [157/250], Train Loss: 0.1384, Validation Loss: 0.1247
Epoch [158/250], Train Loss: 0.1472, Validation Loss: 0.1410
Epoch [159/250], Train Loss: 0.1144, Validation Loss: 0.1180
Epoch [160/250], Train Loss: 0.1204, Validation Loss: 0.1390
Epoch [161/250], Train Loss: 0.1379, Validation Loss: 0.1405
Epoch [162/250], Train Loss: 0.1461, Validation Loss: 0.1530
Epoch [163/250], Train Loss: 0.1528, Validation Loss: 0.1589
Epoch [164/250], Train Loss: 0.1665, Validation Loss: 0.1350
Epoch [165/250], Train Loss: 0.1434, Validation Loss: 0.1590
Epoch [166/250], Train Loss: 0.1575, Validation Loss: 0.1327
Epoch [167/250], Train Loss: 0.1548, Validation Loss: 0.1536
Epoch [168/250], Train Loss: 0.1306, Validation Loss: 0.1807
Epoch [169/250], Train Loss: 0.1792, Validation Loss: 0.1319
Epoch [170/250], Train Loss: 0.1293, Validation Loss: 0.1561
Epoch [171/250], Train Loss: 0.1417, Validation Loss: 0.1343
Epoch [172/250], Train Loss: 0.1274, Validation Loss: 0.1404
Epoch [173/250], Train Loss: 0.1261, Validation Loss: 0.1491
Epoch [174/250], Train Loss: 0.1291, Validation Loss: 0.1447
Epoch [175/250], Train Loss: 0.1263, Validation Loss: 0.1536
Epoch [176/250], Train Loss: 0.1336, Validation Loss: 0.1324
Epoch [177/250], Train Loss: 0.1330, Validation Loss: 0.1521
Epoch [178/250], Train Loss: 0.1359, Validation Loss: 0.1328
Epoch [179/250], Train Loss: 0.1484, Validation Loss: 0.1166
Epoch [180/250], Train Loss: 0.1392, Validation Loss: 0.1638
Epoch [181/250], Train Loss: 0.1273, Validation Loss: 0.1470
Epoch [182/250], Train Loss: 0.1357, Validation Loss: 0.1435
Epoch [183/250], Train Loss: 0.1184, Validation Loss: 0.1373
Epoch [184/250], Train Loss: 0.1487, Validation Loss: 0.1498
Epoch [185/250], Train Loss: 0.1320, Validation Loss: 0.1523
Epoch [186/250], Train Loss: 0.1440, Validation Loss: 0.1441
Epoch [187/250], Train Loss: 0.1218, Validation Loss: 0.1511
Epoch [188/250], Train Loss: 0.1371, Validation Loss: 0.1361
Epoch [189/250], Train Loss: 0.1284, Validation Loss: 0.1327
Epoch [190/250], Train Loss: 0.1387, Validation Loss: 0.1349
Epoch [191/250], Train Loss: 0.1419, Validation Loss: 0.1235
Epoch [192/250], Train Loss: 0.1269, Validation Loss: 0.1697
Epoch [193/250], Train Loss: 0.1463, Validation Loss: 0.1313
Epoch [194/250], Train Loss: 0.1329, Validation Loss: 0.1588
Epoch [195/250], Train Loss: 0.1353, Validation Loss: 0.1577
Epoch [196/250], Train Loss: 0.1241, Validation Loss: 0.1419
Epoch [197/250], Train Loss: 0.1229, Validation Loss: 0.1544
Epoch [198/250], Train Loss: 0.1262, Validation Loss: 0.1489
Epoch [199/250], Train Loss: 0.1190, Validation Loss: 0.1688
Epoch [200/250], Train Loss: 0.1490, Validation Loss: 0.1491
Epoch [201/250], Train Loss: 0.1134, Validation Loss: 0.1481
Epoch [202/250], Train Loss: 0.1419, Validation Loss: 0.1347
Epoch [203/250], Train Loss: 0.1442, Validation Loss: 0.1494
Epoch [204/250], Train Loss: 0.1288, Validation Loss: 0.1545
Epoch [205/250], Train Loss: 0.1349, Validation Loss: 0.1446
Epoch [206/250], Train Loss: 0.1299, Validation Loss: 0.1598
Epoch [207/250], Train Loss: 0.1527, Validation Loss: 0.1264
Epoch [208/250], Train Loss: 0.1245, Validation Loss: 0.1355
Epoch [209/250], Train Loss: 0.1155, Validation Loss: 0.1336
Epoch [210/250], Train Loss: 0.1361, Validation Loss: 0.1293
Epoch [211/250], Train Loss: 0.1183, Validation Loss: 0.1328
Epoch [212/250], Train Loss: 0.1120, Validation Loss: 0.1351
Epoch [213/250], Train Loss: 0.1019, Validation Loss: 0.1376
Epoch [214/250], Train Loss: 0.1145, Validation Loss: 0.1204
Epoch [215/250], Train Loss: 0.1212, Validation Loss: 0.1447
Epoch [216/250], Train Loss: 0.1174, Validation Loss: 0.1452
Epoch [217/250], Train Loss: 0.1353, Validation Loss: 0.1347
Epoch [218/250], Train Loss: 0.1237, Validation Loss: 0.1363
Epoch [219/250], Train Loss: 0.1201, Validation Loss: 0.1540
Epoch [220/250], Train Loss: 0.1315, Validation Loss: 0.1420
Epoch [221/250], Train Loss: 0.1046, Validation Loss: 0.1407
Epoch [222/250], Train Loss: 0.1107, Validation Loss: 0.1400
Epoch [223/250], Train Loss: 0.1370, Validation Loss: 0.1389
Epoch [224/250], Train Loss: 0.1622, Validation Loss: 0.1319
Epoch [225/250], Train Loss: 0.1160, Validation Loss: 0.1373
Epoch [226/250], Train Loss: 0.1431, Validation Loss: 0.1405
Epoch [227/250], Train Loss: 0.1154, Validation Loss: 0.1292
Epoch [228/250], Train Loss: 0.1199, Validation Loss: 0.1331
Epoch [229/250], Train Loss: 0.1296, Validation Loss: 0.1333
Epoch [230/250], Train Loss: 0.1239, Validation Loss: 0.1284
Epoch [231/250], Train Loss: 0.1123, Validation Loss: 0.1452
Epoch [232/250], Train Loss: 0.1113, Validation Loss: 0.1183
Epoch [233/250], Train Loss: 0.1122, Validation Loss: 0.1239
Epoch [234/250], Train Loss: 0.1261, Validation Loss: 0.1256
Epoch [235/250], Train Loss: 0.1113, Validation Loss: 0.1304
Epoch [236/250], Train Loss: 0.1477, Validation Loss: 0.1382
Epoch [237/250], Train Loss: 0.1378, Validation Loss: 0.1826
Epoch [238/250], Train Loss: 0.1383, Validation Loss: 0.1165
Epoch [239/250], Train Loss: 0.1316, Validation Loss: 0.1317
Epoch [240/250], Train Loss: 0.1177, Validation Loss: 0.1272
Epoch [241/250], Train Loss: 0.1259, Validation Loss: 0.1120
Epoch [242/250], Train Loss: 0.1316, Validation Loss: 0.1371
Epoch [243/250], Train Loss: 0.1285, Validation Loss: 0.1227
Epoch [244/250], Train Loss: 0.1131, Validation Loss: 0.1292
Epoch [245/250], Train Loss: 0.1482, Validation Loss: 0.1183
Epoch [246/250], Train Loss: 0.1280, Validation Loss: 0.1397
Epoch [247/250], Train Loss: 0.1039, Validation Loss: 0.1191
Epoch [248/250], Train Loss: 0.1265, Validation Loss: 0.1059
Epoch [249/250], Train Loss: 0.1090, Validation Loss: 0.1280
Epoch [250/250], Train Loss: 0.1120, Validation Loss: 0.1123

Finished Training in 77.1

Noise Sigma:  2.0
Creating datasets...
Start training...
Epoch [1/250], Train Loss: 0.1999, Validation Loss: 0.3399
Epoch [2/250], Train Loss: 0.2774, Validation Loss: 0.2429
Epoch [3/250], Train Loss: 0.2598, Validation Loss: 0.1854
Epoch [4/250], Train Loss: 0.1846, Validation Loss: 0.2318
Epoch [5/250], Train Loss: 0.2190, Validation Loss: 0.1756
Epoch [6/250], Train Loss: 0.2425, Validation Loss: 0.1723
Epoch [7/250], Train Loss: 0.2284, Validation Loss: 0.2255
Epoch [8/250], Train Loss: 0.1762, Validation Loss: 0.1970
Epoch [9/250], Train Loss: 0.2012, Validation Loss: 0.1722
Epoch [10/250], Train Loss: 0.1672, Validation Loss: 0.2152
Epoch [11/250], Train Loss: 0.1843, Validation Loss: 0.1878
Epoch [12/250], Train Loss: 0.1946, Validation Loss: 0.2000
Epoch [13/250], Train Loss: 0.1795, Validation Loss: 0.1759
Epoch [14/250], Train Loss: 0.1716, Validation Loss: 0.2021
Epoch [15/250], Train Loss: 0.1455, Validation Loss: 0.1880
Epoch [16/250], Train Loss: 0.1699, Validation Loss: 0.1729
Epoch [17/250], Train Loss: 0.1530, Validation Loss: 0.1730
Epoch [18/250], Train Loss: 0.1554, Validation Loss: 0.1624
Epoch [19/250], Train Loss: 0.1628, Validation Loss: 0.1615
Epoch [20/250], Train Loss: 0.1432, Validation Loss: 0.1570
Epoch [21/250], Train Loss: 0.1546, Validation Loss: 0.1649
Epoch [22/250], Train Loss: 0.1570, Validation Loss: 0.1724
Epoch [23/250], Train Loss: 0.1501, Validation Loss: 0.1683
Epoch [24/250], Train Loss: 0.1472, Validation Loss: 0.1526
Epoch [25/250], Train Loss: 0.1528, Validation Loss: 0.1668
Epoch [26/250], Train Loss: 0.1483, Validation Loss: 0.1792
Epoch [27/250], Train Loss: 0.1273, Validation Loss: 0.1798
Epoch [28/250], Train Loss: 0.1505, Validation Loss: 0.1676
Epoch [29/250], Train Loss: 0.1845, Validation Loss: 0.1528
Epoch [30/250], Train Loss: 0.1786, Validation Loss: 0.1713
Epoch [31/250], Train Loss: 0.1610, Validation Loss: 0.1690
Epoch [32/250], Train Loss: 0.1506, Validation Loss: 0.1787
Epoch [33/250], Train Loss: 0.1464, Validation Loss: 0.1435
Epoch [34/250], Train Loss: 0.1458, Validation Loss: 0.1746
Epoch [35/250], Train Loss: 0.1390, Validation Loss: 0.1515
Epoch [36/250], Train Loss: 0.1531, Validation Loss: 0.1778
Epoch [37/250], Train Loss: 0.1693, Validation Loss: 0.1736
Epoch [38/250], Train Loss: 0.1575, Validation Loss: 0.1979
Epoch [39/250], Train Loss: 0.1717, Validation Loss: 0.1758
Epoch [40/250], Train Loss: 0.1807, Validation Loss: 0.1641
Epoch [41/250], Train Loss: 0.1423, Validation Loss: 0.1723
Epoch [42/250], Train Loss: 0.1635, Validation Loss: 0.1924
Epoch [43/250], Train Loss: 0.1560, Validation Loss: 0.1787
Epoch [44/250], Train Loss: 0.1523, Validation Loss: 0.1632
Epoch [45/250], Train Loss: 0.1636, Validation Loss: 0.1577
Epoch [46/250], Train Loss: 0.1435, Validation Loss: 0.1352
Epoch [47/250], Train Loss: 0.1582, Validation Loss: 0.1332
Epoch [48/250], Train Loss: 0.1363, Validation Loss: 0.1495
Epoch [49/250], Train Loss: 0.1340, Validation Loss: 0.1453
Epoch [50/250], Train Loss: 0.1522, Validation Loss: 0.1899
Epoch [51/250], Train Loss: 0.1667, Validation Loss: 0.1431
Epoch [52/250], Train Loss: 0.1458, Validation Loss: 0.1730
Epoch [53/250], Train Loss: 0.1332, Validation Loss: 0.1680
Epoch [54/250], Train Loss: 0.1494, Validation Loss: 0.1636
Epoch [55/250], Train Loss: 0.1290, Validation Loss: 0.1367
Epoch [56/250], Train Loss: 0.1487, Validation Loss: 0.1599
Epoch [57/250], Train Loss: 0.1399, Validation Loss: 0.1553
Epoch [58/250], Train Loss: 0.1555, Validation Loss: 0.1481
Epoch [59/250], Train Loss: 0.1588, Validation Loss: 0.1761
Epoch [60/250], Train Loss: 0.1437, Validation Loss: 0.1798
Epoch [61/250], Train Loss: 0.1491, Validation Loss: 0.1713
Epoch [62/250], Train Loss: 0.1382, Validation Loss: 0.1418
Epoch [63/250], Train Loss: 0.1427, Validation Loss: 0.1378
Epoch [64/250], Train Loss: 0.1352, Validation Loss: 0.1336
Epoch [65/250], Train Loss: 0.1383, Validation Loss: 0.1497
Epoch [66/250], Train Loss: 0.1459, Validation Loss: 0.1481
Epoch [67/250], Train Loss: 0.1358, Validation Loss: 0.1474
Epoch [68/250], Train Loss: 0.1583, Validation Loss: 0.1554
Epoch [69/250], Train Loss: 0.1433, Validation Loss: 0.1438
Epoch [70/250], Train Loss: 0.1362, Validation Loss: 0.1474
Epoch [71/250], Train Loss: 0.1301, Validation Loss: 0.1628
Epoch [72/250], Train Loss: 0.1336, Validation Loss: 0.1926
Epoch [73/250], Train Loss: 0.1707, Validation Loss: 0.1550
Epoch [74/250], Train Loss: 0.1464, Validation Loss: 0.1516
Epoch [75/250], Train Loss: 0.1589, Validation Loss: 0.1399
Epoch [76/250], Train Loss: 0.1523, Validation Loss: 0.1698
Epoch [77/250], Train Loss: 0.1428, Validation Loss: 0.1651
Epoch [78/250], Train Loss: 0.1275, Validation Loss: 0.1729
Epoch [79/250], Train Loss: 0.2006, Validation Loss: 0.1578
Epoch [80/250], Train Loss: 0.1461, Validation Loss: 0.1765
Epoch [81/250], Train Loss: 0.1738, Validation Loss: 0.1823
Epoch [82/250], Train Loss: 0.1959, Validation Loss: 0.1706
Epoch [83/250], Train Loss: 0.1490, Validation Loss: 0.1658
Epoch [84/250], Train Loss: 0.1496, Validation Loss: 0.1726
Epoch [85/250], Train Loss: 0.1462, Validation Loss: 0.1490
Epoch [86/250], Train Loss: 0.1579, Validation Loss: 0.1444
Epoch [87/250], Train Loss: 0.1424, Validation Loss: 0.1651
Epoch [88/250], Train Loss: 0.1295, Validation Loss: 0.1483
Epoch [89/250], Train Loss: 0.1252, Validation Loss: 0.1435
Epoch [90/250], Train Loss: 0.1395, Validation Loss: 0.1653
Epoch [91/250], Train Loss: 0.1391, Validation Loss: 0.1549
Epoch [92/250], Train Loss: 0.1283, Validation Loss: 0.1690
Epoch [93/250], Train Loss: 0.1327, Validation Loss: 0.1782
Epoch [94/250], Train Loss: 0.1344, Validation Loss: 0.1673
Epoch [95/250], Train Loss: 0.1111, Validation Loss: 0.1363
Epoch [96/250], Train Loss: 0.1348, Validation Loss: 0.1572
Epoch [97/250], Train Loss: 0.1394, Validation Loss: 0.1382
Epoch [98/250], Train Loss: 0.1392, Validation Loss: 0.1456
Epoch [99/250], Train Loss: 0.1234, Validation Loss: 0.1452
Epoch [100/250], Train Loss: 0.1198, Validation Loss: 0.1566
Epoch [101/250], Train Loss: 0.1520, Validation Loss: 0.1199
Epoch [102/250], Train Loss: 0.1342, Validation Loss: 0.1668
Epoch [103/250], Train Loss: 0.1602, Validation Loss: 0.1426
Epoch [104/250], Train Loss: 0.1582, Validation Loss: 0.1402
Epoch [105/250], Train Loss: 0.1419, Validation Loss: 0.1671
Epoch [106/250], Train Loss: 0.1471, Validation Loss: 0.1338
Epoch [107/250], Train Loss: 0.1504, Validation Loss: 0.1343
Epoch [108/250], Train Loss: 0.1245, Validation Loss: 0.1609
Epoch [109/250], Train Loss: 0.1360, Validation Loss: 0.1674
Epoch [110/250], Train Loss: 0.1367, Validation Loss: 0.1510
Epoch [111/250], Train Loss: 0.1276, Validation Loss: 0.1602
Epoch [112/250], Train Loss: 0.1359, Validation Loss: 0.1509
Epoch [113/250], Train Loss: 0.1473, Validation Loss: 0.1464
Epoch [114/250], Train Loss: 0.1426, Validation Loss: 0.1207
Epoch [115/250], Train Loss: 0.1550, Validation Loss: 0.1508
Epoch [116/250], Train Loss: 0.1358, Validation Loss: 0.1525
Epoch [117/250], Train Loss: 0.1203, Validation Loss: 0.1478
Epoch [118/250], Train Loss: 0.1199, Validation Loss: 0.1555
Epoch [119/250], Train Loss: 0.1407, Validation Loss: 0.1426
Epoch [120/250], Train Loss: 0.1416, Validation Loss: 0.1648
Epoch [121/250], Train Loss: 0.1291, Validation Loss: 0.1660
Epoch [122/250], Train Loss: 0.1550, Validation Loss: 0.1423
Epoch [123/250], Train Loss: 0.1437, Validation Loss: 0.1341
Epoch [124/250], Train Loss: 0.1692, Validation Loss: 0.1432
Epoch [125/250], Train Loss: 0.1376, Validation Loss: 0.1679
Epoch [126/250], Train Loss: 0.1438, Validation Loss: 0.1522
Epoch [127/250], Train Loss: 0.1581, Validation Loss: 0.1253
Epoch [128/250], Train Loss: 0.1369, Validation Loss: 0.1364
Epoch [129/250], Train Loss: 0.1254, Validation Loss: 0.1324
Epoch [130/250], Train Loss: 0.1220, Validation Loss: 0.1658
Epoch [131/250], Train Loss: 0.1362, Validation Loss: 0.1399
Epoch [132/250], Train Loss: 0.1394, Validation Loss: 0.1422
Epoch [133/250], Train Loss: 0.1164, Validation Loss: 0.1526
Epoch [134/250], Train Loss: 0.1342, Validation Loss: 0.1691
Epoch [135/250], Train Loss: 0.1378, Validation Loss: 0.1557
Epoch [136/250], Train Loss: 0.1341, Validation Loss: 0.1565
Epoch [137/250], Train Loss: 0.1227, Validation Loss: 0.1381
Epoch [138/250], Train Loss: 0.1289, Validation Loss: 0.1347
Epoch [139/250], Train Loss: 0.1692, Validation Loss: 0.1577
Epoch [140/250], Train Loss: 0.1284, Validation Loss: 0.1280
Epoch [141/250], Train Loss: 0.1300, Validation Loss: 0.1449
Epoch [142/250], Train Loss: 0.1419, Validation Loss: 0.1344
Epoch [143/250], Train Loss: 0.1371, Validation Loss: 0.1567
Epoch [144/250], Train Loss: 0.1392, Validation Loss: 0.1366
Epoch [145/250], Train Loss: 0.1342, Validation Loss: 0.1266
Epoch [146/250], Train Loss: 0.1297, Validation Loss: 0.1569
Epoch [147/250], Train Loss: 0.1248, Validation Loss: 0.1403
Epoch [148/250], Train Loss: 0.1266, Validation Loss: 0.1402
Epoch [149/250], Train Loss: 0.1275, Validation Loss: 0.1302
Epoch [150/250], Train Loss: 0.1214, Validation Loss: 0.1448
Epoch [151/250], Train Loss: 0.1388, Validation Loss: 0.1693
Epoch [152/250], Train Loss: 0.1135, Validation Loss: 0.1700
Epoch [153/250], Train Loss: 0.1444, Validation Loss: 0.1547
Epoch [154/250], Train Loss: 0.1407, Validation Loss: 0.1424
Epoch [155/250], Train Loss: 0.1104, Validation Loss: 0.1398
Epoch [156/250], Train Loss: 0.1410, Validation Loss: 0.1344
Epoch [157/250], Train Loss: 0.1315, Validation Loss: 0.1387
Epoch [158/250], Train Loss: 0.1331, Validation Loss: 0.1363
Epoch [159/250], Train Loss: 0.1147, Validation Loss: 0.1414
Epoch [160/250], Train Loss: 0.1382, Validation Loss: 0.1535
Epoch [161/250], Train Loss: 0.1339, Validation Loss: 0.1549
Epoch [162/250], Train Loss: 0.1281, Validation Loss: 0.1331
Epoch [163/250], Train Loss: 0.1220, Validation Loss: 0.1459
Epoch [164/250], Train Loss: 0.1294, Validation Loss: 0.1456
Epoch [165/250], Train Loss: 0.1479, Validation Loss: 0.1492
Epoch [166/250], Train Loss: 0.1280, Validation Loss: 0.1330
Epoch [167/250], Train Loss: 0.1183, Validation Loss: 0.1412
Epoch [168/250], Train Loss: 0.1177, Validation Loss: 0.1519
Epoch [169/250], Train Loss: 0.1145, Validation Loss: 0.1428
Epoch [170/250], Train Loss: 0.1464, Validation Loss: 0.1507
Epoch [171/250], Train Loss: 0.1313, Validation Loss: 0.1568
Epoch [172/250], Train Loss: 0.1459, Validation Loss: 0.1618
Epoch [173/250], Train Loss: 0.1200, Validation Loss: 0.1617
Epoch [174/250], Train Loss: 0.1456, Validation Loss: 0.1474
Epoch [175/250], Train Loss: 0.1351, Validation Loss: 0.1268
Epoch [176/250], Train Loss: 0.1292, Validation Loss: 0.1395
Epoch [177/250], Train Loss: 0.1456, Validation Loss: 0.1174
Epoch [178/250], Train Loss: 0.1161, Validation Loss: 0.1304
Epoch [179/250], Train Loss: 0.1222, Validation Loss: 0.1276
Epoch [180/250], Train Loss: 0.1248, Validation Loss: 0.1376
Epoch [181/250], Train Loss: 0.1164, Validation Loss: 0.1363
Epoch [182/250], Train Loss: 0.1195, Validation Loss: 0.1308
Epoch [183/250], Train Loss: 0.1248, Validation Loss: 0.1469
Epoch [184/250], Train Loss: 0.1211, Validation Loss: 0.1279
Epoch [185/250], Train Loss: 0.1166, Validation Loss: 0.1355
Epoch [186/250], Train Loss: 0.1198, Validation Loss: 0.1553
Epoch [187/250], Train Loss: 0.1323, Validation Loss: 0.1343
Epoch [188/250], Train Loss: 0.1397, Validation Loss: 0.1678
Epoch [189/250], Train Loss: 0.1116, Validation Loss: 0.1511
Epoch [190/250], Train Loss: 0.1256, Validation Loss: 0.1396
Epoch [191/250], Train Loss: 0.1364, Validation Loss: 0.1287
Epoch [192/250], Train Loss: 0.1283, Validation Loss: 0.1440
Epoch [193/250], Train Loss: 0.1336, Validation Loss: 0.1582
Epoch [194/250], Train Loss: 0.1564, Validation Loss: 0.1326
Epoch [195/250], Train Loss: 0.1331, Validation Loss: 0.1192
Epoch [196/250], Train Loss: 0.1124, Validation Loss: 0.1395
Epoch [197/250], Train Loss: 0.1172, Validation Loss: 0.1287
Epoch [198/250], Train Loss: 0.1247, Validation Loss: 0.1395
Epoch [199/250], Train Loss: 0.1267, Validation Loss: 0.1553
Epoch [200/250], Train Loss: 0.1577, Validation Loss: 0.1595
Epoch [201/250], Train Loss: 0.1237, Validation Loss: 0.1426
Epoch [202/250], Train Loss: 0.1482, Validation Loss: 0.1381
Epoch [203/250], Train Loss: 0.1342, Validation Loss: 0.1404
Epoch [204/250], Train Loss: 0.1280, Validation Loss: 0.1370
Epoch [205/250], Train Loss: 0.1055, Validation Loss: 0.1525
Epoch [206/250], Train Loss: 0.1216, Validation Loss: 0.1449
Epoch [207/250], Train Loss: 0.1288, Validation Loss: 0.1267
Epoch [208/250], Train Loss: 0.1090, Validation Loss: 0.1326
Epoch [209/250], Train Loss: 0.1292, Validation Loss: 0.1299
Epoch [210/250], Train Loss: 0.1098, Validation Loss: 0.1247
Epoch [211/250], Train Loss: 0.1143, Validation Loss: 0.1607
Epoch [212/250], Train Loss: 0.1132, Validation Loss: 0.1553
Epoch [213/250], Train Loss: 0.1151, Validation Loss: 0.1375
Epoch [214/250], Train Loss: 0.1359, Validation Loss: 0.1635
Epoch [215/250], Train Loss: 0.1329, Validation Loss: 0.1648
Epoch [216/250], Train Loss: 0.1294, Validation Loss: 0.1727
Epoch [217/250], Train Loss: 0.1345, Validation Loss: 0.1434
Epoch [218/250], Train Loss: 0.1272, Validation Loss: 0.1619
Epoch [219/250], Train Loss: 0.1339, Validation Loss: 0.1492
Epoch [220/250], Train Loss: 0.1250, Validation Loss: 0.1507
Epoch [221/250], Train Loss: 0.1261, Validation Loss: 0.1344
Epoch [222/250], Train Loss: 0.1285, Validation Loss: 0.1371
Epoch [223/250], Train Loss: 0.1411, Validation Loss: 0.1415
Epoch [224/250], Train Loss: 0.1405, Validation Loss: 0.1377
Epoch [225/250], Train Loss: 0.1237, Validation Loss: 0.1328
Epoch [226/250], Train Loss: 0.1275, Validation Loss: 0.1168
Epoch [227/250], Train Loss: 0.1176, Validation Loss: 0.1324
Epoch [228/250], Train Loss: 0.1208, Validation Loss: 0.1494
Epoch [229/250], Train Loss: 0.1374, Validation Loss: 0.1317
Epoch [230/250], Train Loss: 0.1219, Validation Loss: 0.1278
Epoch [231/250], Train Loss: 0.1485, Validation Loss: 0.1339
Epoch [232/250], Train Loss: 0.1110, Validation Loss: 0.1462
Epoch [233/250], Train Loss: 0.1058, Validation Loss: 0.1301
Epoch [234/250], Train Loss: 0.1109, Validation Loss: 0.1381
Epoch [235/250], Train Loss: 0.1221, Validation Loss: 0.1205
Epoch [236/250], Train Loss: 0.1036, Validation Loss: 0.1320
Epoch [237/250], Train Loss: 0.1158, Validation Loss: 0.1375
Epoch [238/250], Train Loss: 0.1275, Validation Loss: 0.1481
Epoch [239/250], Train Loss: 0.1146, Validation Loss: 0.1306
Epoch [240/250], Train Loss: 0.1385, Validation Loss: 0.1588
Epoch [241/250], Train Loss: 0.1304, Validation Loss: 0.1414
Epoch [242/250], Train Loss: 0.1021, Validation Loss: 0.1269
Epoch [243/250], Train Loss: 0.1094, Validation Loss: 0.1134
Epoch [244/250], Train Loss: 0.1031, Validation Loss: 0.1292
Epoch [245/250], Train Loss: 0.1107, Validation Loss: 0.1526
Epoch [246/250], Train Loss: 0.1268, Validation Loss: 0.1475
Epoch [247/250], Train Loss: 0.1345, Validation Loss: 0.1309
Epoch [248/250], Train Loss: 0.1199, Validation Loss: 0.1253
Epoch [249/250], Train Loss: 0.1058, Validation Loss: 0.1193
Epoch [250/250], Train Loss: 0.1032, Validation Loss: 0.1316

Finished Training in 76.9

Saving model parameters...
done
