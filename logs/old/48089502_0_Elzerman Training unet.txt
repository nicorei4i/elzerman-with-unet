GPU available:  True
GPU available:  True
cuda
(10000, 8192)
(100, 8192)
(10000, 8192)
noise sigs:  [0.1  0.25 0.4  0.55 0.7 ]
Noise Sigma:  0.1
Creating datasets...
20086
Start training...
train:  13.10475468635559
val:  0.9681813716888428
Epoch [1/25], Train Loss: 0.1461, Validation Loss: 0.0408, lr = 0.01, duration = 14.072990417480469
train:  11.425810813903809
val:  0.14629483222961426
Epoch [2/25], Train Loss: 0.0266, Validation Loss: 0.0169, lr = 0.00964, duration = 11.572144746780396
train:  11.335370779037476
val:  0.14640140533447266
Epoch [3/25], Train Loss: 0.0131, Validation Loss: 0.0098, lr = 0.00928, duration = 11.482269287109375
train:  11.363525867462158
val:  0.14603042602539062
Epoch [4/25], Train Loss: 0.0082, Validation Loss: 0.0066, lr = 0.008919999999999999, duration = 11.509596347808838
train:  11.458484649658203
val:  0.14617681503295898
Epoch [5/25], Train Loss: 0.0058, Validation Loss: 0.0049, lr = 0.00856, duration = 11.604700565338135
train:  11.506396293640137
val:  0.15291309356689453
Epoch [6/25], Train Loss: 0.0044, Validation Loss: 0.0038, lr = 0.008199999999999999, duration = 11.659351825714111
train:  11.623040199279785
val:  0.15957069396972656
Epoch [7/25], Train Loss: 0.0035, Validation Loss: 0.0030, lr = 0.007839999999999998, duration = 11.782650470733643
train:  11.53758955001831
val:  0.1518712043762207
Epoch [8/25], Train Loss: 0.0028, Validation Loss: 0.0025, lr = 0.007479999999999998, duration = 11.689504146575928
train:  11.312667846679688
val:  0.1457209587097168
Epoch [9/25], Train Loss: 0.0023, Validation Loss: 0.0021, lr = 0.007119999999999998, duration = 11.458429336547852
train:  11.315388679504395
val:  0.1486656665802002
Epoch [10/25], Train Loss: 0.0020, Validation Loss: 0.0018, lr = 0.006759999999999998, duration = 11.464101076126099
train:  11.312024116516113
val:  0.14746737480163574
Epoch [11/25], Train Loss: 0.0017, Validation Loss: 0.0015, lr = 0.006399999999999998, duration = 11.459538221359253
train:  11.359533071517944
val:  0.14669227600097656
Epoch [12/25], Train Loss: 0.0015, Validation Loss: 0.0013, lr = 0.006039999999999998, duration = 11.506270408630371
train:  11.357271671295166
val:  0.14740252494812012
Epoch [13/25], Train Loss: 0.0013, Validation Loss: 0.0012, lr = 0.0056799999999999976, duration = 11.504721879959106
train:  11.312444925308228
val:  0.14624786376953125
Epoch [14/25], Train Loss: 0.0011, Validation Loss: 0.0010, lr = 0.0053199999999999975, duration = 11.458735942840576
train:  11.330157279968262
val:  0.1494135856628418
Epoch [15/25], Train Loss: 0.0010, Validation Loss: 0.0009, lr = 0.004959999999999997, duration = 11.479614019393921
train:  11.298595666885376
val:  0.15623927116394043
Epoch [16/25], Train Loss: 0.0009, Validation Loss: 0.0008, lr = 0.004599999999999997, duration = 11.45487904548645
train:  11.334934949874878
val:  0.14612245559692383
Epoch [17/25], Train Loss: 0.0008, Validation Loss: 0.0007, lr = 0.004239999999999997, duration = 11.481101036071777
train:  11.345272064208984
val:  0.14788103103637695
Epoch [18/25], Train Loss: 0.0007, Validation Loss: 0.0006, lr = 0.0038799999999999976, duration = 11.493197917938232
train:  11.319030523300171
val:  0.14663457870483398
Epoch [19/25], Train Loss: 0.0006, Validation Loss: 0.0006, lr = 0.003519999999999998, duration = 11.465708017349243
train:  11.33103322982788
val:  0.14685320854187012
Epoch [20/25], Train Loss: 0.0006, Validation Loss: 0.0005, lr = 0.003159999999999998, duration = 11.47792935371399
train:  11.342725992202759
val:  0.14674782752990723
Epoch [21/25], Train Loss: 0.0005, Validation Loss: 0.0005, lr = 0.002799999999999998, duration = 11.48951530456543
train:  11.33255386352539
val:  0.14904189109802246
Epoch [22/25], Train Loss: 0.0005, Validation Loss: 0.0004, lr = 0.002439999999999998, duration = 11.481635570526123
train:  11.37637710571289
val:  0.1467115879058838
Epoch [23/25], Train Loss: 0.0004, Validation Loss: 0.0004, lr = 0.0020799999999999985, duration = 11.52313232421875
train:  11.322372198104858
val:  0.14559125900268555
Epoch [24/25], Train Loss: 0.0004, Validation Loss: 0.0004, lr = 0.0017199999999999987, duration = 11.468007326126099
train:  11.338853597640991
val:  0.15820598602294922
Epoch [25/25], Train Loss: 0.0004, Validation Loss: 0.0003, lr = 0.001359999999999999, duration = 11.49710488319397

Finished Training in 11.5

Plotting the results...
snr:  15.132030248641968
score:  (1.0, 0.9990588235294118, array([[4246,    0],
       [   4, 5750]]))
Noise Sigma:  0.25
Creating datasets...
20086
Start training...
train:  13.231812000274658
val:  0.9635457992553711
Epoch [1/25], Train Loss: 0.1484, Validation Loss: 0.0482, lr = 0.01, duration = 14.195415258407593
train:  12.24204969406128
val:  0.15743255615234375
Epoch [2/25], Train Loss: 0.0310, Validation Loss: 0.0196, lr = 0.00964, duration = 12.399524211883545
train:  12.228914022445679
val:  0.15734362602233887
Epoch [3/25], Train Loss: 0.0152, Validation Loss: 0.0115, lr = 0.00928, duration = 12.386302709579468
train:  12.27711534500122
val:  0.1575331687927246
Epoch [4/25], Train Loss: 0.0096, Validation Loss: 0.0079, lr = 0.008919999999999999, duration = 12.434690713882446
train:  12.327622413635254
val:  0.15836191177368164
Epoch [5/25], Train Loss: 0.0077, Validation Loss: 0.0058, lr = 0.00856, duration = 12.486029148101807
train:  12.22727656364441
val:  0.15669536590576172
Epoch [6/25], Train Loss: 0.0055, Validation Loss: 0.0045, lr = 0.008199999999999999, duration = 12.384013414382935
train:  12.183073282241821
val:  0.15667462348937988
Epoch [7/25], Train Loss: 0.0042, Validation Loss: 0.0037, lr = 0.007839999999999998, duration = 12.339794874191284
train:  12.18013882637024
val:  0.15661954879760742
Epoch [8/25], Train Loss: 0.0034, Validation Loss: 0.0031, lr = 0.007479999999999998, duration = 12.336800336837769
train:  12.32115626335144
val:  0.1621713638305664
Epoch [9/25], Train Loss: 0.0030, Validation Loss: 0.0026, lr = 0.007119999999999998, duration = 12.483373880386353
train:  12.320581912994385
val:  0.15851569175720215
Epoch [10/25], Train Loss: 0.0024, Validation Loss: 0.0022, lr = 0.006759999999999998, duration = 12.47913670539856
train:  12.285784482955933
val:  0.158735990524292
Epoch [11/25], Train Loss: 0.0021, Validation Loss: 0.0020, lr = 0.006399999999999998, duration = 12.444561958312988
train:  12.323976039886475
val:  0.15923380851745605
Epoch [12/25], Train Loss: 0.0018, Validation Loss: 0.0017, lr = 0.006039999999999998, duration = 12.483254671096802
train:  12.296293258666992
val:  0.15666532516479492
Epoch [13/25], Train Loss: 0.0016, Validation Loss: 0.0015, lr = 0.0056799999999999976, duration = 12.45300030708313
train:  12.222165584564209
val:  0.15697717666625977
Epoch [14/25], Train Loss: 0.0014, Validation Loss: 0.0013, lr = 0.0053199999999999975, duration = 12.379187107086182
train:  12.190312147140503
val:  0.1597590446472168
Epoch [15/25], Train Loss: 0.0012, Validation Loss: 0.0011, lr = 0.004959999999999997, duration = 12.350113153457642
train:  12.181620121002197
val:  0.16565966606140137
Epoch [16/25], Train Loss: 0.0011, Validation Loss: 0.0010, lr = 0.004599999999999997, duration = 12.34731936454773
train:  12.135761022567749
val:  0.15809249877929688
Epoch [17/25], Train Loss: 0.0010, Validation Loss: 0.0009, lr = 0.004239999999999997, duration = 12.293899774551392
train:  12.205177307128906
val:  0.15877580642700195
Epoch [18/25], Train Loss: 0.0009, Validation Loss: 0.0008, lr = 0.0038799999999999976, duration = 12.363996744155884
train:  12.213489055633545
val:  0.16038990020751953
Epoch [19/25], Train Loss: 0.0008, Validation Loss: 0.0008, lr = 0.003519999999999998, duration = 12.373926401138306
train:  12.257739305496216
val:  0.1573946475982666
Epoch [20/25], Train Loss: 0.0009, Validation Loss: 0.0007, lr = 0.003159999999999998, duration = 12.41517448425293
train:  12.227538585662842
val:  0.16133975982666016
Epoch [21/25], Train Loss: 0.0007, Validation Loss: 0.0007, lr = 0.002799999999999998, duration = 12.38891887664795
train:  12.102925539016724
val:  0.15681099891662598
Epoch [22/25], Train Loss: 0.0006, Validation Loss: 0.0006, lr = 0.002439999999999998, duration = 12.25977873802185
train:  12.151308298110962
val:  0.1599874496459961
Epoch [23/25], Train Loss: 0.0006, Validation Loss: 0.0006, lr = 0.0020799999999999985, duration = 12.311342477798462
train:  12.200129985809326
val:  0.16248273849487305
Epoch [24/25], Train Loss: 0.0005, Validation Loss: 0.0005, lr = 0.0017199999999999987, duration = 12.36266016960144
train:  12.198649406433105
val:  0.15588927268981934
Epoch [25/25], Train Loss: 0.0005, Validation Loss: 0.0005, lr = 0.001359999999999999, duration = 12.354583501815796

Finished Training in 12.4

Plotting the results...
snr:  7.0171815156936646
score:  (0.9995287464655985, 0.9981176470588236, array([[4242,    2],
       [   8, 5748]]))
Noise Sigma:  0.4
Creating datasets...
20086
Start training...
train:  12.934164762496948
val:  0.9247875213623047
Epoch [1/25], Train Loss: 0.3804, Validation Loss: 0.3267, lr = 0.01, duration = 13.859005451202393
train:  12.087649583816528
val:  0.15711164474487305
Epoch [2/25], Train Loss: 0.3187, Validation Loss: 0.3249, lr = 0.00964, duration = 12.244807243347168
train:  12.061211824417114
val:  0.15691399574279785
Epoch [3/25], Train Loss: 0.3187, Validation Loss: 0.3271, lr = 0.00928, duration = 12.218165636062622
train:  12.013744115829468
val:  0.15924358367919922
Epoch [4/25], Train Loss: 0.3172, Validation Loss: 0.3248, lr = 0.008919999999999999, duration = 12.173030138015747
train:  12.015587329864502
val:  0.15958213806152344
Epoch [5/25], Train Loss: 0.3170, Validation Loss: 0.3248, lr = 0.00856, duration = 12.17521047592163
train:  12.044946670532227
val:  0.1559605598449707
Epoch [6/25], Train Loss: 0.3172, Validation Loss: 0.3248, lr = 0.008199999999999999, duration = 12.20094895362854
train:  12.071295022964478
val:  0.15616512298583984
Epoch [7/25], Train Loss: 0.2135, Validation Loss: 0.0326, lr = 0.007839999999999998, duration = 12.22750473022461
train:  12.015151023864746
val:  0.1559300422668457
Epoch [8/25], Train Loss: 0.0181, Validation Loss: 0.0113, lr = 0.007479999999999998, duration = 12.171120882034302
train:  11.998347520828247
val:  0.15624499320983887
Epoch [9/25], Train Loss: 0.0089, Validation Loss: 0.0073, lr = 0.007119999999999998, duration = 12.154637575149536
train:  12.008578062057495
val:  0.15801429748535156
Epoch [10/25], Train Loss: 0.0066, Validation Loss: 0.0053, lr = 0.006759999999999998, duration = 12.166636943817139
train:  12.092490673065186
val:  0.15578889846801758
Epoch [11/25], Train Loss: 0.0049, Validation Loss: 0.0044, lr = 0.006399999999999998, duration = 12.248322248458862
train:  12.13486933708191
val:  0.15740656852722168
Epoch [12/25], Train Loss: 0.0037, Validation Loss: 0.0034, lr = 0.006039999999999998, duration = 12.292320728302002
train:  12.044517040252686
val:  0.15793633460998535
Epoch [13/25], Train Loss: 0.0039, Validation Loss: 0.0034, lr = 0.0056799999999999976, duration = 12.202497959136963
train:  12.020668745040894
val:  0.15691161155700684
Epoch [14/25], Train Loss: 0.0030, Validation Loss: 0.0027, lr = 0.0053199999999999975, duration = 12.177621841430664
train:  12.000262975692749
val:  0.1561722755432129
Epoch [15/25], Train Loss: 0.0034, Validation Loss: 0.0027, lr = 0.004959999999999997, duration = 12.156477212905884
train:  12.056169033050537
val:  0.15616297721862793
Epoch [16/25], Train Loss: 0.0023, Validation Loss: 0.0022, lr = 0.004599999999999997, duration = 12.21237564086914
train:  12.06268310546875
val:  0.16486620903015137
Epoch [17/25], Train Loss: 0.0020, Validation Loss: 0.0019, lr = 0.004239999999999997, duration = 12.227592945098877
train:  12.10696792602539
val:  0.1588430404663086
Epoch [18/25], Train Loss: 0.0018, Validation Loss: 0.0017, lr = 0.0038799999999999976, duration = 12.2658531665802
train:  12.039073467254639
val:  0.16920757293701172
Epoch [19/25], Train Loss: 0.0017, Validation Loss: 0.0017, lr = 0.003519999999999998, duration = 12.208322048187256
train:  12.039412021636963
val:  0.15719127655029297
Epoch [20/25], Train Loss: 0.0016, Validation Loss: 0.0015, lr = 0.003159999999999998, duration = 12.196647882461548
train:  12.087672472000122
val:  0.1559741497039795
Epoch [21/25], Train Loss: 0.0018, Validation Loss: 0.0014, lr = 0.002799999999999998, duration = 12.243688583374023
train:  12.0164315700531
val:  0.1571028232574463
Epoch [22/25], Train Loss: 0.0014, Validation Loss: 0.0013, lr = 0.002439999999999998, duration = 12.173577070236206
train:  12.073137998580933
val:  0.15863037109375
Epoch [23/25], Train Loss: 0.0013, Validation Loss: 0.0012, lr = 0.0020799999999999985, duration = 12.231810331344604
train:  11.982264757156372
val:  0.155989408493042
Epoch [24/25], Train Loss: 0.0012, Validation Loss: 0.0013, lr = 0.0017199999999999987, duration = 12.138297319412231
train:  12.028756380081177
val:  0.15651822090148926
Epoch [25/25], Train Loss: 0.0012, Validation Loss: 0.0012, lr = 0.001359999999999999, duration = 12.185318231582642

Finished Training in 12.2

Plotting the results...
snr:  3.009871542453766
score:  (0.9992897727272727, 0.9931764705882353, array([[4221,    3],
       [  29, 5747]]))
Noise Sigma:  0.5499999999999999
Creating datasets...
20086
Start training...
train:  12.481792449951172
val:  0.9527482986450195
Epoch [1/25], Train Loss: 0.6931, Validation Loss: 0.6931, lr = 0.01, duration = 13.434593200683594
train:  11.521965503692627
val:  0.14957451820373535
Epoch [2/25], Train Loss: 0.6931, Validation Loss: 0.6931, lr = 0.00964, duration = 11.671580076217651
train:  11.526846170425415
val:  0.15029168128967285
Epoch [3/25], Train Loss: 0.6931, Validation Loss: 0.6931, lr = 0.00928, duration = 11.677184104919434
train:  11.48962926864624
val:  0.1498420238494873
Epoch [4/25], Train Loss: 0.6931, Validation Loss: 0.6931, lr = 0.008919999999999999, duration = 11.639516353607178
train:  11.457856893539429
val:  0.16331267356872559
Epoch [5/25], Train Loss: 0.6931, Validation Loss: 0.6931, lr = 0.00856, duration = 11.621213912963867
train:  11.453278541564941
val:  0.14938020706176758
Epoch [6/25], Train Loss: 0.6931, Validation Loss: 0.6931, lr = 0.008199999999999999, duration = 11.602702379226685
train:  11.469231843948364
val:  0.15064692497253418
Epoch [7/25], Train Loss: 0.6931, Validation Loss: 0.6931, lr = 0.007839999999999998, duration = 11.619922399520874
train:  11.506237506866455
val:  0.14975643157958984
Epoch [8/25], Train Loss: 0.6931, Validation Loss: 0.6931, lr = 0.007479999999999998, duration = 11.656034708023071
train:  11.490167379379272
val:  0.15057110786437988
Epoch [9/25], Train Loss: 0.6931, Validation Loss: 0.6931, lr = 0.007119999999999998, duration = 11.640779733657837
train:  11.464028120040894
val:  0.15005230903625488
Epoch [10/25], Train Loss: 0.6931, Validation Loss: 0.6931, lr = 0.006759999999999998, duration = 11.614125490188599
train:  11.486874103546143
val:  0.15108847618103027
Epoch [11/25], Train Loss: 0.6931, Validation Loss: 0.6931, lr = 0.006399999999999998, duration = 11.638007640838623
train:  11.42894434928894
val:  0.150773286819458
Epoch [12/25], Train Loss: 0.6931, Validation Loss: 0.6931, lr = 0.006039999999999998, duration = 11.57976222038269
train:  11.49776315689087
val:  0.151108980178833
Epoch [13/25], Train Loss: 0.6931, Validation Loss: 0.6931, lr = 0.0056799999999999976, duration = 11.648925304412842
train:  11.51743483543396
val:  0.14987921714782715
Epoch [14/25], Train Loss: 0.6931, Validation Loss: 0.6931, lr = 0.0053199999999999975, duration = 11.667356252670288
train:  11.48673963546753
val:  0.15301227569580078
Epoch [15/25], Train Loss: 0.6931, Validation Loss: 0.6931, lr = 0.004959999999999997, duration = 11.639801740646362
train:  11.466782808303833
val:  0.16280627250671387
Epoch [16/25], Train Loss: 0.6931, Validation Loss: 0.6931, lr = 0.004599999999999997, duration = 11.62962794303894
train:  11.437580108642578
val:  0.15093994140625
Epoch [17/25], Train Loss: 0.6931, Validation Loss: 0.6931, lr = 0.004239999999999997, duration = 11.588560581207275
train:  11.452833652496338
val:  0.15051507949829102
Epoch [18/25], Train Loss: 0.6931, Validation Loss: 0.6931, lr = 0.0038799999999999976, duration = 11.603393316268921
train:  11.504140615463257
val:  0.1506662368774414
Epoch [19/25], Train Loss: 0.6931, Validation Loss: 0.6931, lr = 0.003519999999999998, duration = 11.654847621917725
train:  11.434926748275757
val:  0.14962077140808105
Epoch [20/25], Train Loss: 0.6931, Validation Loss: 0.6931, lr = 0.003159999999999998, duration = 11.584587335586548
train:  11.467597961425781
val:  0.15032243728637695
Epoch [21/25], Train Loss: 0.6931, Validation Loss: 0.6931, lr = 0.002799999999999998, duration = 11.61796522140503
train:  11.44844126701355
val:  0.15107393264770508
Epoch [22/25], Train Loss: 0.6931, Validation Loss: 0.6931, lr = 0.002439999999999998, duration = 11.599555492401123
train:  11.45456337928772
val:  0.14958858489990234
Epoch [23/25], Train Loss: 0.6931, Validation Loss: 0.6931, lr = 0.0020799999999999985, duration = 11.60419249534607
train:  11.476508617401123
val:  0.149169921875
Epoch [24/25], Train Loss: 0.6931, Validation Loss: 0.6931, lr = 0.0017199999999999987, duration = 11.625723838806152
train:  11.490813732147217
val:  0.15029597282409668
Epoch [25/25], Train Loss: 0.6931, Validation Loss: 0.6931, lr = 0.001359999999999999, duration = 11.641151428222656

Finished Training in 11.6

Plotting the results...
snr:  0.24321353062987328
score:  (0.425, 1.0, array([[4250, 5750],
       [   0,    0]]))
Noise Sigma:  0.7
Creating datasets...
20086
Start training...
train:  12.651522397994995
val:  0.9765026569366455
Epoch [1/25], Train Loss: 0.2521, Validation Loss: 0.0744, lr = 0.01, duration = 13.628077268600464
train:  11.728600978851318
val:  0.1574552059173584
Epoch [2/25], Train Loss: 0.0551, Validation Loss: 0.0392, lr = 0.00964, duration = 11.886097431182861
train:  11.715385913848877
val:  0.15259146690368652
Epoch [3/25], Train Loss: 0.0255, Validation Loss: 0.0204, lr = 0.00928, duration = 11.868016242980957
train:  11.703944206237793
val:  0.1519775390625
Epoch [4/25], Train Loss: 0.0199, Validation Loss: 0.0135, lr = 0.008919999999999999, duration = 11.855961799621582
train:  11.709524154663086
val:  0.15099501609802246
Epoch [5/25], Train Loss: 0.0144, Validation Loss: 0.0103, lr = 0.00856, duration = 11.860560417175293
train:  11.71396541595459
val:  0.15169858932495117
Epoch [6/25], Train Loss: 0.0154, Validation Loss: 0.0082, lr = 0.008199999999999999, duration = 11.865703344345093
train:  11.671546220779419
val:  0.15111756324768066
Epoch [7/25], Train Loss: 0.0110, Validation Loss: 0.0069, lr = 0.007839999999999998, duration = 11.82270622253418
train:  11.6437668800354
val:  0.15109634399414062
Epoch [8/25], Train Loss: 0.0087, Validation Loss: 0.0131, lr = 0.007479999999999998, duration = 11.794903755187988
train:  11.64975094795227
val:  0.1550002098083496
Epoch [9/25], Train Loss: 0.0094, Validation Loss: 0.0134, lr = 0.007119999999999998, duration = 11.80479121208191
train:  11.648838758468628
val:  0.15308904647827148
Epoch [10/25], Train Loss: 0.0088, Validation Loss: 0.0046, lr = 0.006759999999999998, duration = 11.801968812942505
train:  11.654763460159302
val:  0.15404701232910156
Epoch [11/25], Train Loss: 0.0086, Validation Loss: 0.0085, lr = 0.006399999999999998, duration = 11.808849096298218
train:  11.57099723815918
val:  0.15172958374023438
Epoch [12/25], Train Loss: 0.0073, Validation Loss: 0.0097, lr = 0.006039999999999998, duration = 11.722766160964966
train:  11.666388988494873
val:  0.15344977378845215
Epoch [13/25], Train Loss: 0.0069, Validation Loss: 0.0052, lr = 0.0056799999999999976, duration = 11.819879531860352
train:  11.565038204193115
val:  0.15342998504638672
Epoch [14/25], Train Loss: 0.0066, Validation Loss: 0.0064, lr = 0.0053199999999999975, duration = 11.718507528305054
train:  11.642492771148682
val:  0.1528017520904541
Epoch [15/25], Train Loss: 0.0055, Validation Loss: 0.0038, lr = 0.004959999999999997, duration = 11.795336723327637
train:  11.703504800796509
val:  0.15188050270080566
Epoch [16/25], Train Loss: 0.0049, Validation Loss: 0.0038, lr = 0.004599999999999997, duration = 11.855427503585815
train:  11.590948581695557
val:  0.15293645858764648
Epoch [17/25], Train Loss: 0.0054, Validation Loss: 0.0070, lr = 0.004239999999999997, duration = 11.743926286697388
train:  11.649426221847534
val:  0.15958142280578613
Epoch [18/25], Train Loss: 0.0045, Validation Loss: 0.0036, lr = 0.0038799999999999976, duration = 11.809049606323242
train:  11.668129682540894
val:  0.15625214576721191
Epoch [19/25], Train Loss: 0.0039, Validation Loss: 0.0036, lr = 0.003519999999999998, duration = 11.824428081512451
train:  11.600908756256104
val:  0.15141510963439941
Epoch [20/25], Train Loss: 0.0043, Validation Loss: 0.0044, lr = 0.003159999999999998, duration = 11.75236463546753
train:  11.644928932189941
val:  0.1711742877960205
Epoch [21/25], Train Loss: 0.0038, Validation Loss: 0.0029, lr = 0.002799999999999998, duration = 11.816142320632935
train:  11.686880826950073
val:  0.15172457695007324
Epoch [22/25], Train Loss: 0.0039, Validation Loss: 0.0087, lr = 0.002439999999999998, duration = 11.838643789291382
train:  11.642412900924683
val:  0.15299654006958008
Epoch [23/25], Train Loss: 0.0029, Validation Loss: 0.0032, lr = 0.0020799999999999985, duration = 11.79545283317566
train:  11.619137048721313
val:  0.15201187133789062
Epoch [24/25], Train Loss: 0.0032, Validation Loss: 0.0028, lr = 0.0017199999999999987, duration = 11.771189451217651
train:  11.56876516342163
val:  0.1519174575805664
Epoch [25/25], Train Loss: 0.0033, Validation Loss: 0.0029, lr = 0.001359999999999999, duration = 11.720723390579224

Finished Training in 11.7

Plotting the results...
snr:  -1.642630696296692
score:  (0.994484412470024, 0.975764705882353, array([[4147,   23],
       [ 103, 5727]]))
Saving model parameters...
done
