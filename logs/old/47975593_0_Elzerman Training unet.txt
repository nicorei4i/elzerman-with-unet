GPU available:  True
cuda
(100, 8192)
(100, 8192)
20086
noise sigs:  [0.01   0.5075 1.005  1.5025 2.    ]
Noise Sigma:  0.01
Creating datasets...
Start training...
Epoch [1/250], Train Loss: 0.6999, Validation Loss: 0.6938
Epoch [2/250], Train Loss: 0.6929, Validation Loss: 0.6912
Epoch [3/250], Train Loss: 0.6914, Validation Loss: 0.6900
Epoch [4/250], Train Loss: 0.6909, Validation Loss: 0.6896
Epoch [5/250], Train Loss: 0.6907, Validation Loss: 0.6894
Epoch [6/250], Train Loss: 0.6911, Validation Loss: 0.6893
Epoch [7/250], Train Loss: 0.6909, Validation Loss: 0.6889
Epoch [8/250], Train Loss: 0.6905, Validation Loss: 0.6870
Epoch [9/250], Train Loss: 0.6868, Validation Loss: 0.6711
Epoch [10/250], Train Loss: 0.6592, Validation Loss: 0.6109
Epoch [11/250], Train Loss: 0.5807, Validation Loss: 0.5171
Epoch [12/250], Train Loss: 0.4902, Validation Loss: 0.4128
Epoch [13/250], Train Loss: 0.3825, Validation Loss: 0.3141
Epoch [14/250], Train Loss: 0.2922, Validation Loss: 0.2729
Epoch [15/250], Train Loss: 0.2645, Validation Loss: 0.2595
Epoch [16/250], Train Loss: 0.2519, Validation Loss: 0.2473
Epoch [17/250], Train Loss: 0.2402, Validation Loss: 0.2359
Epoch [18/250], Train Loss: 0.2292, Validation Loss: 0.2253
Epoch [19/250], Train Loss: 0.2189, Validation Loss: 0.2154
Epoch [20/250], Train Loss: 0.2094, Validation Loss: 0.2061
Epoch [21/250], Train Loss: 0.2004, Validation Loss: 0.1976
Epoch [22/250], Train Loss: 0.1922, Validation Loss: 0.1897
Epoch [23/250], Train Loss: 0.1845, Validation Loss: 0.1824
Epoch [24/250], Train Loss: 0.1775, Validation Loss: 0.1755
Epoch [25/250], Train Loss: 0.1708, Validation Loss: 0.1690
Epoch [26/250], Train Loss: 0.1645, Validation Loss: 0.1628
Epoch [27/250], Train Loss: 0.1585, Validation Loss: 0.1571
Epoch [28/250], Train Loss: 0.1530, Validation Loss: 0.1517
Epoch [29/250], Train Loss: 0.1478, Validation Loss: 0.1466
Epoch [30/250], Train Loss: 0.1429, Validation Loss: 0.1418
Epoch [31/250], Train Loss: 0.1383, Validation Loss: 0.1373
Epoch [32/250], Train Loss: 0.1339, Validation Loss: 0.1331
Epoch [33/250], Train Loss: 0.1298, Validation Loss: 0.1291
Epoch [34/250], Train Loss: 0.1259, Validation Loss: 0.1253
Epoch [35/250], Train Loss: 0.1222, Validation Loss: 0.1217
Epoch [36/250], Train Loss: 0.1187, Validation Loss: 0.1182
Epoch [37/250], Train Loss: 0.1153, Validation Loss: 0.1149
Epoch [38/250], Train Loss: 0.1121, Validation Loss: 0.1117
Epoch [39/250], Train Loss: 0.1090, Validation Loss: 0.1087
Epoch [40/250], Train Loss: 0.1061, Validation Loss: 0.1058
Epoch [41/250], Train Loss: 0.1033, Validation Loss: 0.1029
Epoch [42/250], Train Loss: 0.1005, Validation Loss: 0.1002
Epoch [43/250], Train Loss: 0.0979, Validation Loss: 0.0976
Epoch [44/250], Train Loss: 0.0953, Validation Loss: 0.0951
Epoch [45/250], Train Loss: 0.0929, Validation Loss: 0.0928
Epoch [46/250], Train Loss: 0.0906, Validation Loss: 0.0905
Epoch [47/250], Train Loss: 0.0884, Validation Loss: 0.0883
Epoch [48/250], Train Loss: 0.0863, Validation Loss: 0.0862
Epoch [49/250], Train Loss: 0.0842, Validation Loss: 0.0842
Epoch [50/250], Train Loss: 0.0823, Validation Loss: 0.0823
Epoch [51/250], Train Loss: 0.0804, Validation Loss: 0.0804
Epoch [52/250], Train Loss: 0.0786, Validation Loss: 0.0786
Epoch [53/250], Train Loss: 0.0769, Validation Loss: 0.0769
Epoch [54/250], Train Loss: 0.0751, Validation Loss: 0.0752
Epoch [55/250], Train Loss: 0.0735, Validation Loss: 0.0736
Epoch [56/250], Train Loss: 0.0719, Validation Loss: 0.0720
Epoch [57/250], Train Loss: 0.0704, Validation Loss: 0.0705
Epoch [58/250], Train Loss: 0.0689, Validation Loss: 0.0690
Epoch [59/250], Train Loss: 0.0675, Validation Loss: 0.0676
Epoch [60/250], Train Loss: 0.0661, Validation Loss: 0.0663
Epoch [61/250], Train Loss: 0.0648, Validation Loss: 0.0650
Epoch [62/250], Train Loss: 0.0636, Validation Loss: 0.0637
Epoch [63/250], Train Loss: 0.0623, Validation Loss: 0.0625
Epoch [64/250], Train Loss: 0.0611, Validation Loss: 0.0613
Epoch [65/250], Train Loss: 0.0600, Validation Loss: 0.0601
Epoch [66/250], Train Loss: 0.0588, Validation Loss: 0.0590
Epoch [67/250], Train Loss: 0.0577, Validation Loss: 0.0579
Epoch [68/250], Train Loss: 0.0567, Validation Loss: 0.0569
Epoch [69/250], Train Loss: 0.0556, Validation Loss: 0.0558
Epoch [70/250], Train Loss: 0.0546, Validation Loss: 0.0548
Epoch [71/250], Train Loss: 0.0537, Validation Loss: 0.0539
Epoch [72/250], Train Loss: 0.0527, Validation Loss: 0.0529
Epoch [73/250], Train Loss: 0.0518, Validation Loss: 0.0520
Epoch [74/250], Train Loss: 0.0509, Validation Loss: 0.0511
Epoch [75/250], Train Loss: 0.0500, Validation Loss: 0.0502
Epoch [76/250], Train Loss: 0.0491, Validation Loss: 0.0493
Epoch [77/250], Train Loss: 0.0483, Validation Loss: 0.0485
Epoch [78/250], Train Loss: 0.0475, Validation Loss: 0.0477
Epoch [79/250], Train Loss: 0.0467, Validation Loss: 0.0469
Epoch [80/250], Train Loss: 0.0459, Validation Loss: 0.0462
Epoch [81/250], Train Loss: 0.0452, Validation Loss: 0.0455
Epoch [82/250], Train Loss: 0.0445, Validation Loss: 0.0448
Epoch [83/250], Train Loss: 0.0438, Validation Loss: 0.0441
Epoch [84/250], Train Loss: 0.0431, Validation Loss: 0.0434
Epoch [85/250], Train Loss: 0.0425, Validation Loss: 0.0427
Epoch [86/250], Train Loss: 0.0418, Validation Loss: 0.0421
Epoch [87/250], Train Loss: 0.0412, Validation Loss: 0.0414
Epoch [88/250], Train Loss: 0.0406, Validation Loss: 0.0408
Epoch [89/250], Train Loss: 0.0400, Validation Loss: 0.0402
Epoch [90/250], Train Loss: 0.0394, Validation Loss: 0.0397
Epoch [91/250], Train Loss: 0.0388, Validation Loss: 0.0391
Epoch [92/250], Train Loss: 0.0383, Validation Loss: 0.0385
Epoch [93/250], Train Loss: 0.0377, Validation Loss: 0.0380
Epoch [94/250], Train Loss: 0.0372, Validation Loss: 0.0375
Epoch [95/250], Train Loss: 0.0367, Validation Loss: 0.0369
Epoch [96/250], Train Loss: 0.0362, Validation Loss: 0.0364
Epoch [97/250], Train Loss: 0.0357, Validation Loss: 0.0359
Epoch [98/250], Train Loss: 0.0352, Validation Loss: 0.0354
Epoch [99/250], Train Loss: 0.0347, Validation Loss: 0.0349
Epoch [100/250], Train Loss: 0.0342, Validation Loss: 0.0345
Epoch [101/250], Train Loss: 0.0338, Validation Loss: 0.0340
Epoch [102/250], Train Loss: 0.0333, Validation Loss: 0.0336
Epoch [103/250], Train Loss: 0.0329, Validation Loss: 0.0331
Epoch [104/250], Train Loss: 0.0324, Validation Loss: 0.0327
Epoch [105/250], Train Loss: 0.0320, Validation Loss: 0.0323
Epoch [106/250], Train Loss: 0.0316, Validation Loss: 0.0318
Epoch [107/250], Train Loss: 0.0312, Validation Loss: 0.0314
Epoch [108/250], Train Loss: 0.0308, Validation Loss: 0.0310
Epoch [109/250], Train Loss: 0.0304, Validation Loss: 0.0306
Epoch [110/250], Train Loss: 0.0300, Validation Loss: 0.0303
Epoch [111/250], Train Loss: 0.0297, Validation Loss: 0.0299
Epoch [112/250], Train Loss: 0.0293, Validation Loss: 0.0295
Epoch [113/250], Train Loss: 0.0289, Validation Loss: 0.0292
Epoch [114/250], Train Loss: 0.0286, Validation Loss: 0.0288
Epoch [115/250], Train Loss: 0.0282, Validation Loss: 0.0285
Epoch [116/250], Train Loss: 0.0279, Validation Loss: 0.0281
Epoch [117/250], Train Loss: 0.0276, Validation Loss: 0.0278
Epoch [118/250], Train Loss: 0.0273, Validation Loss: 0.0275
Epoch [119/250], Train Loss: 0.0269, Validation Loss: 0.0272
Epoch [120/250], Train Loss: 0.0266, Validation Loss: 0.0269
Epoch [121/250], Train Loss: 0.0263, Validation Loss: 0.0266
Epoch [122/250], Train Loss: 0.0260, Validation Loss: 0.0263
Epoch [123/250], Train Loss: 0.0257, Validation Loss: 0.0260
Epoch [124/250], Train Loss: 0.0255, Validation Loss: 0.0257
Epoch [125/250], Train Loss: 0.0252, Validation Loss: 0.0254
Epoch [126/250], Train Loss: 0.0249, Validation Loss: 0.0251
Epoch [127/250], Train Loss: 0.0246, Validation Loss: 0.0249
Epoch [128/250], Train Loss: 0.0244, Validation Loss: 0.0246
Epoch [129/250], Train Loss: 0.0241, Validation Loss: 0.0243
Epoch [130/250], Train Loss: 0.0238, Validation Loss: 0.0241
Epoch [131/250], Train Loss: 0.0236, Validation Loss: 0.0238
Epoch [132/250], Train Loss: 0.0233, Validation Loss: 0.0236
Epoch [133/250], Train Loss: 0.0231, Validation Loss: 0.0233
Epoch [134/250], Train Loss: 0.0229, Validation Loss: 0.0231
Epoch [135/250], Train Loss: 0.0226, Validation Loss: 0.0228
Epoch [136/250], Train Loss: 0.0224, Validation Loss: 0.0226
Epoch [137/250], Train Loss: 0.0222, Validation Loss: 0.0224
Epoch [138/250], Train Loss: 0.0219, Validation Loss: 0.0221
Epoch [139/250], Train Loss: 0.0217, Validation Loss: 0.0219
Epoch [140/250], Train Loss: 0.0215, Validation Loss: 0.0217
Epoch [141/250], Train Loss: 0.0213, Validation Loss: 0.0215
Epoch [142/250], Train Loss: 0.0211, Validation Loss: 0.0213
Epoch [143/250], Train Loss: 0.0209, Validation Loss: 0.0211
Epoch [144/250], Train Loss: 0.0207, Validation Loss: 0.0209
Epoch [145/250], Train Loss: 0.0205, Validation Loss: 0.0207
Epoch [146/250], Train Loss: 0.0203, Validation Loss: 0.0205
Epoch [147/250], Train Loss: 0.0201, Validation Loss: 0.0203
Epoch [148/250], Train Loss: 0.0199, Validation Loss: 0.0201
Epoch [149/250], Train Loss: 0.0197, Validation Loss: 0.0199
Epoch [150/250], Train Loss: 0.0195, Validation Loss: 0.0197
Epoch [151/250], Train Loss: 0.0194, Validation Loss: 0.0196
Epoch [152/250], Train Loss: 0.0192, Validation Loss: 0.0194
Epoch [153/250], Train Loss: 0.0190, Validation Loss: 0.0192
Epoch [154/250], Train Loss: 0.0188, Validation Loss: 0.0190
Epoch [155/250], Train Loss: 0.0187, Validation Loss: 0.0189
Epoch [156/250], Train Loss: 0.0185, Validation Loss: 0.0187
Epoch [157/250], Train Loss: 0.0183, Validation Loss: 0.0185
Epoch [158/250], Train Loss: 0.0182, Validation Loss: 0.0184
Epoch [159/250], Train Loss: 0.0180, Validation Loss: 0.0182
Epoch [160/250], Train Loss: 0.0178, Validation Loss: 0.0180
Epoch [161/250], Train Loss: 0.0177, Validation Loss: 0.0179
Epoch [162/250], Train Loss: 0.0175, Validation Loss: 0.0177
Epoch [163/250], Train Loss: 0.0174, Validation Loss: 0.0176
Epoch [164/250], Train Loss: 0.0172, Validation Loss: 0.0174
Epoch [165/250], Train Loss: 0.0171, Validation Loss: 0.0173
Epoch [166/250], Train Loss: 0.0169, Validation Loss: 0.0171
Epoch [167/250], Train Loss: 0.0168, Validation Loss: 0.0170
Epoch [168/250], Train Loss: 0.0167, Validation Loss: 0.0169
Epoch [169/250], Train Loss: 0.0165, Validation Loss: 0.0167
Epoch [170/250], Train Loss: 0.0164, Validation Loss: 0.0166
Epoch [171/250], Train Loss: 0.0163, Validation Loss: 0.0164
Epoch [172/250], Train Loss: 0.0161, Validation Loss: 0.0163
Epoch [173/250], Train Loss: 0.0160, Validation Loss: 0.0162
Epoch [174/250], Train Loss: 0.0159, Validation Loss: 0.0160
Epoch [175/250], Train Loss: 0.0157, Validation Loss: 0.0159
Epoch [176/250], Train Loss: 0.0156, Validation Loss: 0.0158
Epoch [177/250], Train Loss: 0.0155, Validation Loss: 0.0157
Epoch [178/250], Train Loss: 0.0154, Validation Loss: 0.0155
Epoch [179/250], Train Loss: 0.0152, Validation Loss: 0.0154
Epoch [180/250], Train Loss: 0.0151, Validation Loss: 0.0153
Epoch [181/250], Train Loss: 0.0150, Validation Loss: 0.0152
Epoch [182/250], Train Loss: 0.0149, Validation Loss: 0.0150
Epoch [183/250], Train Loss: 0.0148, Validation Loss: 0.0149
Epoch [184/250], Train Loss: 0.0146, Validation Loss: 0.0148
Epoch [185/250], Train Loss: 0.0145, Validation Loss: 0.0147
Epoch [186/250], Train Loss: 0.0144, Validation Loss: 0.0146
Epoch [187/250], Train Loss: 0.0143, Validation Loss: 0.0145
Epoch [188/250], Train Loss: 0.0142, Validation Loss: 0.0144
Epoch [189/250], Train Loss: 0.0141, Validation Loss: 0.0143
Epoch [190/250], Train Loss: 0.0140, Validation Loss: 0.0142
Epoch [191/250], Train Loss: 0.0139, Validation Loss: 0.0140
Epoch [192/250], Train Loss: 0.0138, Validation Loss: 0.0139
Epoch [193/250], Train Loss: 0.0137, Validation Loss: 0.0138
Epoch [194/250], Train Loss: 0.0136, Validation Loss: 0.0137
Epoch [195/250], Train Loss: 0.0135, Validation Loss: 0.0136
Epoch [196/250], Train Loss: 0.0134, Validation Loss: 0.0135
Epoch [197/250], Train Loss: 0.0133, Validation Loss: 0.0134
Epoch [198/250], Train Loss: 0.0132, Validation Loss: 0.0133
Epoch [199/250], Train Loss: 0.0131, Validation Loss: 0.0132
Epoch [200/250], Train Loss: 0.0130, Validation Loss: 0.0132
Epoch [201/250], Train Loss: 0.0129, Validation Loss: 0.0131
Epoch [202/250], Train Loss: 0.0128, Validation Loss: 0.0130
Epoch [203/250], Train Loss: 0.0127, Validation Loss: 0.0129
Epoch [204/250], Train Loss: 0.0126, Validation Loss: 0.0128
Epoch [205/250], Train Loss: 0.0125, Validation Loss: 0.0127
Epoch [206/250], Train Loss: 0.0125, Validation Loss: 0.0126
Epoch [207/250], Train Loss: 0.0124, Validation Loss: 0.0125
Epoch [208/250], Train Loss: 0.0123, Validation Loss: 0.0124
Epoch [209/250], Train Loss: 0.0122, Validation Loss: 0.0124
Epoch [210/250], Train Loss: 0.0121, Validation Loss: 0.0123
Epoch [211/250], Train Loss: 0.0120, Validation Loss: 0.0122
Epoch [212/250], Train Loss: 0.0120, Validation Loss: 0.0121
Epoch [213/250], Train Loss: 0.0119, Validation Loss: 0.0120
Epoch [214/250], Train Loss: 0.0118, Validation Loss: 0.0119
Epoch [215/250], Train Loss: 0.0117, Validation Loss: 0.0119
Epoch [216/250], Train Loss: 0.0116, Validation Loss: 0.0118
Epoch [217/250], Train Loss: 0.0116, Validation Loss: 0.0117
Epoch [218/250], Train Loss: 0.0115, Validation Loss: 0.0116
Epoch [219/250], Train Loss: 0.0114, Validation Loss: 0.0116
Epoch [220/250], Train Loss: 0.0113, Validation Loss: 0.0115
Epoch [221/250], Train Loss: 0.0113, Validation Loss: 0.0114
Epoch [222/250], Train Loss: 0.0112, Validation Loss: 0.0113
Epoch [223/250], Train Loss: 0.0111, Validation Loss: 0.0113
Epoch [224/250], Train Loss: 0.0110, Validation Loss: 0.0112
Epoch [225/250], Train Loss: 0.0110, Validation Loss: 0.0111
Epoch [226/250], Train Loss: 0.0109, Validation Loss: 0.0111
Epoch [227/250], Train Loss: 0.0108, Validation Loss: 0.0110
Epoch [228/250], Train Loss: 0.0108, Validation Loss: 0.0109
Epoch [229/250], Train Loss: 0.0107, Validation Loss: 0.0108
Epoch [230/250], Train Loss: 0.0106, Validation Loss: 0.0108
Epoch [231/250], Train Loss: 0.0106, Validation Loss: 0.0107
Epoch [232/250], Train Loss: 0.0105, Validation Loss: 0.0106
Epoch [233/250], Train Loss: 0.0104, Validation Loss: 0.0106
Epoch [234/250], Train Loss: 0.0104, Validation Loss: 0.0105
Epoch [235/250], Train Loss: 0.0103, Validation Loss: 0.0104
Epoch [236/250], Train Loss: 0.0102, Validation Loss: 0.0104
Epoch [237/250], Train Loss: 0.0102, Validation Loss: 0.0103
Epoch [238/250], Train Loss: 0.0101, Validation Loss: 0.0103
Epoch [239/250], Train Loss: 0.0101, Validation Loss: 0.0102
Epoch [240/250], Train Loss: 0.0100, Validation Loss: 0.0101
Epoch [241/250], Train Loss: 0.0099, Validation Loss: 0.0101
Epoch [242/250], Train Loss: 0.0099, Validation Loss: 0.0100
Epoch [243/250], Train Loss: 0.0098, Validation Loss: 0.0100
Epoch [244/250], Train Loss: 0.0098, Validation Loss: 0.0099
Epoch [245/250], Train Loss: 0.0097, Validation Loss: 0.0098
Epoch [246/250], Train Loss: 0.0097, Validation Loss: 0.0098
Epoch [247/250], Train Loss: 0.0096, Validation Loss: 0.0097
Epoch [248/250], Train Loss: 0.0095, Validation Loss: 0.0097
Epoch [249/250], Train Loss: 0.0095, Validation Loss: 0.0096
Epoch [250/250], Train Loss: 0.0094, Validation Loss: 0.0096

Finished Training in 80.0

Noise Sigma:  0.5075
Creating datasets...
Start training...
Epoch [1/250], Train Loss: 0.8309, Validation Loss: 0.8205
Epoch [2/250], Train Loss: 0.8811, Validation Loss: 0.5569
Epoch [3/250], Train Loss: 0.5715, Validation Loss: 0.3887
Epoch [4/250], Train Loss: 0.3830, Validation Loss: 0.5433
Epoch [5/250], Train Loss: 0.4825, Validation Loss: 0.2546
Epoch [6/250], Train Loss: 0.3172, Validation Loss: 0.2814
Epoch [7/250], Train Loss: 0.2881, Validation Loss: 0.3067
Epoch [8/250], Train Loss: 0.2960, Validation Loss: 0.2905
Epoch [9/250], Train Loss: 0.2901, Validation Loss: 0.2763
Epoch [10/250], Train Loss: 0.2592, Validation Loss: 0.2641
Epoch [11/250], Train Loss: 0.2734, Validation Loss: 0.2615
Epoch [12/250], Train Loss: 0.2614, Validation Loss: 0.2605
Epoch [13/250], Train Loss: 0.2521, Validation Loss: 0.2372
Epoch [14/250], Train Loss: 0.2721, Validation Loss: 0.2558
Epoch [15/250], Train Loss: 0.2756, Validation Loss: 0.2389
Epoch [16/250], Train Loss: 0.2490, Validation Loss: 0.2614
Epoch [17/250], Train Loss: 0.2339, Validation Loss: 0.2390
Epoch [18/250], Train Loss: 0.2473, Validation Loss: 0.2544
Epoch [19/250], Train Loss: 0.2501, Validation Loss: 0.2394
Epoch [20/250], Train Loss: 0.2498, Validation Loss: 0.2446
Epoch [21/250], Train Loss: 0.2416, Validation Loss: 0.2363
Epoch [22/250], Train Loss: 0.2342, Validation Loss: 0.2556
Epoch [23/250], Train Loss: 0.2569, Validation Loss: 0.2299
Epoch [24/250], Train Loss: 0.2268, Validation Loss: 0.2327
Epoch [25/250], Train Loss: 0.2212, Validation Loss: 0.2351
Epoch [26/250], Train Loss: 0.2135, Validation Loss: 0.2343
Epoch [27/250], Train Loss: 0.2285, Validation Loss: 0.2497
Epoch [28/250], Train Loss: 0.2327, Validation Loss: 0.2350
Epoch [29/250], Train Loss: 0.2199, Validation Loss: 0.2378
Epoch [30/250], Train Loss: 0.2247, Validation Loss: 0.2238
Epoch [31/250], Train Loss: 0.2295, Validation Loss: 0.2484
Epoch [32/250], Train Loss: 0.2232, Validation Loss: 0.2335
Epoch [33/250], Train Loss: 0.2459, Validation Loss: 0.2255
Epoch [34/250], Train Loss: 0.2277, Validation Loss: 0.2382
Epoch [35/250], Train Loss: 0.2421, Validation Loss: 0.2273
Epoch [36/250], Train Loss: 0.2282, Validation Loss: 0.2495
Epoch [37/250], Train Loss: 0.2268, Validation Loss: 0.2109
Epoch [38/250], Train Loss: 0.2240, Validation Loss: 0.2259
Epoch [39/250], Train Loss: 0.2362, Validation Loss: 0.2325
Epoch [40/250], Train Loss: 0.2338, Validation Loss: 0.2359
Epoch [41/250], Train Loss: 0.2323, Validation Loss: 0.2369
Epoch [42/250], Train Loss: 0.2210, Validation Loss: 0.2215
Epoch [43/250], Train Loss: 0.2262, Validation Loss: 0.2278
Epoch [44/250], Train Loss: 0.2288, Validation Loss: 0.2340
Epoch [45/250], Train Loss: 0.2122, Validation Loss: 0.2275
Epoch [46/250], Train Loss: 0.2192, Validation Loss: 0.2263
Epoch [47/250], Train Loss: 0.2436, Validation Loss: 0.2330
Epoch [48/250], Train Loss: 0.2271, Validation Loss: 0.2278
Epoch [49/250], Train Loss: 0.2173, Validation Loss: 0.2452
Epoch [50/250], Train Loss: 0.2224, Validation Loss: 0.2493
Epoch [51/250], Train Loss: 0.2721, Validation Loss: 0.2518
Epoch [52/250], Train Loss: 0.2763, Validation Loss: 0.2415
Epoch [53/250], Train Loss: 0.2347, Validation Loss: 0.2635
Epoch [54/250], Train Loss: 0.2350, Validation Loss: 0.2311
Epoch [55/250], Train Loss: 0.2245, Validation Loss: 0.2265
Epoch [56/250], Train Loss: 0.2255, Validation Loss: 0.2322
Epoch [57/250], Train Loss: 0.2304, Validation Loss: 0.2275
Epoch [58/250], Train Loss: 0.2420, Validation Loss: 0.2501
Epoch [59/250], Train Loss: 0.2417, Validation Loss: 0.2517
Epoch [60/250], Train Loss: 0.2377, Validation Loss: 0.2294
Epoch [61/250], Train Loss: 0.2245, Validation Loss: 0.2256
Epoch [62/250], Train Loss: 0.2234, Validation Loss: 0.2462
Epoch [63/250], Train Loss: 0.2264, Validation Loss: 0.2296
Epoch [64/250], Train Loss: 0.2204, Validation Loss: 0.2616
Epoch [65/250], Train Loss: 0.2462, Validation Loss: 0.2284
Epoch [66/250], Train Loss: 0.2290, Validation Loss: 0.2355
Epoch [67/250], Train Loss: 0.2335, Validation Loss: 0.2364
Epoch [68/250], Train Loss: 0.2249, Validation Loss: 0.2324
Epoch [69/250], Train Loss: 0.2400, Validation Loss: 0.2337
Epoch [70/250], Train Loss: 0.2382, Validation Loss: 0.2395
Epoch [71/250], Train Loss: 0.2156, Validation Loss: 0.2325
Epoch [72/250], Train Loss: 0.2332, Validation Loss: 0.2457
Epoch [73/250], Train Loss: 0.2248, Validation Loss: 0.2372
Epoch [74/250], Train Loss: 0.2276, Validation Loss: 0.2273
Epoch [75/250], Train Loss: 0.2314, Validation Loss: 0.2336
Epoch [76/250], Train Loss: 0.2240, Validation Loss: 0.2341
Epoch [77/250], Train Loss: 0.2335, Validation Loss: 0.2397
Epoch [78/250], Train Loss: 0.2252, Validation Loss: 0.2250
Epoch [79/250], Train Loss: 0.2143, Validation Loss: 0.2336
Epoch [80/250], Train Loss: 0.2276, Validation Loss: 0.2450
Epoch [81/250], Train Loss: 0.2228, Validation Loss: 0.2382
Epoch [82/250], Train Loss: 0.2343, Validation Loss: 0.2305
Epoch [83/250], Train Loss: 0.2434, Validation Loss: 0.2356
Epoch [84/250], Train Loss: 0.2190, Validation Loss: 0.2511
Epoch [85/250], Train Loss: 0.2256, Validation Loss: 0.2344
Epoch [86/250], Train Loss: 0.2364, Validation Loss: 0.2342
Epoch [87/250], Train Loss: 0.2395, Validation Loss: 0.2422
Epoch [88/250], Train Loss: 0.2173, Validation Loss: 0.2351
Epoch [89/250], Train Loss: 0.2118, Validation Loss: 0.2356
Epoch [90/250], Train Loss: 0.2509, Validation Loss: 0.2375
Epoch [91/250], Train Loss: 0.2234, Validation Loss: 0.2432
Epoch [92/250], Train Loss: 0.2323, Validation Loss: 0.2310
Epoch [93/250], Train Loss: 0.2301, Validation Loss: 0.2611
Epoch [94/250], Train Loss: 0.2328, Validation Loss: 0.2360
Epoch [95/250], Train Loss: 0.2332, Validation Loss: 0.2364
Epoch [96/250], Train Loss: 0.2269, Validation Loss: 0.2512
Epoch [97/250], Train Loss: 0.2104, Validation Loss: 0.2279
Epoch [98/250], Train Loss: 0.2276, Validation Loss: 0.2125
Epoch [99/250], Train Loss: 0.2337, Validation Loss: 0.2415
Epoch [100/250], Train Loss: 0.2460, Validation Loss: 0.2215
Epoch [101/250], Train Loss: 0.2603, Validation Loss: 0.2573
Epoch [102/250], Train Loss: 0.2497, Validation Loss: 0.2332
Epoch [103/250], Train Loss: 0.2184, Validation Loss: 0.2328
Epoch [104/250], Train Loss: 0.2083, Validation Loss: 0.2222
Epoch [105/250], Train Loss: 0.2298, Validation Loss: 0.2258
Epoch [106/250], Train Loss: 0.2274, Validation Loss: 0.2311
Epoch [107/250], Train Loss: 0.2142, Validation Loss: 0.2214
Epoch [108/250], Train Loss: 0.2228, Validation Loss: 0.2351
Epoch [109/250], Train Loss: 0.2400, Validation Loss: 0.2303
Epoch [110/250], Train Loss: 0.2330, Validation Loss: 0.2175
Epoch [111/250], Train Loss: 0.2504, Validation Loss: 0.2241
Epoch [112/250], Train Loss: 0.2284, Validation Loss: 0.2399
Epoch [113/250], Train Loss: 0.2307, Validation Loss: 0.2314
Epoch [114/250], Train Loss: 0.2326, Validation Loss: 0.2304
Epoch [115/250], Train Loss: 0.2491, Validation Loss: 0.2175
Epoch [116/250], Train Loss: 0.2259, Validation Loss: 0.2321
Epoch [117/250], Train Loss: 0.2147, Validation Loss: 0.2201
Epoch [118/250], Train Loss: 0.2341, Validation Loss: 0.2290
Epoch [119/250], Train Loss: 0.2318, Validation Loss: 0.2249
Epoch [120/250], Train Loss: 0.2259, Validation Loss: 0.2454
Epoch [121/250], Train Loss: 0.2223, Validation Loss: 0.2629
Epoch [122/250], Train Loss: 0.2466, Validation Loss: 0.2457
Epoch [123/250], Train Loss: 0.2311, Validation Loss: 0.2475
Epoch [124/250], Train Loss: 0.2291, Validation Loss: 0.2430
Epoch [125/250], Train Loss: 0.2100, Validation Loss: 0.2296
Epoch [126/250], Train Loss: 0.2185, Validation Loss: 0.2421
Epoch [127/250], Train Loss: 0.2163, Validation Loss: 0.2313
Epoch [128/250], Train Loss: 0.2171, Validation Loss: 0.2442
Epoch [129/250], Train Loss: 0.2196, Validation Loss: 0.2392
Epoch [130/250], Train Loss: 0.2237, Validation Loss: 0.2238
Epoch [131/250], Train Loss: 0.2226, Validation Loss: 0.2335
Epoch [132/250], Train Loss: 0.2090, Validation Loss: 0.2265
Epoch [133/250], Train Loss: 0.2158, Validation Loss: 0.2219
Epoch [134/250], Train Loss: 0.2224, Validation Loss: 0.2446
Epoch [135/250], Train Loss: 0.2377, Validation Loss: 0.2263
Epoch [136/250], Train Loss: 0.2311, Validation Loss: 0.2322
Epoch [137/250], Train Loss: 0.2178, Validation Loss: 0.2259
Epoch [138/250], Train Loss: 0.2355, Validation Loss: 0.2152
Epoch [139/250], Train Loss: 0.2202, Validation Loss: 0.2196
Epoch [140/250], Train Loss: 0.2217, Validation Loss: 0.2128
Epoch [141/250], Train Loss: 0.2118, Validation Loss: 0.2259
Epoch [142/250], Train Loss: 0.2283, Validation Loss: 0.2783
Epoch [143/250], Train Loss: 0.2516, Validation Loss: 0.2317
Epoch [144/250], Train Loss: 0.2726, Validation Loss: 0.2601
Epoch [145/250], Train Loss: 0.2118, Validation Loss: 0.2413
Epoch [146/250], Train Loss: 0.2392, Validation Loss: 0.2452
Epoch [147/250], Train Loss: 0.2403, Validation Loss: 0.2676
Epoch [148/250], Train Loss: 0.2436, Validation Loss: 0.2384
Epoch [149/250], Train Loss: 0.2228, Validation Loss: 0.2315
Epoch [150/250], Train Loss: 0.2419, Validation Loss: 0.2207
Epoch [151/250], Train Loss: 0.2204, Validation Loss: 0.2396
Epoch [152/250], Train Loss: 0.2310, Validation Loss: 0.2319
Epoch [153/250], Train Loss: 0.2121, Validation Loss: 0.2450
Epoch [154/250], Train Loss: 0.2032, Validation Loss: 0.2282
Epoch [155/250], Train Loss: 0.2332, Validation Loss: 0.2345
Epoch [156/250], Train Loss: 0.2336, Validation Loss: 0.2082
Epoch [157/250], Train Loss: 0.2175, Validation Loss: 0.2254
Epoch [158/250], Train Loss: 0.2250, Validation Loss: 0.2232
Epoch [159/250], Train Loss: 0.2269, Validation Loss: 0.2312
Epoch [160/250], Train Loss: 0.2218, Validation Loss: 0.2342
Epoch [161/250], Train Loss: 0.2386, Validation Loss: 0.2114
Epoch [162/250], Train Loss: 0.2086, Validation Loss: 0.2393
Epoch [163/250], Train Loss: 0.2130, Validation Loss: 0.2401
Epoch [164/250], Train Loss: 0.2200, Validation Loss: 0.2135
Epoch [165/250], Train Loss: 0.2143, Validation Loss: 0.2151
Epoch [166/250], Train Loss: 0.2320, Validation Loss: 0.2288
Epoch [167/250], Train Loss: 0.2166, Validation Loss: 0.2265
Epoch [168/250], Train Loss: 0.2302, Validation Loss: 0.2307
Epoch [169/250], Train Loss: 0.2325, Validation Loss: 0.2366
Epoch [170/250], Train Loss: 0.2198, Validation Loss: 0.2405
Epoch [171/250], Train Loss: 0.2278, Validation Loss: 0.2432
Epoch [172/250], Train Loss: 0.2361, Validation Loss: 0.2368
Epoch [173/250], Train Loss: 0.2275, Validation Loss: 0.2215
Epoch [174/250], Train Loss: 0.2242, Validation Loss: 0.2211
Epoch [175/250], Train Loss: 0.2218, Validation Loss: 0.2291
Epoch [176/250], Train Loss: 0.2329, Validation Loss: 0.2290
Epoch [177/250], Train Loss: 0.2226, Validation Loss: 0.2242
Epoch [178/250], Train Loss: 0.2138, Validation Loss: 0.2223
Epoch [179/250], Train Loss: 0.2182, Validation Loss: 0.2420
Epoch [180/250], Train Loss: 0.2264, Validation Loss: 0.2449
Epoch [181/250], Train Loss: 0.2226, Validation Loss: 0.2543
Epoch [182/250], Train Loss: 0.2215, Validation Loss: 0.2255
Epoch [183/250], Train Loss: 0.2153, Validation Loss: 0.2211
Epoch [184/250], Train Loss: 0.2158, Validation Loss: 0.2230
Epoch [185/250], Train Loss: 0.2413, Validation Loss: 0.2420
Epoch [186/250], Train Loss: 0.2352, Validation Loss: 0.2380
Epoch [187/250], Train Loss: 0.2363, Validation Loss: 0.2467
Epoch [188/250], Train Loss: 0.2223, Validation Loss: 0.2260
Epoch [189/250], Train Loss: 0.2270, Validation Loss: 0.2490
Epoch [190/250], Train Loss: 0.2159, Validation Loss: 0.2281
Epoch [191/250], Train Loss: 0.2269, Validation Loss: 0.2130
Epoch [192/250], Train Loss: 0.2126, Validation Loss: 0.2324
Epoch [193/250], Train Loss: 0.2217, Validation Loss: 0.2275
Epoch [194/250], Train Loss: 0.2222, Validation Loss: 0.2240
Epoch [195/250], Train Loss: 0.2114, Validation Loss: 0.2299
Epoch [196/250], Train Loss: 0.2236, Validation Loss: 0.2217
Epoch [197/250], Train Loss: 0.2318, Validation Loss: 0.2412
Epoch [198/250], Train Loss: 0.2345, Validation Loss: 0.2139
Epoch [199/250], Train Loss: 0.2256, Validation Loss: 0.2594
Epoch [200/250], Train Loss: 0.2309, Validation Loss: 0.2240
Epoch [201/250], Train Loss: 0.2315, Validation Loss: 0.2456
Epoch [202/250], Train Loss: 0.2127, Validation Loss: 0.2095
Epoch [203/250], Train Loss: 0.2122, Validation Loss: 0.2251
Epoch [204/250], Train Loss: 0.2196, Validation Loss: 0.2332
Epoch [205/250], Train Loss: 0.2140, Validation Loss: 0.2272
Epoch [206/250], Train Loss: 0.2131, Validation Loss: 0.2164
Epoch [207/250], Train Loss: 0.2265, Validation Loss: 0.2197
Epoch [208/250], Train Loss: 0.2139, Validation Loss: 0.2205
Epoch [209/250], Train Loss: 0.2212, Validation Loss: 0.2263
Epoch [210/250], Train Loss: 0.2215, Validation Loss: 0.2257
Epoch [211/250], Train Loss: 0.2368, Validation Loss: 0.2122
Epoch [212/250], Train Loss: 0.2195, Validation Loss: 0.2440
Epoch [213/250], Train Loss: 0.2437, Validation Loss: 0.2195
Epoch [214/250], Train Loss: 0.2226, Validation Loss: 0.2168
Epoch [215/250], Train Loss: 0.2034, Validation Loss: 0.2397
Epoch [216/250], Train Loss: 0.2423, Validation Loss: 0.2271
Epoch [217/250], Train Loss: 0.2205, Validation Loss: 0.2400
Epoch [218/250], Train Loss: 0.2388, Validation Loss: 0.2007
Epoch [219/250], Train Loss: 0.2139, Validation Loss: 0.2424
Epoch [220/250], Train Loss: 0.2058, Validation Loss: 0.2306
Epoch [221/250], Train Loss: 0.2078, Validation Loss: 0.2381
Epoch [222/250], Train Loss: 0.2280, Validation Loss: 0.2070
Epoch [223/250], Train Loss: 0.2129, Validation Loss: 0.2321
Epoch [224/250], Train Loss: 0.2271, Validation Loss: 0.2437
Epoch [225/250], Train Loss: 0.2424, Validation Loss: 0.2146
Epoch [226/250], Train Loss: 0.2412, Validation Loss: 0.2440
Epoch [227/250], Train Loss: 0.2192, Validation Loss: 0.2205
Epoch [228/250], Train Loss: 0.2196, Validation Loss: 0.2363
Epoch [229/250], Train Loss: 0.2133, Validation Loss: 0.2186
Epoch [230/250], Train Loss: 0.2413, Validation Loss: 0.2185
Epoch [231/250], Train Loss: 0.2235, Validation Loss: 0.2181
Epoch [232/250], Train Loss: 0.2097, Validation Loss: 0.2375
Epoch [233/250], Train Loss: 0.2223, Validation Loss: 0.2256
Epoch [234/250], Train Loss: 0.2216, Validation Loss: 0.2242
Epoch [235/250], Train Loss: 0.2250, Validation Loss: 0.2260
Epoch [236/250], Train Loss: 0.2373, Validation Loss: 0.2139
Epoch [237/250], Train Loss: 0.2244, Validation Loss: 0.2238
Epoch [238/250], Train Loss: 0.2161, Validation Loss: 0.2248
Epoch [239/250], Train Loss: 0.2212, Validation Loss: 0.2180
Epoch [240/250], Train Loss: 0.2184, Validation Loss: 0.2347
Epoch [241/250], Train Loss: 0.2361, Validation Loss: 0.2163
Epoch [242/250], Train Loss: 0.2230, Validation Loss: 0.2259
Epoch [243/250], Train Loss: 0.2083, Validation Loss: 0.2318
Epoch [244/250], Train Loss: 0.2459, Validation Loss: 0.2276
Epoch [245/250], Train Loss: 0.2235, Validation Loss: 0.2402
Epoch [246/250], Train Loss: 0.2522, Validation Loss: 0.2333
Epoch [247/250], Train Loss: 0.2243, Validation Loss: 0.2373
Epoch [248/250], Train Loss: 0.2201, Validation Loss: 0.2304
Epoch [249/250], Train Loss: 0.2241, Validation Loss: 0.2336
Epoch [250/250], Train Loss: 0.2251, Validation Loss: 0.2396

Finished Training in 79.4

Noise Sigma:  1.005
Creating datasets...
Start training...
Epoch [1/250], Train Loss: 0.6345, Validation Loss: 0.5550
Epoch [2/250], Train Loss: 0.5385, Validation Loss: 0.5843
Epoch [3/250], Train Loss: 0.5608, Validation Loss: 0.5298
Epoch [4/250], Train Loss: 0.5220, Validation Loss: 0.5143
Epoch [5/250], Train Loss: 0.5076, Validation Loss: 0.5143
Epoch [6/250], Train Loss: 0.5148, Validation Loss: 0.5277
Epoch [7/250], Train Loss: 0.5372, Validation Loss: 0.5255
Epoch [8/250], Train Loss: 0.5035, Validation Loss: 0.5296
Epoch [9/250], Train Loss: 0.5256, Validation Loss: 0.5160
Epoch [10/250], Train Loss: 0.5019, Validation Loss: 0.5077
Epoch [11/250], Train Loss: 0.5013, Validation Loss: 0.5123
Epoch [12/250], Train Loss: 0.4970, Validation Loss: 0.4975
Epoch [13/250], Train Loss: 0.5038, Validation Loss: 0.5126
Epoch [14/250], Train Loss: 0.5175, Validation Loss: 0.4921
Epoch [15/250], Train Loss: 0.4901, Validation Loss: 0.5084
Epoch [16/250], Train Loss: 0.5109, Validation Loss: 0.4991
Epoch [17/250], Train Loss: 0.5022, Validation Loss: 0.5166
Epoch [18/250], Train Loss: 0.4953, Validation Loss: 0.4959
Epoch [19/250], Train Loss: 0.5135, Validation Loss: 0.5195
Epoch [20/250], Train Loss: 0.5077, Validation Loss: 0.5002
Epoch [21/250], Train Loss: 0.5017, Validation Loss: 0.5048
Epoch [22/250], Train Loss: 0.5203, Validation Loss: 0.5138
Epoch [23/250], Train Loss: 0.5080, Validation Loss: 0.4987
Epoch [24/250], Train Loss: 0.5027, Validation Loss: 0.4998
Epoch [25/250], Train Loss: 0.4901, Validation Loss: 0.5145
Epoch [26/250], Train Loss: 0.5063, Validation Loss: 0.5172
Epoch [27/250], Train Loss: 0.5071, Validation Loss: 0.4955
Epoch [28/250], Train Loss: 0.5031, Validation Loss: 0.4976
Epoch [29/250], Train Loss: 0.5039, Validation Loss: 0.5050
Epoch [30/250], Train Loss: 0.5006, Validation Loss: 0.5021
Epoch [31/250], Train Loss: 0.5027, Validation Loss: 0.4929
Epoch [32/250], Train Loss: 0.4995, Validation Loss: 0.4957
Epoch [33/250], Train Loss: 0.4933, Validation Loss: 0.4984
Epoch [34/250], Train Loss: 0.4922, Validation Loss: 0.5162
Epoch [35/250], Train Loss: 0.4814, Validation Loss: 0.5054
Epoch [36/250], Train Loss: 0.5013, Validation Loss: 0.5084
Epoch [37/250], Train Loss: 0.4721, Validation Loss: 0.4888
Epoch [38/250], Train Loss: 0.5445, Validation Loss: 0.4915
Epoch [39/250], Train Loss: 0.4752, Validation Loss: 0.5141
Epoch [40/250], Train Loss: 0.4877, Validation Loss: 0.5148
Epoch [41/250], Train Loss: 0.5098, Validation Loss: 0.4969
Epoch [42/250], Train Loss: 0.5090, Validation Loss: 0.5015
Epoch [43/250], Train Loss: 0.5099, Validation Loss: 0.5038
Epoch [44/250], Train Loss: 0.5064, Validation Loss: 0.4949
Epoch [45/250], Train Loss: 0.4883, Validation Loss: 0.4981
Epoch [46/250], Train Loss: 0.4863, Validation Loss: 0.5142
Epoch [47/250], Train Loss: 0.5028, Validation Loss: 0.5063
Epoch [48/250], Train Loss: 0.5241, Validation Loss: 0.4926
Epoch [49/250], Train Loss: 0.5205, Validation Loss: 0.5591
Epoch [50/250], Train Loss: 0.5218, Validation Loss: 0.5025
Epoch [51/250], Train Loss: 0.5289, Validation Loss: 0.5268
Epoch [52/250], Train Loss: 0.5076, Validation Loss: 0.4945
Epoch [53/250], Train Loss: 0.5218, Validation Loss: 0.5275
Epoch [54/250], Train Loss: 0.5170, Validation Loss: 0.4994
Epoch [55/250], Train Loss: 0.5404, Validation Loss: 0.5379
Epoch [56/250], Train Loss: 0.5312, Validation Loss: 0.5127
Epoch [57/250], Train Loss: 0.5191, Validation Loss: 0.5232
Epoch [58/250], Train Loss: 0.5190, Validation Loss: 0.5176
Epoch [59/250], Train Loss: 0.5298, Validation Loss: 0.5152
Epoch [60/250], Train Loss: 0.5133, Validation Loss: 0.5033
Epoch [61/250], Train Loss: 0.5182, Validation Loss: 0.5143
Epoch [62/250], Train Loss: 0.4973, Validation Loss: 0.5125
Epoch [63/250], Train Loss: 0.4939, Validation Loss: 0.5033
Epoch [64/250], Train Loss: 0.5047, Validation Loss: 0.4816
Epoch [65/250], Train Loss: 0.4914, Validation Loss: 0.4874
Epoch [66/250], Train Loss: 0.4994, Validation Loss: 0.4917
Epoch [67/250], Train Loss: 0.4937, Validation Loss: 0.5069
Epoch [68/250], Train Loss: 0.4971, Validation Loss: 0.4993
Epoch [69/250], Train Loss: 0.5067, Validation Loss: 0.5028
Epoch [70/250], Train Loss: 0.4927, Validation Loss: 0.4954
Epoch [71/250], Train Loss: 0.5057, Validation Loss: 0.5024
Epoch [72/250], Train Loss: 0.5036, Validation Loss: 0.5044
Epoch [73/250], Train Loss: 0.5120, Validation Loss: 0.5044
Epoch [74/250], Train Loss: 0.5002, Validation Loss: 0.4976
Epoch [75/250], Train Loss: 0.4857, Validation Loss: 0.4939
Epoch [76/250], Train Loss: 0.4975, Validation Loss: 0.5211
Epoch [77/250], Train Loss: 0.5190, Validation Loss: 0.5221
Epoch [78/250], Train Loss: 0.5134, Validation Loss: 0.5265
Epoch [79/250], Train Loss: 0.5263, Validation Loss: 0.5050
Epoch [80/250], Train Loss: 0.4896, Validation Loss: 0.5147
Epoch [81/250], Train Loss: 0.4988, Validation Loss: 0.5016
Epoch [82/250], Train Loss: 0.5013, Validation Loss: 0.5157
Epoch [83/250], Train Loss: 0.4928, Validation Loss: 0.5031
Epoch [84/250], Train Loss: 0.5080, Validation Loss: 0.5024
Epoch [85/250], Train Loss: 0.5028, Validation Loss: 0.5309
Epoch [86/250], Train Loss: 0.5442, Validation Loss: 0.5170
Epoch [87/250], Train Loss: 0.5062, Validation Loss: 0.5005
Epoch [88/250], Train Loss: 0.5138, Validation Loss: 0.5102
Epoch [89/250], Train Loss: 0.4897, Validation Loss: 0.5082
Epoch [90/250], Train Loss: 0.5142, Validation Loss: 0.5023
Epoch [91/250], Train Loss: 0.5050, Validation Loss: 0.5096
Epoch [92/250], Train Loss: 0.4939, Validation Loss: 0.5065
Epoch [93/250], Train Loss: 0.4983, Validation Loss: 0.4897
Epoch [94/250], Train Loss: 0.5092, Validation Loss: 0.4984
Epoch [95/250], Train Loss: 0.4911, Validation Loss: 0.5080
Epoch [96/250], Train Loss: 0.4928, Validation Loss: 0.5038
Epoch [97/250], Train Loss: 0.5128, Validation Loss: 0.4997
Epoch [98/250], Train Loss: 0.5085, Validation Loss: 0.4942
Epoch [99/250], Train Loss: 0.4999, Validation Loss: 0.5090
Epoch [100/250], Train Loss: 0.4972, Validation Loss: 0.4824
Epoch [101/250], Train Loss: 0.4997, Validation Loss: 0.4992
Epoch [102/250], Train Loss: 0.5019, Validation Loss: 0.4919
Epoch [103/250], Train Loss: 0.4952, Validation Loss: 0.4783
Epoch [104/250], Train Loss: 0.4856, Validation Loss: 0.5217
Epoch [105/250], Train Loss: 0.4875, Validation Loss: 0.4979
Epoch [106/250], Train Loss: 0.5042, Validation Loss: 0.5115
Epoch [107/250], Train Loss: 0.4953, Validation Loss: 0.4858
Epoch [108/250], Train Loss: 0.5049, Validation Loss: 0.4936
Epoch [109/250], Train Loss: 0.5084, Validation Loss: 0.5123
Epoch [110/250], Train Loss: 0.4989, Validation Loss: 0.5057
Epoch [111/250], Train Loss: 0.4899, Validation Loss: 0.5044
Epoch [112/250], Train Loss: 0.5122, Validation Loss: 0.5029
Epoch [113/250], Train Loss: 0.5005, Validation Loss: 0.5109
Epoch [114/250], Train Loss: 0.4899, Validation Loss: 0.4996
Epoch [115/250], Train Loss: 0.4870, Validation Loss: 0.5070
Epoch [116/250], Train Loss: 0.5058, Validation Loss: 0.5031
Epoch [117/250], Train Loss: 0.4922, Validation Loss: 0.5260
Epoch [118/250], Train Loss: 0.4884, Validation Loss: 0.5101
Epoch [119/250], Train Loss: 0.4924, Validation Loss: 0.5129
Epoch [120/250], Train Loss: 0.4971, Validation Loss: 0.5079
Epoch [121/250], Train Loss: 0.4931, Validation Loss: 0.4979
Epoch [122/250], Train Loss: 0.4931, Validation Loss: 0.4933
Epoch [123/250], Train Loss: 0.4890, Validation Loss: 0.4933
Epoch [124/250], Train Loss: 0.5003, Validation Loss: 0.5047
Epoch [125/250], Train Loss: 0.4867, Validation Loss: 0.5105
Epoch [126/250], Train Loss: 0.5017, Validation Loss: 0.4937
Epoch [127/250], Train Loss: 0.4811, Validation Loss: 0.5015
Epoch [128/250], Train Loss: 0.5040, Validation Loss: 0.4899
Epoch [129/250], Train Loss: 0.5027, Validation Loss: 0.4949
Epoch [130/250], Train Loss: 0.5118, Validation Loss: 0.5010
Epoch [131/250], Train Loss: 0.5028, Validation Loss: 0.5026
Epoch [132/250], Train Loss: 0.5280, Validation Loss: 0.5004
Epoch [133/250], Train Loss: 0.4959, Validation Loss: 0.5154
Epoch [134/250], Train Loss: 0.5072, Validation Loss: 0.4842
Epoch [135/250], Train Loss: 0.4989, Validation Loss: 0.4981
Epoch [136/250], Train Loss: 0.4976, Validation Loss: 0.4959
Epoch [137/250], Train Loss: 0.4945, Validation Loss: 0.4842
Epoch [138/250], Train Loss: 0.4987, Validation Loss: 0.4851
Epoch [139/250], Train Loss: 0.4982, Validation Loss: 0.5039
Epoch [140/250], Train Loss: 0.4905, Validation Loss: 0.4979
Epoch [141/250], Train Loss: 0.4774, Validation Loss: 0.5121
Epoch [142/250], Train Loss: 0.5137, Validation Loss: 0.4994
Epoch [143/250], Train Loss: 0.4846, Validation Loss: 0.5035
Epoch [144/250], Train Loss: 0.5087, Validation Loss: 0.4941
Epoch [145/250], Train Loss: 0.4900, Validation Loss: 0.4978
Epoch [146/250], Train Loss: 0.4914, Validation Loss: 0.5091
Epoch [147/250], Train Loss: 0.5268, Validation Loss: 0.5108
Epoch [148/250], Train Loss: 0.4937, Validation Loss: 0.5049
Epoch [149/250], Train Loss: 0.5020, Validation Loss: 0.5065
Epoch [150/250], Train Loss: 0.5050, Validation Loss: 0.4989
Epoch [151/250], Train Loss: 0.5010, Validation Loss: 0.5077
Epoch [152/250], Train Loss: 0.5086, Validation Loss: 0.4786
Epoch [153/250], Train Loss: 0.4883, Validation Loss: 0.5107
Epoch [154/250], Train Loss: 0.5073, Validation Loss: 0.4859
Epoch [155/250], Train Loss: 0.5118, Validation Loss: 0.5025
Epoch [156/250], Train Loss: 0.4857, Validation Loss: 0.4791
Epoch [157/250], Train Loss: 0.5152, Validation Loss: 0.5141
Epoch [158/250], Train Loss: 0.4973, Validation Loss: 0.4990
Epoch [159/250], Train Loss: 0.4970, Validation Loss: 0.4921
Epoch [160/250], Train Loss: 0.5100, Validation Loss: 0.4964
Epoch [161/250], Train Loss: 0.4914, Validation Loss: 0.5091
Epoch [162/250], Train Loss: 0.4949, Validation Loss: 0.5302
Epoch [163/250], Train Loss: 0.5090, Validation Loss: 0.4873
Epoch [164/250], Train Loss: 0.5002, Validation Loss: 0.4990
Epoch [165/250], Train Loss: 0.4952, Validation Loss: 0.4985
Epoch [166/250], Train Loss: 0.4821, Validation Loss: 0.4986
Epoch [167/250], Train Loss: 0.5121, Validation Loss: 0.4881
Epoch [168/250], Train Loss: 0.5115, Validation Loss: 0.5073
Epoch [169/250], Train Loss: 0.5312, Validation Loss: 0.5185
Epoch [170/250], Train Loss: 0.5201, Validation Loss: 0.5282
Epoch [171/250], Train Loss: 0.5005, Validation Loss: 0.4940
Epoch [172/250], Train Loss: 0.5118, Validation Loss: 0.5204
Epoch [173/250], Train Loss: 0.5025, Validation Loss: 0.4956
Epoch [174/250], Train Loss: 0.5040, Validation Loss: 0.5030
Epoch [175/250], Train Loss: 0.4931, Validation Loss: 0.4872
Epoch [176/250], Train Loss: 0.5095, Validation Loss: 0.5110
Epoch [177/250], Train Loss: 0.5033, Validation Loss: 0.4935
Epoch [178/250], Train Loss: 0.5022, Validation Loss: 0.5208
Epoch [179/250], Train Loss: 0.5166, Validation Loss: 0.4945
Epoch [180/250], Train Loss: 0.5076, Validation Loss: 0.5293
Epoch [181/250], Train Loss: 0.5165, Validation Loss: 0.4997
Epoch [182/250], Train Loss: 0.4919, Validation Loss: 0.4865
Epoch [183/250], Train Loss: 0.5095, Validation Loss: 0.4943
Epoch [184/250], Train Loss: 0.5067, Validation Loss: 0.5070
Epoch [185/250], Train Loss: 0.4968, Validation Loss: 0.5126
Epoch [186/250], Train Loss: 0.5159, Validation Loss: 0.4980
Epoch [187/250], Train Loss: 0.5051, Validation Loss: 0.5060
Epoch [188/250], Train Loss: 0.5007, Validation Loss: 0.5007
Epoch [189/250], Train Loss: 0.4886, Validation Loss: 0.4847
Epoch [190/250], Train Loss: 0.5085, Validation Loss: 0.4979
Epoch [191/250], Train Loss: 0.4865, Validation Loss: 0.5036
Epoch [192/250], Train Loss: 0.4965, Validation Loss: 0.5100
Epoch [193/250], Train Loss: 0.4876, Validation Loss: 0.4862
Epoch [194/250], Train Loss: 0.4932, Validation Loss: 0.4889
Epoch [195/250], Train Loss: 0.5113, Validation Loss: 0.4958
Epoch [196/250], Train Loss: 0.4893, Validation Loss: 0.5021
Epoch [197/250], Train Loss: 0.5021, Validation Loss: 0.4946
Epoch [198/250], Train Loss: 0.5077, Validation Loss: 0.4929
Epoch [199/250], Train Loss: 0.5040, Validation Loss: 0.4978
Epoch [200/250], Train Loss: 0.4897, Validation Loss: 0.5061
Epoch [201/250], Train Loss: 0.5035, Validation Loss: 0.4939
Epoch [202/250], Train Loss: 0.4912, Validation Loss: 0.5142
Epoch [203/250], Train Loss: 0.5113, Validation Loss: 0.5009
Epoch [204/250], Train Loss: 0.4964, Validation Loss: 0.4996
Epoch [205/250], Train Loss: 0.5009, Validation Loss: 0.5006
Epoch [206/250], Train Loss: 0.4862, Validation Loss: 0.5259
Epoch [207/250], Train Loss: 0.4942, Validation Loss: 0.5177
Epoch [208/250], Train Loss: 0.5009, Validation Loss: 0.5014
Epoch [209/250], Train Loss: 0.4870, Validation Loss: 0.5076
Epoch [210/250], Train Loss: 0.5075, Validation Loss: 0.4963
Epoch [211/250], Train Loss: 0.4876, Validation Loss: 0.5018
Epoch [212/250], Train Loss: 0.4893, Validation Loss: 0.4855
Epoch [213/250], Train Loss: 0.4890, Validation Loss: 0.5150
Epoch [214/250], Train Loss: 0.4974, Validation Loss: 0.5024
Epoch [215/250], Train Loss: 0.4799, Validation Loss: 0.4776
Epoch [216/250], Train Loss: 0.5176, Validation Loss: 0.4841
Epoch [217/250], Train Loss: 0.5068, Validation Loss: 0.5008
Epoch [218/250], Train Loss: 0.5108, Validation Loss: 0.4994
Epoch [219/250], Train Loss: 0.4865, Validation Loss: 0.4976
Epoch [220/250], Train Loss: 0.4719, Validation Loss: 0.4767
Epoch [221/250], Train Loss: 0.4987, Validation Loss: 0.4931
Epoch [222/250], Train Loss: 0.5063, Validation Loss: 0.4858
Epoch [223/250], Train Loss: 0.5010, Validation Loss: 0.4993
Epoch [224/250], Train Loss: 0.5056, Validation Loss: 0.5156
Epoch [225/250], Train Loss: 0.5139, Validation Loss: 0.5118
Epoch [226/250], Train Loss: 0.4937, Validation Loss: 0.4791
Epoch [227/250], Train Loss: 0.4763, Validation Loss: 0.4873
Epoch [228/250], Train Loss: 0.5104, Validation Loss: 0.4859
Epoch [229/250], Train Loss: 0.5033, Validation Loss: 0.4924
Epoch [230/250], Train Loss: 0.5052, Validation Loss: 0.4825
Epoch [231/250], Train Loss: 0.4790, Validation Loss: 0.5023
Epoch [232/250], Train Loss: 0.4981, Validation Loss: 0.4942
Epoch [233/250], Train Loss: 0.4853, Validation Loss: 0.5041
Epoch [234/250], Train Loss: 0.4949, Validation Loss: 0.4988
Epoch [235/250], Train Loss: 0.5130, Validation Loss: 0.5011
Epoch [236/250], Train Loss: 0.4800, Validation Loss: 0.4997
Epoch [237/250], Train Loss: 0.4935, Validation Loss: 0.5071
Epoch [238/250], Train Loss: 0.4816, Validation Loss: 0.5062
Epoch [239/250], Train Loss: 0.5204, Validation Loss: 0.5049
Epoch [240/250], Train Loss: 0.5117, Validation Loss: 0.4930
Epoch [241/250], Train Loss: 0.4986, Validation Loss: 0.4964
Epoch [242/250], Train Loss: 0.5091, Validation Loss: 0.5021
Epoch [243/250], Train Loss: 0.4907, Validation Loss: 0.4834
Epoch [244/250], Train Loss: 0.4958, Validation Loss: 0.5063
Epoch [245/250], Train Loss: 0.4951, Validation Loss: 0.5213
Epoch [246/250], Train Loss: 0.5159, Validation Loss: 0.5020
Epoch [247/250], Train Loss: 0.4780, Validation Loss: 0.5190
Epoch [248/250], Train Loss: 0.5140, Validation Loss: 0.4943
Epoch [249/250], Train Loss: 0.4889, Validation Loss: 0.4916
Epoch [250/250], Train Loss: 0.4912, Validation Loss: 0.4954

Finished Training in 79.5

Noise Sigma:  1.5025
Creating datasets...
Start training...
Epoch [1/250], Train Loss: 0.6460, Validation Loss: 0.6041
Epoch [2/250], Train Loss: 0.6005, Validation Loss: 0.5943
Epoch [3/250], Train Loss: 0.5933, Validation Loss: 0.5986
Epoch [4/250], Train Loss: 0.6001, Validation Loss: 0.5821
Epoch [5/250], Train Loss: 0.5936, Validation Loss: 0.5981
Epoch [6/250], Train Loss: 0.5855, Validation Loss: 0.6023
Epoch [7/250], Train Loss: 0.5983, Validation Loss: 0.5860
Epoch [8/250], Train Loss: 0.6070, Validation Loss: 0.6035
Epoch [9/250], Train Loss: 0.5976, Validation Loss: 0.5936
Epoch [10/250], Train Loss: 0.5957, Validation Loss: 0.5905
Epoch [11/250], Train Loss: 0.5953, Validation Loss: 0.5861
Epoch [12/250], Train Loss: 0.5930, Validation Loss: 0.5969
Epoch [13/250], Train Loss: 0.5985, Validation Loss: 0.6031
Epoch [14/250], Train Loss: 0.5988, Validation Loss: 0.6093
Epoch [15/250], Train Loss: 0.5915, Validation Loss: 0.6167
Epoch [16/250], Train Loss: 0.5821, Validation Loss: 0.6022
Epoch [17/250], Train Loss: 0.6092, Validation Loss: 0.5949
Epoch [18/250], Train Loss: 0.5901, Validation Loss: 0.6078
Epoch [19/250], Train Loss: 0.6034, Validation Loss: 0.5967
Epoch [20/250], Train Loss: 0.6033, Validation Loss: 0.5942
Epoch [21/250], Train Loss: 0.6077, Validation Loss: 0.5967
Epoch [22/250], Train Loss: 0.5848, Validation Loss: 0.5900
Epoch [23/250], Train Loss: 0.5968, Validation Loss: 0.5918
Epoch [24/250], Train Loss: 0.6028, Validation Loss: 0.5948
Epoch [25/250], Train Loss: 0.5939, Validation Loss: 0.5908
Epoch [26/250], Train Loss: 0.6017, Validation Loss: 0.6020
Epoch [27/250], Train Loss: 0.5957, Validation Loss: 0.5909
Epoch [28/250], Train Loss: 0.5898, Validation Loss: 0.5943
Epoch [29/250], Train Loss: 0.6029, Validation Loss: 0.5862
Epoch [30/250], Train Loss: 0.5934, Validation Loss: 0.6049
Epoch [31/250], Train Loss: 0.5779, Validation Loss: 0.5841
Epoch [32/250], Train Loss: 0.5794, Validation Loss: 0.5971
Epoch [33/250], Train Loss: 0.5986, Validation Loss: 0.6002
Epoch [34/250], Train Loss: 0.5900, Validation Loss: 0.6132
Epoch [35/250], Train Loss: 0.5862, Validation Loss: 0.5970
Epoch [36/250], Train Loss: 0.5925, Validation Loss: 0.5917
Epoch [37/250], Train Loss: 0.6054, Validation Loss: 0.6063
Epoch [38/250], Train Loss: 0.5984, Validation Loss: 0.5881
Epoch [39/250], Train Loss: 0.5874, Validation Loss: 0.6022
Epoch [40/250], Train Loss: 0.6044, Validation Loss: 0.5921
Epoch [41/250], Train Loss: 0.5856, Validation Loss: 0.5940
Epoch [42/250], Train Loss: 0.5990, Validation Loss: 0.5835
Epoch [43/250], Train Loss: 0.5769, Validation Loss: 0.6066
Epoch [44/250], Train Loss: 0.6005, Validation Loss: 0.5901
Epoch [45/250], Train Loss: 0.5898, Validation Loss: 0.5895
Epoch [46/250], Train Loss: 0.5859, Validation Loss: 0.5918
Epoch [47/250], Train Loss: 0.6007, Validation Loss: 0.5921
Epoch [48/250], Train Loss: 0.6061, Validation Loss: 0.6150
Epoch [49/250], Train Loss: 0.5927, Validation Loss: 0.5951
Epoch [50/250], Train Loss: 0.5858, Validation Loss: 0.6122
Epoch [51/250], Train Loss: 0.6132, Validation Loss: 0.6011
Epoch [52/250], Train Loss: 0.5889, Validation Loss: 0.6124
Epoch [53/250], Train Loss: 0.5923, Validation Loss: 0.6073
Epoch [54/250], Train Loss: 0.6018, Validation Loss: 0.5999
Epoch [55/250], Train Loss: 0.5863, Validation Loss: 0.5946
Epoch [56/250], Train Loss: 0.6081, Validation Loss: 0.5981
Epoch [57/250], Train Loss: 0.6063, Validation Loss: 0.6056
Epoch [58/250], Train Loss: 0.6097, Validation Loss: 0.5864
Epoch [59/250], Train Loss: 0.6033, Validation Loss: 0.5893
Epoch [60/250], Train Loss: 0.5841, Validation Loss: 0.6011
Epoch [61/250], Train Loss: 0.5987, Validation Loss: 0.5930
Epoch [62/250], Train Loss: 0.5858, Validation Loss: 0.5891
Epoch [63/250], Train Loss: 0.5955, Validation Loss: 0.5915
Epoch [64/250], Train Loss: 0.5773, Validation Loss: 0.5976
Epoch [65/250], Train Loss: 0.5981, Validation Loss: 0.6094
Epoch [66/250], Train Loss: 0.6014, Validation Loss: 0.5945
Epoch [67/250], Train Loss: 0.5825, Validation Loss: 0.6048
Epoch [68/250], Train Loss: 0.6015, Validation Loss: 0.5931
Epoch [69/250], Train Loss: 0.5957, Validation Loss: 0.5978
Epoch [70/250], Train Loss: 0.5899, Validation Loss: 0.5943
Epoch [71/250], Train Loss: 0.5977, Validation Loss: 0.5977
Epoch [72/250], Train Loss: 0.5833, Validation Loss: 0.5946
Epoch [73/250], Train Loss: 0.5866, Validation Loss: 0.5888
Epoch [74/250], Train Loss: 0.5884, Validation Loss: 0.5871
Epoch [75/250], Train Loss: 0.5975, Validation Loss: 0.5883
Epoch [76/250], Train Loss: 0.5946, Validation Loss: 0.5879
Epoch [77/250], Train Loss: 0.5950, Validation Loss: 0.5887
Epoch [78/250], Train Loss: 0.5903, Validation Loss: 0.5937
Epoch [79/250], Train Loss: 0.5862, Validation Loss: 0.5861
Epoch [80/250], Train Loss: 0.5782, Validation Loss: 0.5972
Epoch [81/250], Train Loss: 0.5874, Validation Loss: 0.5891
Epoch [82/250], Train Loss: 0.5957, Validation Loss: 0.5891
Epoch [83/250], Train Loss: 0.5933, Validation Loss: 0.5929
Epoch [84/250], Train Loss: 0.5953, Validation Loss: 0.5888
Epoch [85/250], Train Loss: 0.5943, Validation Loss: 0.5982
Epoch [86/250], Train Loss: 0.5978, Validation Loss: 0.5799
Epoch [87/250], Train Loss: 0.5745, Validation Loss: 0.5909
Epoch [88/250], Train Loss: 0.5983, Validation Loss: 0.6007
Epoch [89/250], Train Loss: 0.5811, Validation Loss: 0.5908
Epoch [90/250], Train Loss: 0.5852, Validation Loss: 0.5888
Epoch [91/250], Train Loss: 0.6132, Validation Loss: 0.5884
Epoch [92/250], Train Loss: 0.5930, Validation Loss: 0.6060
Epoch [93/250], Train Loss: 0.5938, Validation Loss: 0.5873
Epoch [94/250], Train Loss: 0.5868, Validation Loss: 0.5938
Epoch [95/250], Train Loss: 0.5981, Validation Loss: 0.5997
Epoch [96/250], Train Loss: 0.6003, Validation Loss: 0.5938
Epoch [97/250], Train Loss: 0.6209, Validation Loss: 0.5821
Epoch [98/250], Train Loss: 0.5992, Validation Loss: 0.6006
Epoch [99/250], Train Loss: 0.6143, Validation Loss: 0.5868
Epoch [100/250], Train Loss: 0.6070, Validation Loss: 0.5869
Epoch [101/250], Train Loss: 0.5903, Validation Loss: 0.5878
Epoch [102/250], Train Loss: 0.5908, Validation Loss: 0.5951
Epoch [103/250], Train Loss: 0.5868, Validation Loss: 0.5979
Epoch [104/250], Train Loss: 0.5909, Validation Loss: 0.5998
Epoch [105/250], Train Loss: 0.6048, Validation Loss: 0.5976
Epoch [106/250], Train Loss: 0.6253, Validation Loss: 0.6040
Epoch [107/250], Train Loss: 0.6031, Validation Loss: 0.6218
Epoch [108/250], Train Loss: 0.6287, Validation Loss: 0.5978
Epoch [109/250], Train Loss: 0.6049, Validation Loss: 0.6098
Epoch [110/250], Train Loss: 0.6184, Validation Loss: 0.5902
Epoch [111/250], Train Loss: 0.5954, Validation Loss: 0.5998
Epoch [112/250], Train Loss: 0.5982, Validation Loss: 0.5952
Epoch [113/250], Train Loss: 0.5851, Validation Loss: 0.5841
Epoch [114/250], Train Loss: 0.5976, Validation Loss: 0.5940
Epoch [115/250], Train Loss: 0.5945, Validation Loss: 0.5913
Epoch [116/250], Train Loss: 0.5832, Validation Loss: 0.6066
Epoch [117/250], Train Loss: 0.5893, Validation Loss: 0.5948
Epoch [118/250], Train Loss: 0.5869, Validation Loss: 0.5929
Epoch [119/250], Train Loss: 0.5914, Validation Loss: 0.5971
Epoch [120/250], Train Loss: 0.5991, Validation Loss: 0.5917
Epoch [121/250], Train Loss: 0.5955, Validation Loss: 0.6038
Epoch [122/250], Train Loss: 0.6030, Validation Loss: 0.5961
Epoch [123/250], Train Loss: 0.6045, Validation Loss: 0.5875
Epoch [124/250], Train Loss: 0.6023, Validation Loss: 0.5944
Epoch [125/250], Train Loss: 0.5918, Validation Loss: 0.6052
Epoch [126/250], Train Loss: 0.5984, Validation Loss: 0.5920
Epoch [127/250], Train Loss: 0.5948, Validation Loss: 0.5969
Epoch [128/250], Train Loss: 0.5743, Validation Loss: 0.5919
Epoch [129/250], Train Loss: 0.5902, Validation Loss: 0.6038
Epoch [130/250], Train Loss: 0.6092, Validation Loss: 0.5961
Epoch [131/250], Train Loss: 0.5961, Validation Loss: 0.5877
Epoch [132/250], Train Loss: 0.5847, Validation Loss: 0.5970
Epoch [133/250], Train Loss: 0.5966, Validation Loss: 0.5868
Epoch [134/250], Train Loss: 0.5825, Validation Loss: 0.5769
Epoch [135/250], Train Loss: 0.5822, Validation Loss: 0.5891
Epoch [136/250], Train Loss: 0.5968, Validation Loss: 0.6048
Epoch [137/250], Train Loss: 0.5794, Validation Loss: 0.6006
Epoch [138/250], Train Loss: 0.5924, Validation Loss: 0.5903
Epoch [139/250], Train Loss: 0.5935, Validation Loss: 0.5960
Epoch [140/250], Train Loss: 0.5955, Validation Loss: 0.5807
Epoch [141/250], Train Loss: 0.5912, Validation Loss: 0.5861
Epoch [142/250], Train Loss: 0.5885, Validation Loss: 0.5862
Epoch [143/250], Train Loss: 0.5829, Validation Loss: 0.5949
Epoch [144/250], Train Loss: 0.5974, Validation Loss: 0.5832
Epoch [145/250], Train Loss: 0.5788, Validation Loss: 0.5902
Epoch [146/250], Train Loss: 0.5810, Validation Loss: 0.5936
Epoch [147/250], Train Loss: 0.5995, Validation Loss: 0.5916
Epoch [148/250], Train Loss: 0.5808, Validation Loss: 0.5919
Epoch [149/250], Train Loss: 0.5947, Validation Loss: 0.5965
Epoch [150/250], Train Loss: 0.5853, Validation Loss: 0.5987
Epoch [151/250], Train Loss: 0.5860, Validation Loss: 0.5875
Epoch [152/250], Train Loss: 0.5915, Validation Loss: 0.5800
Epoch [153/250], Train Loss: 0.5883, Validation Loss: 0.5923
Epoch [154/250], Train Loss: 0.5975, Validation Loss: 0.6092
Epoch [155/250], Train Loss: 0.5904, Validation Loss: 0.5947
Epoch [156/250], Train Loss: 0.5934, Validation Loss: 0.5923
Epoch [157/250], Train Loss: 0.5901, Validation Loss: 0.5781
Epoch [158/250], Train Loss: 0.5871, Validation Loss: 0.5840
Epoch [159/250], Train Loss: 0.5861, Validation Loss: 0.5900
Epoch [160/250], Train Loss: 0.5926, Validation Loss: 0.5857
Epoch [161/250], Train Loss: 0.6009, Validation Loss: 0.6059
Epoch [162/250], Train Loss: 0.5918, Validation Loss: 0.5759
Epoch [163/250], Train Loss: 0.5855, Validation Loss: 0.5854
Epoch [164/250], Train Loss: 0.5984, Validation Loss: 0.5936
Epoch [165/250], Train Loss: 0.5913, Validation Loss: 0.5930
Epoch [166/250], Train Loss: 0.5963, Validation Loss: 0.5849
Epoch [167/250], Train Loss: 0.5896, Validation Loss: 0.5849
Epoch [168/250], Train Loss: 0.5866, Validation Loss: 0.5998
Epoch [169/250], Train Loss: 0.5841, Validation Loss: 0.5833
Epoch [170/250], Train Loss: 0.5934, Validation Loss: 0.5855
Epoch [171/250], Train Loss: 0.5866, Validation Loss: 0.5929
Epoch [172/250], Train Loss: 0.5876, Validation Loss: 0.5986
Epoch [173/250], Train Loss: 0.5905, Validation Loss: 0.5998
Epoch [174/250], Train Loss: 0.5871, Validation Loss: 0.5926
Epoch [175/250], Train Loss: 0.5990, Validation Loss: 0.5858
Epoch [176/250], Train Loss: 0.5822, Validation Loss: 0.5853
Epoch [177/250], Train Loss: 0.5899, Validation Loss: 0.5927
Epoch [178/250], Train Loss: 0.5858, Validation Loss: 0.5922
Epoch [179/250], Train Loss: 0.5924, Validation Loss: 0.5867
Epoch [180/250], Train Loss: 0.5944, Validation Loss: 0.5813
Epoch [181/250], Train Loss: 0.5942, Validation Loss: 0.5952
Epoch [182/250], Train Loss: 0.5948, Validation Loss: 0.5930
Epoch [183/250], Train Loss: 0.5917, Validation Loss: 0.5811
Epoch [184/250], Train Loss: 0.5884, Validation Loss: 0.5960
Epoch [185/250], Train Loss: 0.5950, Validation Loss: 0.5875
Epoch [186/250], Train Loss: 0.5856, Validation Loss: 0.5832
Epoch [187/250], Train Loss: 0.5861, Validation Loss: 0.6021
Epoch [188/250], Train Loss: 0.5836, Validation Loss: 0.5873
Epoch [189/250], Train Loss: 0.5895, Validation Loss: 0.5970
Epoch [190/250], Train Loss: 0.6062, Validation Loss: 0.5804
Epoch [191/250], Train Loss: 0.5922, Validation Loss: 0.5963
Epoch [192/250], Train Loss: 0.6004, Validation Loss: 0.5737
Epoch [193/250], Train Loss: 0.5888, Validation Loss: 0.6002
Epoch [194/250], Train Loss: 0.5962, Validation Loss: 0.5953
Epoch [195/250], Train Loss: 0.6008, Validation Loss: 0.5886
Epoch [196/250], Train Loss: 0.5918, Validation Loss: 0.5981
Epoch [197/250], Train Loss: 0.5916, Validation Loss: 0.5841
Epoch [198/250], Train Loss: 0.5902, Validation Loss: 0.5753
Epoch [199/250], Train Loss: 0.5947, Validation Loss: 0.5849
Epoch [200/250], Train Loss: 0.5914, Validation Loss: 0.5994
Epoch [201/250], Train Loss: 0.5947, Validation Loss: 0.5911
Epoch [202/250], Train Loss: 0.5889, Validation Loss: 0.6051
Epoch [203/250], Train Loss: 0.5912, Validation Loss: 0.6012
Epoch [204/250], Train Loss: 0.5780, Validation Loss: 0.5944
Epoch [205/250], Train Loss: 0.5976, Validation Loss: 0.5958
Epoch [206/250], Train Loss: 0.5873, Validation Loss: 0.5918
Epoch [207/250], Train Loss: 0.5949, Validation Loss: 0.5795
Epoch [208/250], Train Loss: 0.5809, Validation Loss: 0.6056
Epoch [209/250], Train Loss: 0.5872, Validation Loss: 0.6007
Epoch [210/250], Train Loss: 0.5796, Validation Loss: 0.5915
Epoch [211/250], Train Loss: 0.5915, Validation Loss: 0.5995
Epoch [212/250], Train Loss: 0.5887, Validation Loss: 0.5879
Epoch [213/250], Train Loss: 0.5950, Validation Loss: 0.5872
Epoch [214/250], Train Loss: 0.5891, Validation Loss: 0.5823
Epoch [215/250], Train Loss: 0.5896, Validation Loss: 0.5987
Epoch [216/250], Train Loss: 0.5860, Validation Loss: 0.5982
Epoch [217/250], Train Loss: 0.5899, Validation Loss: 0.5801
Epoch [218/250], Train Loss: 0.5857, Validation Loss: 0.6025
Epoch [219/250], Train Loss: 0.5998, Validation Loss: 0.5844
Epoch [220/250], Train Loss: 0.5808, Validation Loss: 0.5989
Epoch [221/250], Train Loss: 0.5793, Validation Loss: 0.5807
Epoch [222/250], Train Loss: 0.5869, Validation Loss: 0.5940
Epoch [223/250], Train Loss: 0.5970, Validation Loss: 0.5902
Epoch [224/250], Train Loss: 0.6013, Validation Loss: 0.5910
Epoch [225/250], Train Loss: 0.5936, Validation Loss: 0.5891
Epoch [226/250], Train Loss: 0.5834, Validation Loss: 0.5955
Epoch [227/250], Train Loss: 0.5969, Validation Loss: 0.5893
Epoch [228/250], Train Loss: 0.5876, Validation Loss: 0.5781
Epoch [229/250], Train Loss: 0.5892, Validation Loss: 0.5864
Epoch [230/250], Train Loss: 0.5886, Validation Loss: 0.6006
Epoch [231/250], Train Loss: 0.5830, Validation Loss: 0.5821
Epoch [232/250], Train Loss: 0.5869, Validation Loss: 0.5941
Epoch [233/250], Train Loss: 0.6016, Validation Loss: 0.5919
Epoch [234/250], Train Loss: 0.5988, Validation Loss: 0.5945
Epoch [235/250], Train Loss: 0.6012, Validation Loss: 0.5936
Epoch [236/250], Train Loss: 0.5863, Validation Loss: 0.5985
Epoch [237/250], Train Loss: 0.5766, Validation Loss: 0.5954
Epoch [238/250], Train Loss: 0.5960, Validation Loss: 0.5776
Epoch [239/250], Train Loss: 0.6075, Validation Loss: 0.5940
Epoch [240/250], Train Loss: 0.5886, Validation Loss: 0.5875
Epoch [241/250], Train Loss: 0.5868, Validation Loss: 0.5958
Epoch [242/250], Train Loss: 0.6127, Validation Loss: 0.5894
Epoch [243/250], Train Loss: 0.5931, Validation Loss: 0.5888
Epoch [244/250], Train Loss: 0.5860, Validation Loss: 0.5878
Epoch [245/250], Train Loss: 0.6145, Validation Loss: 0.5867
Epoch [246/250], Train Loss: 0.5867, Validation Loss: 0.6111
Epoch [247/250], Train Loss: 0.5826, Validation Loss: 0.5756
Epoch [248/250], Train Loss: 0.5993, Validation Loss: 0.5948
Epoch [249/250], Train Loss: 0.6022, Validation Loss: 0.5976
Epoch [250/250], Train Loss: 0.5745, Validation Loss: 0.6106

Finished Training in 80.1

Noise Sigma:  2.0
Creating datasets...
Start training...
Epoch [1/250], Train Loss: 0.6631, Validation Loss: 0.6299
Epoch [2/250], Train Loss: 0.6360, Validation Loss: 0.6270
Epoch [3/250], Train Loss: 0.6472, Validation Loss: 0.6407
Epoch [4/250], Train Loss: 0.6352, Validation Loss: 0.6324
Epoch [5/250], Train Loss: 0.6334, Validation Loss: 0.6344
Epoch [6/250], Train Loss: 0.6238, Validation Loss: 0.6220
Epoch [7/250], Train Loss: 0.6335, Validation Loss: 0.6339
Epoch [8/250], Train Loss: 0.6235, Validation Loss: 0.6339
Epoch [9/250], Train Loss: 0.6380, Validation Loss: 0.6275
Epoch [10/250], Train Loss: 0.6413, Validation Loss: 0.6453
Epoch [11/250], Train Loss: 0.6320, Validation Loss: 0.6395
Epoch [12/250], Train Loss: 0.6259, Validation Loss: 0.6262
Epoch [13/250], Train Loss: 0.6381, Validation Loss: 0.6365
Epoch [14/250], Train Loss: 0.6492, Validation Loss: 0.6254
Epoch [15/250], Train Loss: 0.6318, Validation Loss: 0.6266
Epoch [16/250], Train Loss: 0.6339, Validation Loss: 0.6188
Epoch [17/250], Train Loss: 0.6322, Validation Loss: 0.6325
Epoch [18/250], Train Loss: 0.6321, Validation Loss: 0.6311
Epoch [19/250], Train Loss: 0.6312, Validation Loss: 0.6340
Epoch [20/250], Train Loss: 0.6244, Validation Loss: 0.6304
Epoch [21/250], Train Loss: 0.6430, Validation Loss: 0.6255
Epoch [22/250], Train Loss: 0.6216, Validation Loss: 0.6489
Epoch [23/250], Train Loss: 0.6389, Validation Loss: 0.6285
Epoch [24/250], Train Loss: 0.6339, Validation Loss: 0.6254
Epoch [25/250], Train Loss: 0.6357, Validation Loss: 0.6198
Epoch [26/250], Train Loss: 0.6253, Validation Loss: 0.6380
Epoch [27/250], Train Loss: 0.6347, Validation Loss: 0.6353
Epoch [28/250], Train Loss: 0.6306, Validation Loss: 0.6198
Epoch [29/250], Train Loss: 0.6345, Validation Loss: 0.6405
Epoch [30/250], Train Loss: 0.6357, Validation Loss: 0.6124
Epoch [31/250], Train Loss: 0.6420, Validation Loss: 0.6331
Epoch [32/250], Train Loss: 0.6222, Validation Loss: 0.6346
Epoch [33/250], Train Loss: 0.6422, Validation Loss: 0.6295
Epoch [34/250], Train Loss: 0.6291, Validation Loss: 0.6283
Epoch [35/250], Train Loss: 0.6338, Validation Loss: 0.6378
Epoch [36/250], Train Loss: 0.6313, Validation Loss: 0.6298
Epoch [37/250], Train Loss: 0.6168, Validation Loss: 0.6274
Epoch [38/250], Train Loss: 0.6254, Validation Loss: 0.6252
Epoch [39/250], Train Loss: 0.6325, Validation Loss: 0.6233
Epoch [40/250], Train Loss: 0.6312, Validation Loss: 0.6207
Epoch [41/250], Train Loss: 0.6243, Validation Loss: 0.6294
Epoch [42/250], Train Loss: 0.6380, Validation Loss: 0.6269
Epoch [43/250], Train Loss: 0.6347, Validation Loss: 0.6354
Epoch [44/250], Train Loss: 0.6300, Validation Loss: 0.6259
Epoch [45/250], Train Loss: 0.6227, Validation Loss: 0.6261
Epoch [46/250], Train Loss: 0.6296, Validation Loss: 0.6264
Epoch [47/250], Train Loss: 0.6310, Validation Loss: 0.6317
Epoch [48/250], Train Loss: 0.6164, Validation Loss: 0.6229
Epoch [49/250], Train Loss: 0.6327, Validation Loss: 0.6384
Epoch [50/250], Train Loss: 0.6223, Validation Loss: 0.6228
Epoch [51/250], Train Loss: 0.6320, Validation Loss: 0.6314
Epoch [52/250], Train Loss: 0.6360, Validation Loss: 0.6413
Epoch [53/250], Train Loss: 0.6440, Validation Loss: 0.6288
Epoch [54/250], Train Loss: 0.6251, Validation Loss: 0.6268
Epoch [55/250], Train Loss: 0.6257, Validation Loss: 0.6374
Epoch [56/250], Train Loss: 0.6240, Validation Loss: 0.6292
Epoch [57/250], Train Loss: 0.6309, Validation Loss: 0.6180
Epoch [58/250], Train Loss: 0.6274, Validation Loss: 0.6396
Epoch [59/250], Train Loss: 0.6279, Validation Loss: 0.6436
Epoch [60/250], Train Loss: 0.6293, Validation Loss: 0.6365
Epoch [61/250], Train Loss: 0.6491, Validation Loss: 0.6236
Epoch [62/250], Train Loss: 0.6300, Validation Loss: 0.6254
Epoch [63/250], Train Loss: 0.6242, Validation Loss: 0.6272
Epoch [64/250], Train Loss: 0.6319, Validation Loss: 0.6368
Epoch [65/250], Train Loss: 0.6365, Validation Loss: 0.6307
Epoch [66/250], Train Loss: 0.6270, Validation Loss: 0.6481
Epoch [67/250], Train Loss: 0.6342, Validation Loss: 0.6290
Epoch [68/250], Train Loss: 0.6336, Validation Loss: 0.6297
Epoch [69/250], Train Loss: 0.6218, Validation Loss: 0.6321
Epoch [70/250], Train Loss: 0.6390, Validation Loss: 0.6314
Epoch [71/250], Train Loss: 0.6343, Validation Loss: 0.6319
Epoch [72/250], Train Loss: 0.6412, Validation Loss: 0.6232
Epoch [73/250], Train Loss: 0.6362, Validation Loss: 0.6330
Epoch [74/250], Train Loss: 0.6424, Validation Loss: 0.6307
Epoch [75/250], Train Loss: 0.6325, Validation Loss: 0.6238
Epoch [76/250], Train Loss: 0.6270, Validation Loss: 0.6381
Epoch [77/250], Train Loss: 0.6257, Validation Loss: 0.6290
Epoch [78/250], Train Loss: 0.6429, Validation Loss: 0.6261
Epoch [79/250], Train Loss: 0.6383, Validation Loss: 0.6263
Epoch [80/250], Train Loss: 0.6334, Validation Loss: 0.6300
Epoch [81/250], Train Loss: 0.6337, Validation Loss: 0.6331
Epoch [82/250], Train Loss: 0.6329, Validation Loss: 0.6278
Epoch [83/250], Train Loss: 0.6251, Validation Loss: 0.6307
Epoch [84/250], Train Loss: 0.6222, Validation Loss: 0.6271
Epoch [85/250], Train Loss: 0.6378, Validation Loss: 0.6257
Epoch [86/250], Train Loss: 0.6296, Validation Loss: 0.6333
Epoch [87/250], Train Loss: 0.6297, Validation Loss: 0.6368
Epoch [88/250], Train Loss: 0.6385, Validation Loss: 0.6247
Epoch [89/250], Train Loss: 0.6307, Validation Loss: 0.6366
Epoch [90/250], Train Loss: 0.6312, Validation Loss: 0.6327
Epoch [91/250], Train Loss: 0.6266, Validation Loss: 0.6307
Epoch [92/250], Train Loss: 0.6245, Validation Loss: 0.6212
Epoch [93/250], Train Loss: 0.6242, Validation Loss: 0.6225
Epoch [94/250], Train Loss: 0.6213, Validation Loss: 0.6239
Epoch [95/250], Train Loss: 0.6272, Validation Loss: 0.6203
Epoch [96/250], Train Loss: 0.6338, Validation Loss: 0.6355
Epoch [97/250], Train Loss: 0.6170, Validation Loss: 0.6205
Epoch [98/250], Train Loss: 0.6264, Validation Loss: 0.6327
Epoch [99/250], Train Loss: 0.6241, Validation Loss: 0.6255
Epoch [100/250], Train Loss: 0.6298, Validation Loss: 0.6270
Epoch [101/250], Train Loss: 0.6260, Validation Loss: 0.6318
Epoch [102/250], Train Loss: 0.6239, Validation Loss: 0.6280
Epoch [103/250], Train Loss: 0.6343, Validation Loss: 0.6262
Epoch [104/250], Train Loss: 0.6354, Validation Loss: 0.6250
Epoch [105/250], Train Loss: 0.6283, Validation Loss: 0.6226
Epoch [106/250], Train Loss: 0.6305, Validation Loss: 0.6350
Epoch [107/250], Train Loss: 0.6361, Validation Loss: 0.6403
Epoch [108/250], Train Loss: 0.6278, Validation Loss: 0.6308
Epoch [109/250], Train Loss: 0.6263, Validation Loss: 0.6348
Epoch [110/250], Train Loss: 0.6296, Validation Loss: 0.6186
Epoch [111/250], Train Loss: 0.6202, Validation Loss: 0.6434
Epoch [112/250], Train Loss: 0.6395, Validation Loss: 0.6267
Epoch [113/250], Train Loss: 0.6224, Validation Loss: 0.6393
Epoch [114/250], Train Loss: 0.6271, Validation Loss: 0.6281
Epoch [115/250], Train Loss: 0.6324, Validation Loss: 0.6283
Epoch [116/250], Train Loss: 0.6326, Validation Loss: 0.6372
Epoch [117/250], Train Loss: 0.6338, Validation Loss: 0.6383
Epoch [118/250], Train Loss: 0.6388, Validation Loss: 0.6268
Epoch [119/250], Train Loss: 0.6213, Validation Loss: 0.6229
Epoch [120/250], Train Loss: 0.6225, Validation Loss: 0.6256
Epoch [121/250], Train Loss: 0.6200, Validation Loss: 0.6224
Epoch [122/250], Train Loss: 0.6295, Validation Loss: 0.6336
Epoch [123/250], Train Loss: 0.6244, Validation Loss: 0.6289
Epoch [124/250], Train Loss: 0.6357, Validation Loss: 0.6251
Epoch [125/250], Train Loss: 0.6302, Validation Loss: 0.6335
Epoch [126/250], Train Loss: 0.6243, Validation Loss: 0.6219
Epoch [127/250], Train Loss: 0.6274, Validation Loss: 0.6319
Epoch [128/250], Train Loss: 0.6257, Validation Loss: 0.6293
Epoch [129/250], Train Loss: 0.6298, Validation Loss: 0.6240
Epoch [130/250], Train Loss: 0.6438, Validation Loss: 0.6220
Epoch [131/250], Train Loss: 0.6328, Validation Loss: 0.6226
Epoch [132/250], Train Loss: 0.6255, Validation Loss: 0.6195
Epoch [133/250], Train Loss: 0.6311, Validation Loss: 0.6258
Epoch [134/250], Train Loss: 0.6260, Validation Loss: 0.6259
Epoch [135/250], Train Loss: 0.6267, Validation Loss: 0.6202
Epoch [136/250], Train Loss: 0.6198, Validation Loss: 0.6390
Epoch [137/250], Train Loss: 0.6267, Validation Loss: 0.6271
Epoch [138/250], Train Loss: 0.6233, Validation Loss: 0.6233
Epoch [139/250], Train Loss: 0.6227, Validation Loss: 0.6280
Epoch [140/250], Train Loss: 0.6282, Validation Loss: 0.6226
Epoch [141/250], Train Loss: 0.6184, Validation Loss: 0.6277
Epoch [142/250], Train Loss: 0.6272, Validation Loss: 0.6235
Epoch [143/250], Train Loss: 0.6243, Validation Loss: 0.6226
Epoch [144/250], Train Loss: 0.6312, Validation Loss: 0.6228
Epoch [145/250], Train Loss: 0.6389, Validation Loss: 0.6316
Epoch [146/250], Train Loss: 0.6271, Validation Loss: 0.6310
Epoch [147/250], Train Loss: 0.6366, Validation Loss: 0.6300
Epoch [148/250], Train Loss: 0.6227, Validation Loss: 0.6406
Epoch [149/250], Train Loss: 0.6356, Validation Loss: 0.6265
Epoch [150/250], Train Loss: 0.6383, Validation Loss: 0.6460
Epoch [151/250], Train Loss: 0.6303, Validation Loss: 0.6229
Epoch [152/250], Train Loss: 0.6273, Validation Loss: 0.6317
Epoch [153/250], Train Loss: 0.6304, Validation Loss: 0.6233
Epoch [154/250], Train Loss: 0.6288, Validation Loss: 0.6286
Epoch [155/250], Train Loss: 0.6272, Validation Loss: 0.6250
Epoch [156/250], Train Loss: 0.6312, Validation Loss: 0.6355
Epoch [157/250], Train Loss: 0.6307, Validation Loss: 0.6329
Epoch [158/250], Train Loss: 0.6278, Validation Loss: 0.6322
Epoch [159/250], Train Loss: 0.6235, Validation Loss: 0.6225
Epoch [160/250], Train Loss: 0.6209, Validation Loss: 0.6299
Epoch [161/250], Train Loss: 0.6274, Validation Loss: 0.6272
Epoch [162/250], Train Loss: 0.6261, Validation Loss: 0.6333
Epoch [163/250], Train Loss: 0.6435, Validation Loss: 0.6330
Epoch [164/250], Train Loss: 0.6227, Validation Loss: 0.6276
Epoch [165/250], Train Loss: 0.6294, Validation Loss: 0.6280
Epoch [166/250], Train Loss: 0.6249, Validation Loss: 0.6215
Epoch [167/250], Train Loss: 0.6310, Validation Loss: 0.6183
Epoch [168/250], Train Loss: 0.6427, Validation Loss: 0.6264
Epoch [169/250], Train Loss: 0.6356, Validation Loss: 0.6258
Epoch [170/250], Train Loss: 0.6257, Validation Loss: 0.6272
Epoch [171/250], Train Loss: 0.6254, Validation Loss: 0.6260
Epoch [172/250], Train Loss: 0.6325, Validation Loss: 0.6379
Epoch [173/250], Train Loss: 0.6389, Validation Loss: 0.6213
Epoch [174/250], Train Loss: 0.6200, Validation Loss: 0.6252
Epoch [175/250], Train Loss: 0.6258, Validation Loss: 0.6220
Epoch [176/250], Train Loss: 0.6341, Validation Loss: 0.6305
Epoch [177/250], Train Loss: 0.6258, Validation Loss: 0.6458
Epoch [178/250], Train Loss: 0.6433, Validation Loss: 0.6281
Epoch [179/250], Train Loss: 0.6357, Validation Loss: 0.6418
Epoch [180/250], Train Loss: 0.6334, Validation Loss: 0.6277
Epoch [181/250], Train Loss: 0.6380, Validation Loss: 0.6629
Epoch [182/250], Train Loss: 0.6444, Validation Loss: 0.6358
Epoch [183/250], Train Loss: 0.6228, Validation Loss: 0.6185
Epoch [184/250], Train Loss: 0.6347, Validation Loss: 0.6260
Epoch [185/250], Train Loss: 0.6306, Validation Loss: 0.6336
Epoch [186/250], Train Loss: 0.6282, Validation Loss: 0.6285
Epoch [187/250], Train Loss: 0.6157, Validation Loss: 0.6208
Epoch [188/250], Train Loss: 0.6282, Validation Loss: 0.6277
Epoch [189/250], Train Loss: 0.6267, Validation Loss: 0.6248
Epoch [190/250], Train Loss: 0.6273, Validation Loss: 0.6289
Epoch [191/250], Train Loss: 0.6482, Validation Loss: 0.6240
Epoch [192/250], Train Loss: 0.6184, Validation Loss: 0.6203
Epoch [193/250], Train Loss: 0.6288, Validation Loss: 0.6242
Epoch [194/250], Train Loss: 0.6427, Validation Loss: 0.6274
Epoch [195/250], Train Loss: 0.6259, Validation Loss: 0.6187
Epoch [196/250], Train Loss: 0.6349, Validation Loss: 0.6267
Epoch [197/250], Train Loss: 0.6298, Validation Loss: 0.6266
Epoch [198/250], Train Loss: 0.6291, Validation Loss: 0.6352
Epoch [199/250], Train Loss: 0.6183, Validation Loss: 0.6306
Epoch [200/250], Train Loss: 0.6176, Validation Loss: 0.6201
Epoch [201/250], Train Loss: 0.6251, Validation Loss: 0.6278
Epoch [202/250], Train Loss: 0.6168, Validation Loss: 0.6300
Epoch [203/250], Train Loss: 0.6271, Validation Loss: 0.6241
Epoch [204/250], Train Loss: 0.6259, Validation Loss: 0.6337
Epoch [205/250], Train Loss: 0.6344, Validation Loss: 0.6221
Epoch [206/250], Train Loss: 0.6320, Validation Loss: 0.6388
Epoch [207/250], Train Loss: 0.6446, Validation Loss: 0.6303
Epoch [208/250], Train Loss: 0.6269, Validation Loss: 0.6291
Epoch [209/250], Train Loss: 0.6344, Validation Loss: 0.6259
Epoch [210/250], Train Loss: 0.6522, Validation Loss: 0.6321
Epoch [211/250], Train Loss: 0.6164, Validation Loss: 0.6287
Epoch [212/250], Train Loss: 0.6416, Validation Loss: 0.6434
Epoch [213/250], Train Loss: 0.6386, Validation Loss: 0.6211
Epoch [214/250], Train Loss: 0.6403, Validation Loss: 0.6441
Epoch [215/250], Train Loss: 0.6342, Validation Loss: 0.6240
Epoch [216/250], Train Loss: 0.6324, Validation Loss: 0.6342
Epoch [217/250], Train Loss: 0.6355, Validation Loss: 0.6255
Epoch [218/250], Train Loss: 0.6394, Validation Loss: 0.6294
Epoch [219/250], Train Loss: 0.6300, Validation Loss: 0.6285
Epoch [220/250], Train Loss: 0.6268, Validation Loss: 0.6240
Epoch [221/250], Train Loss: 0.6269, Validation Loss: 0.6119
Epoch [222/250], Train Loss: 0.6191, Validation Loss: 0.6193
Epoch [223/250], Train Loss: 0.6239, Validation Loss: 0.6245
Epoch [224/250], Train Loss: 0.6335, Validation Loss: 0.6223
Epoch [225/250], Train Loss: 0.6280, Validation Loss: 0.6301
Epoch [226/250], Train Loss: 0.6370, Validation Loss: 0.6184
Epoch [227/250], Train Loss: 0.6302, Validation Loss: 0.6378
Epoch [228/250], Train Loss: 0.6417, Validation Loss: 0.6224
Epoch [229/250], Train Loss: 0.6233, Validation Loss: 0.6355
Epoch [230/250], Train Loss: 0.6191, Validation Loss: 0.6258
Epoch [231/250], Train Loss: 0.6322, Validation Loss: 0.6259
Epoch [232/250], Train Loss: 0.6281, Validation Loss: 0.6350
Epoch [233/250], Train Loss: 0.6287, Validation Loss: 0.6211
Epoch [234/250], Train Loss: 0.6281, Validation Loss: 0.6260
Epoch [235/250], Train Loss: 0.6354, Validation Loss: 0.6303
Epoch [236/250], Train Loss: 0.6269, Validation Loss: 0.6316
Epoch [237/250], Train Loss: 0.6154, Validation Loss: 0.6221
Epoch [238/250], Train Loss: 0.6267, Validation Loss: 0.6362
Epoch [239/250], Train Loss: 0.6316, Validation Loss: 0.6307
Epoch [240/250], Train Loss: 0.6261, Validation Loss: 0.6356
Epoch [241/250], Train Loss: 0.6289, Validation Loss: 0.6323
Epoch [242/250], Train Loss: 0.6340, Validation Loss: 0.6267
Epoch [243/250], Train Loss: 0.6251, Validation Loss: 0.6276
Epoch [244/250], Train Loss: 0.6264, Validation Loss: 0.6262
Epoch [245/250], Train Loss: 0.6264, Validation Loss: 0.6219
Epoch [246/250], Train Loss: 0.6287, Validation Loss: 0.6330
Epoch [247/250], Train Loss: 0.6241, Validation Loss: 0.6329
Epoch [248/250], Train Loss: 0.6298, Validation Loss: 0.6252
Epoch [249/250], Train Loss: 0.6276, Validation Loss: 0.6324
Epoch [250/250], Train Loss: 0.6392, Validation Loss: 0.6192

Finished Training in 80.3

Saving model parameters...
done
